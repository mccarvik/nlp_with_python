{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Chapter 10\n",
    "\n",
    "## Analyzing the Meaning of Sentences\n",
    "\n",
    "*The html version of this chapter in the book is available [here](https://www.nltk.org/book/ch10.html \"ch10\").*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% start S\n",
      "S[SEM=(?np + WHERE + ?vp)] -> NP[SEM=?np] VP[SEM=?vp]\n",
      "VP[SEM=(?v + ?pp)] -> IV[SEM=?v] PP[SEM=?pp]\n",
      "VP[SEM=(?v + ?ap)] -> IV[SEM=?v] AP[SEM=?ap]\n",
      "NP[SEM=(?det + ?n)] -> Det[SEM=?det] N[SEM=?n]\n",
      "PP[SEM=(?p + ?np)] -> P[SEM=?p] NP[SEM=?np]\n",
      "AP[SEM=?pp] -> A[SEM=?a] PP[SEM=?pp]\n",
      "NP[SEM='Country=\"greece\"'] -> 'Greece'\n",
      "NP[SEM='Country=\"china\"'] -> 'China'\n",
      "Det[SEM='SELECT'] -> 'Which' | 'What'\n",
      "N[SEM='City FROM city_table'] -> 'cities'\n",
      "IV[SEM=''] -> 'are'\n",
      "A[SEM=''] -> 'located'\n",
      "P[SEM=''] -> 'in'\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.data.show_cfg('grammars/book_grammars/sql0.fcfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT City FROM city_table WHERE   Country=\"china\"\n",
      "canton chungking dairen harbin kowloon mukden peking shanghai sian tientsin "
     ]
    }
   ],
   "source": [
    "from nltk import load_parser\n",
    "cp = load_parser('grammars/book_grammars/sql0.fcfg')\n",
    "query = 'What cities are located in China'\n",
    "trees = list(cp.parse(query.split()))\n",
    "answer = trees[0].label()['SEM']\n",
    "q = ' '.join(answer)\n",
    "print(q)\n",
    "\n",
    "from nltk.sem import chat80\n",
    "rows = chat80.sql_query('corpora/city_database/city.db', q)\n",
    "for r in rows: print(r[0], end=\" \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negation       \t-\n",
      "conjunction    \t&\n",
      "disjunction    \t|\n",
      "implication    \t->\n",
      "equivalence    \t<->\n"
     ]
    }
   ],
   "source": [
    "nltk.boolean_ops()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-(P & Q)\n",
      "(P & Q)\n",
      "(P | (R -> Q))\n",
      "(P <-> --P)\n"
     ]
    }
   ],
   "source": [
    "lp = nltk.sem.logic.LogicParser()\n",
    "print(lp.parse('-(P & Q)'))\n",
    "print(lp.parse('P & Q'))\n",
    "print(lp.parse('P | (R -> Q)'))\n",
    "print(lp.parse('P <-> -- P'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp = nltk.sem.logic.LogicParser()\n",
    "SnF = lp.parse('SnF')\n",
    "NotFnS = lp.parse('-FnS')\n",
    "R = lp.parse('SnF -> -FnS')\n",
    "prover = nltk.Prover9()\n",
    "# prover.prove(NotFnS, [SnF, R])\n",
    "# need to downloand prover9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "val = nltk.Valuation([('P', True), ('Q', True), ('R', False)])\n",
    "print(val['P'])\n",
    "dom = set([])\n",
    "g = nltk.Assignment(dom)\n",
    "m = nltk.Model(dom, val)\n",
    "\n",
    "print(m.evaluate('(P & Q)', g))\n",
    "print(m.evaluate('-(P & Q)', g))\n",
    "print(m.evaluate('(P & R)', g))\n",
    "print(m.evaluate('(P | R)', g))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angus\n",
      "e\n",
      "walk\n",
      "<e,?>\n"
     ]
    }
   ],
   "source": [
    "tlp = nltk.sem.logic.LogicParser(type_check=True)\n",
    "parsed = tlp.parse('walk(angus)')\n",
    "print(parsed.argument)\n",
    "print(parsed.argument.type)\n",
    "print(parsed.function)\n",
    "print(parsed.function.type)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig = {'walk': '<e, t>'}\n",
    "parsed = tlp.parse('walk(angus)', sig)\n",
    "parsed.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "{Variable('x')}\n",
      "set()\n",
      "set()\n",
      "{Variable('x')}\n",
      "{Variable('y')}\n"
     ]
    }
   ],
   "source": [
    "lp = nltk.sem.logic.LogicParser()\n",
    "print(lp.parse('dog(cyril)').free())\n",
    "print(lp.parse('dog(x)').free())\n",
    "print(lp.parse('own(angus, cyril)').free())\n",
    "print(lp.parse('exists x.dog(x)').free())\n",
    "print(lp.parse('((some x. walk(x)) -> sing(x))').free())\n",
    "print(lp.parse('exists x.own(y, x)').free())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NotFnS = lp.parse('-north_of(f, s)')\n",
    "SnF = lp.parse('north_of(s, f)')\n",
    "R = lp.parse('all x. all y. (north_of(x, y) -> -north_of(y, x))')\n",
    "prover = nltk.Prover9()\n",
    "# prover.prove(NotFnS, [SnF, R])\n",
    "# need to downloand prover9\n",
    "\n",
    "FnS = lp.parse('north_of(f, s)')\n",
    "# prover.prove(FnS, [SnF, R])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bertie': 'b',\n",
      " 'boy': {('b',)},\n",
      " 'cyril': 'c',\n",
      " 'dog': {('c',)},\n",
      " 'girl': {('o',)},\n",
      " 'olive': 'o',\n",
      " 'see': {('b', 'o'), ('o', 'c'), ('c', 'b')},\n",
      " 'walk': {('o',), ('c',)}}\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "dom = {'b', 'o', 'c'}\n",
    "v = \"\"\"\n",
    "    bertie => b\n",
    "    olive => o\n",
    "    cyril => c\n",
    "    boy => {b}\n",
    "    girl => {o}\n",
    "    dog => {c}\n",
    "    walk => {o, c}\n",
    "    see => {(b, o), (c, b), (o, c)}\n",
    "    \"\"\"\n",
    "val = nltk.Valuation.fromstring(v)\n",
    "print(val)\n",
    "\n",
    "print(('o', 'c') in val['see'])\n",
    "print(('b', 'o') in val['see'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 'o', 'y': 'c'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = nltk.Assignment(dom, [('x', 'o'), ('y', 'c')])\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g[c/y][o/x]\n"
     ]
    }
   ],
   "source": [
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "m = nltk.Model(dom, val)\n",
    "print(m.evaluate('see(olive, y)', g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(g['y'])\n",
    "print(m.evaluate('see(y, x)', g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g\n",
      "Undefined\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "g.purge()\n",
    "print(g)\n",
    "print(m.evaluate('see(olive, y)', g))\n",
    "print(m.evaluate('see(bertie, olive) & boy(bertie) & -walk(bertie)', g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "{'o', 'b'}\n",
      "{'o', 'c', 'b'}\n",
      "{'o', 'b'}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Quantification\n",
    "print(m.evaluate('exists x.(girl(x) & walk(x))', g))\n",
    "print(m.evaluate('girl(x) & walk(x)', g.add('x', 'o')))\n",
    "\n",
    "fmla1 = lp.parse('girl(x) | boy(x)')\n",
    "print(m.satisfiers(fmla1, 'x', g))\n",
    "fmla2 = lp.parse('girl(x) -> walk(x)')\n",
    "print(m.satisfiers(fmla2, 'x', g))\n",
    "fmla3 = lp.parse('walk(x) -> girl(x)')\n",
    "print(m.satisfiers(fmla3, 'x', g))\n",
    "\n",
    "print(m.evaluate('all x.(girl(x) -> walk(x))', g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'e', 'm', 'j', 'b'}\n",
      "set()\n",
      "{'b'}\n"
     ]
    }
   ],
   "source": [
    "v2 = \"\"\"\n",
    "    bruce => b\n",
    "    elspeth => e\n",
    "    julia => j\n",
    "    matthew => m\n",
    "    person => {b, e, j, m}\n",
    "    admire => {(j, b), (b, b), (m, e), (e, m), (e, j)}\n",
    "    \"\"\"\n",
    "val2 = nltk.Valuation.fromstring(v2)\n",
    "\n",
    "dom2 = val2.domain\n",
    "m2 = nltk.Model(dom2, val2)\n",
    "g2 = nltk.Assignment(dom2)\n",
    "fmla4 = lp.parse('(person(x) -> exists y.(person(y) & admire(x, y)))')\n",
    "print(m2.satisfiers(fmla4, 'x', g2))\n",
    "\n",
    "fmla5 = lp.parse('(person(y) & all x.(person(x) -> admire(x, y)))')\n",
    "print(m2.satisfiers(fmla5, 'y', g2))\n",
    "\n",
    "fmla6 = lp.parse('(person(y) & all x.((x = bruce | x = julia) -> admire(x, y)))')\n",
    "print(m2.satisfiers(fmla6, 'y', g2))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3 = lp.parse('exists x.(man(x) & walks(x))')\n",
    "c1 = lp.parse('mortal(socrates)')\n",
    "c2 = lp.parse('-mortal(socrates)')\n",
    "# mb = nltk.Mace(5)\n",
    "# need to download prover9\n",
    "# print(mb.build_model(None, [a3, c1]))\n",
    "# print(mb.build_model(None, [a3, c2]))\n",
    "# print(mb.build_model(None, [c1, c2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a4 = lp.parse('exists y. (woman(y) & all x. (man(x) -> love(x,y)))')\n",
    "a5 = lp.parse('man(adam)')\n",
    "a6 = lp.parse('woman(eve)')\n",
    "g = lp.parse('love(adam,eve)')\n",
    "# mc = nltk.MaceCommand(g, assumptions=[a4, a5, a6])\n",
    "# print(mc.build_model())\n",
    "# print(mc.valuation)\n",
    "# need to download prover9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a7 = lp.parse('all x. (man(x) -> -woman(x))')\n",
    "g = lp.parse('love(adam,eve)')\n",
    "# mc = nltk.MaceCommand(g, assumptions=[a4, a5, a6, a7])\n",
    "# print(mc.build_model())\n",
    "# print(mc.valuation)\n",
    "# need to download prover9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\x.(walk(x) & chew_gum(x))\n",
      "set()\n",
      "\\x.(walk(x) & chew_gum(x))\n",
      "\\x.(walk(x) & chew_gum(y))\n"
     ]
    }
   ],
   "source": [
    "lp = nltk.sem.logic.LogicParser()\n",
    "e = lp.parse(r'\\x.(walk(x) & chew_gum(x))')\n",
    "print(e)\n",
    "print(e.free())\n",
    "print(e.simplify())\n",
    "print(lp.parse(r'\\x.(walk(x) & chew_gum(y))'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\x.(walk(x) & chew_gum(x))(gerald)\n",
      "(walk(gerald) & chew_gum(gerald))\n"
     ]
    }
   ],
   "source": [
    "e = lp.parse(r'\\x.(walk(x) & chew_gum(x))(gerald)')\n",
    "print(e)\n",
    "print(e.simplify())\n",
    "\n",
    "print(lp.parse(r'\\x.\\y.(dog(x) & own(y, x))(cyril)').simplify())\n",
    "print(lp.parse(r'\\x y.(dog(x) & own(y, x))(cyril, angus)').simplify())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exists x.P(x)\n",
      "exists z.P(z)\n",
      "True\n",
      "exists x.P(x)\n",
      "exists x.P(x)\n"
     ]
    }
   ],
   "source": [
    "e1 = lp.parse('exists x.P(x)')\n",
    "print(e1)\n",
    "e2 = e1.alpha_convert(nltk.Variable('z'))\n",
    "print(e2)\n",
    "print(e1 == e2)\n",
    "\n",
    "e3 = lp.parse('exists x.P(x)')\n",
    "print(e3)\n",
    "print(e3.simplify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\\X x.X(\\y.chase(x,y)))(\\P.exists x.(dog(x) & P(x)))\n",
      "\\x.exists z1.(dog(z1) & chase(x,z1))\n"
     ]
    }
   ],
   "source": [
    "lp = nltk.sem.logic.LogicParser()\n",
    "tvp = lp.parse(r'\\X x.X(\\y.chase(x,y))')\n",
    "np = lp.parse(r'(\\P.exists x.(dog(x) & P(x)))')\n",
    "vp = nltk.sem.ApplicationExpression(tvp, np)\n",
    "print(vp)\n",
    "print(vp.simplify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<all z9.(dog(z9) -> exists z8.(bone(z8) & give(angus,z8,z9)))>]\n",
      "  (NP[-LOC, NUM='sg', SEM=<\\P.P(angus)>]\n",
      "    (PropN[-LOC, NUM='sg', SEM=<\\P.P(angus)>] Angus))\n",
      "  (VP[NUM='sg', SEM=<\\x.all z9.(dog(z9) -> exists z8.(bone(z8) & give(x,z8,z9)))>]\n",
      "    (DTV[NUM='sg', SEM=<\\Y X x.X(\\z.Y(\\y.give(x,y,z)))>, TNS='pres']\n",
      "      gives)\n",
      "    (NP[NUM='sg', SEM=<\\Q.exists x.(bone(x) & Q(x))>]\n",
      "      (Det[NUM='sg', SEM=<\\P Q.exists x.(P(x) & Q(x))>] a)\n",
      "      (Nom[NUM='sg', SEM=<\\x.bone(x)>]\n",
      "        (N[NUM='sg', SEM=<\\x.bone(x)>] bone)))\n",
      "    (PP[SEM=<\\Q.all x.(dog(x) -> Q(x))>, +TO]\n",
      "      (P[+to] to)\n",
      "      (NP[NUM='sg', SEM=<\\Q.all x.(dog(x) -> Q(x))>]\n",
      "        (Det[NUM='sg', SEM=<\\P Q.all x.(P(x) -> Q(x))>] every)\n",
      "        (Nom[NUM='sg', SEM=<\\x.dog(x)>]\n",
      "          (N[NUM='sg', SEM=<\\x.dog(x)>] dog))))))\n"
     ]
    }
   ],
   "source": [
    "from nltk import load_parser\n",
    "parser = load_parser('grammars/book_grammars/simple-sem.fcfg', trace=0)\n",
    "# grammar = nltk.data.load('grammars/book_grammars/simple-sem.fcfg')  # Replace 'atis.cfg' with the grammar you want to use\n",
    "# parser = nltk.ChartParser(grammar)\n",
    "\n",
    "sentence = 'Angus gives a bone to every dog'\n",
    "\n",
    "tokens = sentence.split()\n",
    "# trees = parser.nbest_parse(tokens)\n",
    "trees = parser.parse(tokens)\n",
    "print(next(trees))\n",
    "for tree in trees:\n",
    "    print(tree.label()['SEM'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all z26.(boy(z26) -> see(cyril,z26))\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "v = \"\"\"\n",
    "bertie => b\n",
    "olive => o\n",
    "cyril => c\n",
    "boy => {b}\n",
    "girl => {o}\n",
    "dog => {c}\n",
    "walk => {o, c}\n",
    "see => {(b, o), (c, b), (o, c)}\n",
    "\"\"\"\n",
    "\n",
    "val = nltk.Valuation.fromstring(v)\n",
    "\n",
    "g = nltk.Assignment(val.domain)\n",
    "m = nltk.Model(val.domain, val)\n",
    " \n",
    "sent = 'Cyril sees every boy'\n",
    "grammar_file = 'grammars/book_grammars/simple-sem.fcfg'\n",
    "results = nltk.evaluate_sents([sent], grammar_file, m, g)[0]\n",
    "for (syntree, semrep, value) in results:\n",
    "    print(semrep)\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chase(z2,z3)\n",
      "bo(\\P.all x.(girl(x) -> P(x)),z2)\n",
      "bo(\\P.exists x.(dog(x) & P(x)),z3)\n",
      "Permutation 1\n",
      "   (\\P.all x.(girl(x) -> P(x)))(\\z2.chase(z2,z3))\n",
      "   (\\P.exists x.(dog(x) & P(x)))(\\z3.all x.(girl(x) -> chase(x,z3)))\n",
      "Permutation 2\n",
      "   (\\P.exists x.(dog(x) & P(x)))(\\z3.chase(z2,z3))\n",
      "   (\\P.all x.(girl(x) -> P(x)))(\\z2.exists x.(dog(x) & chase(z2,x)))\n",
      "None\n",
      "exists x.(dog(x) & all z31.(girl(z31) -> chase(z31,x)))\n",
      "all x.(girl(x) -> exists z32.(dog(z32) & chase(x,z32)))\n"
     ]
    }
   ],
   "source": [
    "from nltk.sem import cooper_storage as cs\n",
    "sentence = 'every girl chases a dog'\n",
    "trees = cs.parse_with_bindops(sentence, grammar='grammars/book_grammars/storage.fcfg')\n",
    "semrep = trees[0].label()['SEM']\n",
    "cs_semrep = cs.CooperStore(semrep)\n",
    "print(cs_semrep.core)\n",
    "for bo in cs_semrep.store:\n",
    "    print(bo)\n",
    "\n",
    "print(cs_semrep.s_retrieve(trace=True))\n",
    "for reading in cs_semrep.readings:\n",
    "    print(reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([x,y],[angus(x), dog(y), own(x,y)])\n",
      "exists x y.(angus(x) & dog(y) & own(x,y))\n",
      "(([x],[walk(x)]) + ([y],[run(y)]))\n",
      "([x,y],[walk(x), run(y)])\n",
      "all x.(dog(x) -> exists y.(ankle(y) & bite(x,y)))\n",
      "(([x,y],[angus(x), dog(y), own(x,y)]) + ([u,z],[PRO(u), irene(z), bite(u,z)]))\n",
      "([u,x,y,z],[angus(x), dog(y), own(x,y), PRO(u), irene(z), bite(u,z)])\n",
      "([u,x,y,z],[angus(x), dog(y), own(x,y), (u = [x,y,z]), irene(z), bite(u,z)])\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sem.drt import DrtParser\n",
    "\n",
    "dp = DrtParser()\n",
    "drs1 = dp.parse('([x, y], [angus(x), dog(y), own(x, y)])')\n",
    "print(drs1)\n",
    "\n",
    "# dp = nltk.DrtParser()\n",
    "# drs1 = dp.parse('([x, y], [angus(x), dog(y), own(x, y)])')\n",
    "# print(drs1)\n",
    "# print(drs1.draw())\n",
    "# drs1.draw()\n",
    "\n",
    "print(drs1.fol())\n",
    "drs2 = dp.parse('([x], [walk(x)]) + ([y], [run(y)])')\n",
    "print(drs2)\n",
    "print(drs2.simplify())\n",
    "\n",
    "drs3 = dp.parse('([], [(([x], [dog(x)]) -> ([y],[ankle(y), bite(x, y)]))])')\n",
    "print(drs3.fol())\n",
    "\n",
    "drs4 = dp.parse('([x, y], [angus(x), dog(y), own(x, y)])')\n",
    "drs5 = dp.parse('([u, z], [PRO(u), irene(z), bite(u, z)])')\n",
    "drs6 = drs4 + drs5\n",
    "print(drs6)\n",
    "print(drs6.simplify())\n",
    "print(drs6.simplify().resolve_anaphora())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S[SEM=<([x,z64],[Angus(x), dog(z64), own(x,z64)])>]\n",
      "  (NP[-LOC, NUM='sg', SEM=<\\P.(([x],[Angus(x)]) + P(x))>]\n",
      "    (PropN[-LOC, NUM='sg', SEM=<\\P.(([x],[Angus(x)]) + P(x))>] Angus))\n",
      "  (VP[NUM='sg', SEM=<\\z63.([x],[dog(x), own(z63,x)])>]\n",
      "    (TV[NUM='sg', SEM=<\\X x.X(\\y.([],[own(x,y)]))>, tns='pres'] owns)\n",
      "    (NP[NUM='sg', SEM=<\\Q.(([x],[dog(x)]) + Q(x))>]\n",
      "      (Det[NUM='sg', SEM=<\\P Q.(([x],[]) + P(x) + Q(x))>] a)\n",
      "      (Nom[NUM='sg', SEM=<\\x.([],[dog(x)])>]\n",
      "        (N[NUM='sg', SEM=<\\x.([],[dog(x)])>] dog)))))\n"
     ]
    }
   ],
   "source": [
    "from nltk import load_parser\n",
    "parser = load_parser('grammars/book_grammars/drt.fcfg', logic_parser=nltk.sem.drt.DrtParser())\n",
    "trees = parser.parse('Angus owns a dog'.split())\n",
    "print(next(trees))\n",
    "# for tree in trees:\n",
    "#     print(tree.label()['SEM'])\n",
    "# trees = parser.nbest_parse('Angus owns a dog'.split())\n",
    "# print(trees[0].node['sem'].simplify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n\n===========================================================================\nNLTK was unable to find the mace4 file!\nUse software specific configuration parameters or set the PROVER9 environment variable.\n\n  Searched in:\n    - /usr/local/bin/prover9\n    - /usr/local/bin/prover9/bin\n    - /usr/local/bin\n    - /usr/bin\n    - /usr/local/prover9\n    - /usr/local/share/prover9\n\n  For more information on mace4, see:\n    <https://www.cs.unm.edu/~mccune/prover9/>\n===========================================================================",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[122], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39m# dt.readings()\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# need to download prover9\u001b[39;00m\n\u001b[0;32m      4\u001b[0m dt\u001b[39m.\u001b[39madd_sentence(\u001b[39m'\u001b[39m\u001b[39mNo person dances\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m dt\u001b[39m.\u001b[39;49mretract_sentence(\u001b[39m'\u001b[39;49m\u001b[39mNo person dances\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m dt\u001b[39m.\u001b[39madd_sentence(\u001b[39m'\u001b[39m\u001b[39mA person dances\u001b[39m\u001b[39m'\u001b[39m, consistchk\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\inference\\discourse.py:265\u001b[0m, in \u001b[0;36mDiscourseTester.retract_sentence\u001b[1;34m(self, sentence, verbose)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentences \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39ms\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m i: sent \u001b[39mfor\u001b[39;00m i, sent \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input)}\n\u001b[1;32m--> 265\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreadings(verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    266\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[0;32m    267\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCurrent sentences are \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\inference\\discourse.py:375\u001b[0m, in \u001b[0;36mDiscourseTester.readings\u001b[1;34m(self, sentence, threaded, verbose, filter, show_thread_readings)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39mConstruct and show the readings of the discourse (or of a single sentence).\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[39m:param filter: if ``True``, only print out consistent thread IDs and threads.\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_readings()\n\u001b[1;32m--> 375\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_construct_threads()\n\u001b[0;32m    377\u001b[0m \u001b[39m# if we are filtering or showing thread readings, show threads\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mfilter\u001b[39m \u001b[39mor\u001b[39;00m show_thread_readings:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\inference\\discourse.py:314\u001b[0m, in \u001b[0;36mDiscourseTester._construct_threads\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_filtered_threads \u001b[39m=\u001b[39m {}\n\u001b[0;32m    313\u001b[0m \u001b[39m# keep the same ids, but only include threads which get models\u001b[39;00m\n\u001b[1;32m--> 314\u001b[0m consistency_checked \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_consistency(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_threads)\n\u001b[0;32m    315\u001b[0m \u001b[39mfor\u001b[39;00m (tid, thread) \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    316\u001b[0m     \u001b[39mif\u001b[39;00m (tid, \u001b[39mTrue\u001b[39;00m) \u001b[39min\u001b[39;00m consistency_checked:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\inference\\discourse.py:428\u001b[0m, in \u001b[0;36mDiscourseTester._check_consistency\u001b[1;34m(self, threads, show, verbose)\u001b[0m\n\u001b[0;32m    426\u001b[0m     \u001b[39m# if Mace4 finds a model, it always seems to find it quickly\u001b[39;00m\n\u001b[0;32m    427\u001b[0m     mb \u001b[39m=\u001b[39m MaceCommand(\u001b[39mNone\u001b[39;00m, assumptions, max_models\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[1;32m--> 428\u001b[0m     modelfound \u001b[39m=\u001b[39m mb\u001b[39m.\u001b[39;49mbuild_model()\n\u001b[0;32m    429\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    430\u001b[0m     modelfound \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\inference\\api.py:340\u001b[0m, in \u001b[0;36mBaseModelBuilderCommand.build_model\u001b[1;34m(self, verbose)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[39mAttempt to build a model.  Store the result to prevent unnecessary\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[39mre-building.\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 340\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_modelbuilder\u001b[39m.\u001b[39;49m_build_model(\n\u001b[0;32m    341\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgoal(), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49massumptions(), verbose\n\u001b[0;32m    342\u001b[0m     )\n\u001b[0;32m    343\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\inference\\mace.py:247\u001b[0m, in \u001b[0;36mMace._build_model\u001b[1;34m(self, goal, assumptions, verbose)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m assumptions:\n\u001b[0;32m    245\u001b[0m     assumptions \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 247\u001b[0m stdout, returncode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_mace4(\n\u001b[0;32m    248\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprover9_input(goal, assumptions), verbose\u001b[39m=\u001b[39;49mverbose\n\u001b[0;32m    249\u001b[0m )\n\u001b[0;32m    250\u001b[0m \u001b[39mreturn\u001b[39;00m (returncode \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, stdout)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\inference\\mace.py:262\u001b[0m, in \u001b[0;36mMace._call_mace4\u001b[1;34m(self, input_str, args, verbose)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[39mCall the ``mace4`` binary with the given input.\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39m:see: ``config_prover9``\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mace4_bin \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 262\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mace4_bin \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_find_binary(\u001b[39m\"\u001b[39;49m\u001b[39mmace4\u001b[39;49m\u001b[39m\"\u001b[39;49m, verbose)\n\u001b[0;32m    264\u001b[0m updated_input_str \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    265\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_end_size \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\inference\\prover9.py:177\u001b[0m, in \u001b[0;36mProver9Parent._find_binary\u001b[1;34m(self, name, verbose)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_binary_location \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     binary_locations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_binary_location]\n\u001b[1;32m--> 177\u001b[0m \u001b[39mreturn\u001b[39;00m nltk\u001b[39m.\u001b[39;49minternals\u001b[39m.\u001b[39;49mfind_binary(\n\u001b[0;32m    178\u001b[0m     name,\n\u001b[0;32m    179\u001b[0m     searchpath\u001b[39m=\u001b[39;49mbinary_locations,\n\u001b[0;32m    180\u001b[0m     env_vars\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mPROVER9\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    181\u001b[0m     url\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mhttps://www.cs.unm.edu/~mccune/prover9/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    182\u001b[0m     binary_names\u001b[39m=\u001b[39;49m[name, name \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.exe\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    183\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    184\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\internals.py:675\u001b[0m, in \u001b[0;36mfind_binary\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_binary\u001b[39m(\n\u001b[0;32m    667\u001b[0m     name,\n\u001b[0;32m    668\u001b[0m     path_to_bin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    673\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    674\u001b[0m ):\n\u001b[1;32m--> 675\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\n\u001b[0;32m    676\u001b[0m         find_binary_iter(\n\u001b[0;32m    677\u001b[0m             name, path_to_bin, env_vars, searchpath, binary_names, url, verbose\n\u001b[0;32m    678\u001b[0m         )\n\u001b[0;32m    679\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\internals.py:661\u001b[0m, in \u001b[0;36mfind_binary_iter\u001b[1;34m(name, path_to_bin, env_vars, searchpath, binary_names, url, verbose)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_binary_iter\u001b[39m(\n\u001b[0;32m    642\u001b[0m     name,\n\u001b[0;32m    643\u001b[0m     path_to_bin\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    648\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    649\u001b[0m ):\n\u001b[0;32m    650\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    651\u001b[0m \u001b[39m    Search for a file to be used by nltk.\u001b[39;00m\n\u001b[0;32m    652\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    659\u001b[0m \u001b[39m    :param verbose: Whether or not to print path when a file is found.\u001b[39;00m\n\u001b[0;32m    660\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 661\u001b[0m     \u001b[39myield from\u001b[39;00m find_file_iter(\n\u001b[0;32m    662\u001b[0m         path_to_bin \u001b[39mor\u001b[39;00m name, env_vars, searchpath, binary_names, url, verbose\n\u001b[0;32m    663\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\nltk\\internals.py:620\u001b[0m, in \u001b[0;36mfind_file_iter\u001b[1;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[0;32m    618\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m  For more information on \u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m, see:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m    <\u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m>\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    619\u001b[0m div \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m75\u001b[39m\n\u001b[1;32m--> 620\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mdiv\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mdiv\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the mace4 file!\nUse software specific configuration parameters or set the PROVER9 environment variable.\n\n  Searched in:\n    - /usr/local/bin/prover9\n    - /usr/local/bin/prover9/bin\n    - /usr/local/bin\n    - /usr/bin\n    - /usr/local/prover9\n    - /usr/local/share/prover9\n\n  For more information on mace4, see:\n    <https://www.cs.unm.edu/~mccune/prover9/>\n==========================================================================="
     ]
    }
   ],
   "source": [
    "dt = nltk.DiscourseTester(['A student dances', 'Every student is a person'])\n",
    "# dt.readings()\n",
    "# need to download prover9\n",
    "# print(dt.add_sentence('No person dances'))\n",
    "# print(dt.retract_sentence('No person dances'))\n",
    "# print(dt.add_sentence('A person dances', consistchk=True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import RegexpTagger\n",
    "tagger = RegexpTagger(\n",
    "    [('^(chases|runs)$', 'VB'),\n",
    "        ('^(a)$', 'ex_quant'),\n",
    "        ('^(every)$', 'univ_quant'),\n",
    "        ('^(dog|boy)$', 'NN'),\n",
    "        ('^(He)$', 'PRP')\n",
    "    ])\n",
    "# rc = nltk.DrtGlueReadingCommand(depparser=nltk.MaltParser(tagger=tagger))\n",
    "# dt = nltk.DiscourseTester(['Every dog chases a boy', 'He runs'], rc)\n",
    "# print(dt.readings())\n",
    "# print(dt.readings(show_thread_readings=True))\n",
    "# print(dt.readings(show_thread_readings=True, filter=True))\n",
    "# need to download prover9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
