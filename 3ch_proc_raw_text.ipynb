{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Chapter 3\n",
    "\n",
    "## Processing Raw Text\n",
    "\n",
    "*The html version of this page is available [here](https://www.nltk.org/book/ch03.html \"ch03\").*\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to be called from this point on in the book\n",
    "\n",
    "import nltk, re, pprint\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Accessing Text from the Web and from Disk\n",
    "\n",
    "*Getting from Project Gutenburg text number 2554, which is an English translation of __Crime and Punishment__:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "response = request.urlopen(url)\n",
    "\n",
    "# this line is different from the book\n",
    "# we need to decode without byte order mark (BOM)\n",
    "# so use this encoding instead\n",
    "\n",
    "raw = response.read().decode('utf-8-sig') \n",
    "type(raw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Slightly different from the book's answer:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176811"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg eBook of Crime and Punishment, by Fyodor Dostoevsky\\r\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw[:75]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tokenizing the text:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(raw)\n",
    "type(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257058"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Project', 'Gutenberg', 'eBook', 'of', 'Crime', 'and', 'Punishment', ',', 'by']"
     ]
    }
   ],
   "source": [
    "print(tokens[:10], end = '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Converting to an NLTK text:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.text.Text"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['insight', 'impresses', 'us', 'as', 'wisdom', '...', 'that', 'wisdom', 'of', 'the', 'heart', 'which', 'we', 'seek', 'that', 'we', 'may', 'learn', 'from', 'it', 'how', 'to', 'live', '.', 'All', 'his', 'other', 'gifts', 'came', 'to', 'him', 'from', 'nature', ',', 'this', 'he', 'won', 'for']"
     ]
    }
   ],
   "source": [
    "print(text[1024:1062], end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katerina Ivanovna; Pyotr Petrovitch; Pulcheria Alexandrovna; Avdotya\n",
      "Romanovna; Rodion Romanovitch; Marfa Petrovna; Sofya Semyonovna; old\n",
      "woman; Project Gutenberg-tm; Porfiry Petrovitch; Amalia Ivanovna;\n",
      "great deal; young man; Nikodim Fomitch; Project Gutenberg; Ilya\n",
      "Petrovitch; Andrey Semyonovitch; Hay Market; Dmitri Prokofitch; Good\n",
      "heavens\n"
     ]
    }
   ],
   "source": [
    "text.collocations()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Getting rid of header and footer:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.find(\"PART I\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This returns `-1`, which means the search failed:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.rfind(\"End of Gutenberg's Crim\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The reason is because older Project Gutenberg texts often use curly single quotes `’`, which are not used in many modern systems.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.rfind(\"End of Project Gutenberg’s Crime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = raw[5335:1157811]\n",
    "raw.find(\"PART I\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dealing with HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://news.bbc.co.uk/2/hi/health/2284783.stm\"\n",
    "html = request.urlopen(url).read().decode('utf8')\n",
    "html[:60]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All the HTML content:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html public \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/loose.dtd\">\n",
      "<html>\n",
      "<head>\n",
      "<title>BBC NEWS | Health | Blondes 'to die out in 200 years'</title>\n",
      "<meta name=\"keywords\" content=\"BBC, News, BBC News, news online, world, uk, international, foreign, british, online, service\">\n",
      "<meta name=\"OriginalPublicationDate\" content=\"2002/09/27 11:51:55\">\n",
      "<meta name=\"UKFS_URL\" content=\"/1/hi/health/2284783.stm\">\n",
      "<meta name=\"IFS_URL\" content=\"/2/hi/health/2284783.stm\">\n",
      "<meta name=\"HTTP-EQUIV\" content=\"text/html;charset=iso-8859-1\">\n",
      "<meta name=\"Headline\" content=\"Blondes 'to die out in 200 years'\">\n",
      "<meta name=\"Section\" content=\"Health\">\n",
      "<meta name=\"Description\" content=\"Natural blondes are an endangered species and will die out by 2202, a study suggests.\">\n",
      "<!-- GENMaps-->\n",
      "<map name=\"banner\">\n",
      "<area alt=\"BBC NEWS\" coords=\"7,9,167,32\" href=\"http://news.bbc.co.uk/1/hi.html\" shape=\"RECT\">\n",
      "</map>\n",
      "\n",
      "<script src=\"/nol/shared/js/livestats_v1_1.js\" language=\"JavaScript\" type=\"text/javascript\"></script>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\n",
      "\t<map name=\"world_map\">\n",
      "<area alt=\"Americas\" coords=\"40,55,40,4,6,4,7,55\" href=\"/2/hi/americas/default.stm\" shape=\"POLY\">\n",
      "<area alt=\"Africa\" shape=\"POLY\" coords=\"41,54,41,27,46,27,46,32,46,33,55,33,55,36,58,36,58,54\" href=\"/2/hi/africa/default.stm\">\n",
      "<area alt=\"Europe\" shape=\"POLY\" coords=\"41,5,41,25,63,25,63,17,73,17,73,4\" href=\"/2/hi/europe/default.stm\">\n",
      "<area alt=\"Middle East\" shape=\"POLY\" coords=\"60,54,60,54,60,34,57,34,57,31,48,31,48,27,63,27,63,54\" href=\"/2/hi/middle_east/default.stm\">\n",
      "<area alt=\"South Asia\" coords=\"67,55,65,54,65,27,71,27,71,54\" href=\"/2/hi/south_asia/default.stm\" shape=\"POLY\">\n",
      "<area alt=\"Asia Pacific\" shape=\"POLY\" coords=\"75,54,73,54,73,25,65,25,65,19,75,19,75,5,94,5,94,56\" href=\"/2/hi/asia-pacific/default.stm\">\n",
      "</map>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<link type=\"text/css\" rel=\"stylesheet\" href=\"/nol/shared/stylesheets/uki_globalstylesheet.css\">\n",
      "<script src=\"/nol/shared/js_ifs/nol.js\" language=\"JavaScript\"></script>\n",
      "</head>\n",
      "\n",
      "<body bgcolor=\"#FFFFFF\" text=\"#000000\" link=\"#000066\" alink=\"#000066\" vlink=\"#993333\" topmargin=\"0\" leftmargin=\"0\" marginheight=\"0\" marginwidth=\"0\">\n",
      "<!--[START]--(( BBCi TOOLBAR )) IFS News -->\n",
      "<table width=\"610\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\">\n",
      "<tr>\n",
      "<td class=\"bbcpageShadow\"><a name=\"top\"><img src=\"/nol/shared/img/global_toolbar/t.gif\" width=\"600\" height=\"2\" alt=\"\"/></a></td>\n",
      "</tr>\n",
      "<form action=\"http://newssearch.bbc.co.uk/cgi-bin/search/results.pl\">\n",
      "<input type=\"hidden\" name=\"scope\" value=\"newsifs\">\n",
      "<input type=\"hidden\" name=\"tab\" value=\"news\">\n",
      "<tr>\n",
      "<td class=\"bbcpageGrey\">\n",
      "<table cellpadding=\"0\" cellspacing=\"0\" border=\"0\">\n",
      "<tr>\n",
      "<td class=\"bbcpageShadowLeft\" width=\"100%\"><a href=\"http://www.bbc.co.uk/\"><img src=\"/nol/shared/img/global_toolbar/logo.gif\" width=\"62\" height=\"20\" alt=\"BBCi\" border=\"0\" hspace=\"7\" vspace=\"2\" /></a></td>\n",
      "<td class=\"bbcpageGreyT\" align=\"right\"><font color=\"#000000\"><font face=\"tahoma,arial,helvetica,sans-serif\" size=\"1\" class=\"bbcpageWhite\"><b><a href=\"http://news.bbc.co.uk\" class=\"bbcpageWhite\">NEWS</a></b></font></td>\n",
      "<td class=\"bbcpageBar\"><font face=\"tahoma,arial,helvetica,sans-serif\" size=\"1\" class=\"bbcpageWhite\">&nbsp;&nbsp;<b><a href=\"http://news.bbc.co.uk/sport/\" class=\"bbcpageWhite\">SPORT</a></b></font></td>\n",
      "<td class=\"bbcpageBar2\"><font face=\"tahoma,arial,helvetica,sans-serif\" size=\"1\" class=\"bbcpageWhite\">&nbsp;&nbsp;<b><a href=\"http://www.bbc.co.uk/weather/\" class=\"bbcpageWhite\">WEATHER</a></b></font></td>\n",
      "<td class=\"bbcpageBar\"><font face=\"tahoma,arial,helvetica,sans-serif\" size=\"1\" class=\"bbcpageWhite\">&nbsp;&nbsp;<b><a href=\"http://www.bbc.co.uk/worldservice/index.shtml\" class=\"bbcpageWhite\">WORLD SERVICE</a></b></font></td>\n",
      "<!-- <td class=\"bbcpageBar2\"><font face=\"tahoma,arial,helvetica,sans-serif\" size=\"1\" class=\"bbcpageWhite\">&nbsp;&nbsp;<b><a href=\"http://www.bbc.co.uk/whereilive/\" class=\"bbcpageWhite\">WHERE&nbsp;I&nbsp;LIVE</a></b></font></td> -->\n",
      "<td class=\"bbcpageBar\"><font face=\"tahoma,arial,helvetica,sans-serif\" size=\"1\" class=\"bbcpageWhite\">&nbsp;&nbsp;<b><a href=\"http://www.bbc.co.uk/a-z/\" class=\"bbcpageWhite\">A-Z INDEX</a>&nbsp;</b></font></td>\n",
      "<td class=\"bbcpageSearchL\"><img src=\"/furniture/nothing.gif\" width=\"2\" height=\"30\" alt=\"\"/></td>\n",
      "<td class=\"bbcpageSearch\"><font face=\"tahoma,arial,helvetica,sans-serif\" size=\"1\" class=\"bbcpageCream\">&nbsp;&nbsp;<label for=\"bbcpagesearchbox\"><b>SEARCH</b></label>&nbsp;</font></td>\n",
      "<td class=\"bbcpageSearch2\" style=\"font-family:tahoma,arial,helvetica,sans-serif;\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"3\" alt=\"\" /><br /><INPUT type=\"text\" name=\"q\" id=\"bbcpagesearchbox\" size=\"5\" style=\"width:95px;\" /></td>\n",
      "<td class=\"bbcpageSearch\"><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\" /></td>\n",
      "<td class=\"bbcpageSearch2\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"5\" alt=\"\" /><br /><input type=\"image\" value=\"go\" src=\"/nol/shared/img/global_toolbar/go.gif\" width=\"20\" height=\"16\" border=\"0\" alt=\"Go\" align=\"top\" /></td>\n",
      "<td class=\"bbcpageSearch\"><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\" /></td>\n",
      "<td class=\"bbcpageSearchR\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"30\" alt=\"\" /></td>\n",
      "</tr>\n",
      "\n",
      "<tr bgcolor=\"#000000\">\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"76\" height=\"1\" alt=\"\"/></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"76\" height=\"1\" alt=\"\"/></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"20\" height=\"1\" alt=\"\"/></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"42\" height=\"1\" alt=\"\"/></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"94\" height=\"1\" alt=\"\"/></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"80\" height=\"1\" alt=\"\"/></td>\n",
      "<!-- <td><img src=\"/shared/img/o.gif\" width=\"42\" height=\"1\" alt=\"\"/></td> -->\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"2\" height=\"1\" alt=\"\"/></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"51\" height=\"1\" alt=\"\"/></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"100\" height=\"1\" alt=\"\"/></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"/></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"20\" height=\"1\" alt=\"\"/></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"/></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"/></td>\n",
      "</tr>\n",
      "\n",
      "</table></td>\n",
      "\n",
      "</tr>\n",
      "</form>\n",
      "</table>\n",
      "<!-- end news toolbar 1.0 -->\n",
      "<table width=\"610\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\n",
      "<tr><td bgcolor=\"#9C0000\"><img src=\"/nol/shared/img/banners/ifs_banner.gif\" width=\"610\" height=\"40\" border=\"0\" alt=\"BBC News World Edition\" usemap=\"#banner\"></td></tr></table>\n",
      "<!--END OF BANNER-->\n",
      "\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"610\">\n",
      "<tr>\n",
      "<td width=\"10\"><img src=\"/shared/img/o.gif\" width=\"10\" height=\"1\" alt=\"\"></td>\n",
      "<td width=\"100\"><img src=\"/shared/img/o.gif\" width=\"100\" height=\"1\" alt=\"\"></td>\n",
      "<td width=\"5\"><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\n",
      "<td bgcolor=\"#999966\" width=\"315\"><img src=\"/shared/img/o.gif\" width=\"315\" height=\"1\" alt=\"\"></td>\n",
      "<td bgcolor=\"#999966\" width=\"10\"><img src=\"/shared/img/o.gif\" width=\"10\" height=\"1\" alt=\"\"></td>\n",
      "<td bgcolor=\"#999966\" width=\"170\"><img src=\"/shared/img/o.gif\" width=\"170\" height=\"1\" alt=\"\"></td>\n",
      "</tr>\n",
      "\n",
      "<tr>\n",
      "<td width=\"10\"><img src=\"/shared/img/o.gif\" width=\"10\" height=\"1\" alt=\"\"></td>\n",
      "<td width=\"100\"><img src=\"/shared/img/o.gif\" width=\"100\" height=\"1\" alt=\"\"></td>\n",
      "<td width=\"5\"><img src=\"/shared/img/o.gif\" width=\"5\" height=\"3\" alt=\"\"></td>\n",
      "<td colspan=\"3\" width=\"495\" class=\"crumbtraila\" bgcolor=\"#CCCC99\">\n",
      "    &nbsp;You are in:&nbsp;<a href=\"/2/hi/health/default.stm\"><b>Health</b> </a>&nbsp;\n",
      "    \n",
      "    \n",
      "</td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td width=\"10\"><img src=\"/shared/img/o.gif\" width=\"10\" height=\"1\" alt=\"\"></td>\n",
      "<td align=\"LEFT\" valign=\"TOP\">\n",
      "    \n",
      "\t<table width=\"100\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\n",
      "\t<tr>\n",
      "\t<td><img height=\"1\" border=\"0\" width=\"96\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\n",
      "\t<td><img height=\"1\" border=\"0\" width=\"4\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\n",
      "\t</tr>\n",
      "\t\n",
      "\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyleTight\" align=\"right\"><a href=\"/2/hi/default.stm\" class=\"index\"><b>News Front Page</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t<td colspan=\"2\"><img height=\"60\" usemap=\"#world_map\" border=\"0\" width=\"100\" alt=\"\" src=\"http://newsimg.bbc.co.uk/nol/shared/img/nav/blue_map_world.gif\"></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/africa/default.stm\" class=\"index\"><b>Africa</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/americas/default.stm\" class=\"index\"><b>Americas</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/asia-pacific/default.stm\" class=\"index\"><b>Asia-Pacific</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/europe/default.stm\" class=\"index\"><b>Europe</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/middle_east/default.stm\" class=\"index\"><b>Middle East</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/south_asia/default.stm\" class=\"index\"><b>South Asia</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/uk_news/default.stm\" class=\"index\"><b>UK</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/business/default.stm\" class=\"index\"><b>Business</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/entertainment/default.stm\" class=\"index\"><b>Entertainment</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyleTight\" align=\"right\"><a href=\"/2/hi/science/nature/default.stm\" class=\"index\"><b>Science/Nature</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/technology/default.stm\" class=\"index\"><b>Technology</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t<td bgColor=\"#999999\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/health/default.stm\" class=\"index\"><b>Health</b></a></td><td bgColor=\"#CC3300\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\t\n",
      "\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t<td bgColor=\"#CCCCCC\" align=\"right\" class=\"sectionStyle\"><a href=\"/2/hi/health/medical_notes/default.stm\" class=\"index\"><b>Medical notes</b></a></td><td bgcolor=\"#CCCCCC\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t<td align=\"CENTER\" colspan=\"2\"><span class=\"lhsNavSeparator\">-------------</span></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/talking_point/default.stm\" class=\"index\"><b>Talking Point</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t<td align=\"CENTER\" colspan=\"2\"><span class=\"lhsNavSeparator\">-------------</span></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\t<tr>\n",
      "\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyleTight\" align=\"right\"><a href=\"/2/shared/bsp/hi/country_profiles/html/default.stm\" class=\"index\"><b>Country Profiles</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\n",
      "\t\t\t\t</tr>\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\t<tr>\n",
      "\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/shared/bsp/hi/in_depth/html/default.stm\" class=\"index\"><b>In Depth</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\n",
      "\t\t\t\t</tr>\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\t<tr>\n",
      "\t\t\t\t<td align=\"CENTER\" colspan=\"2\"><span class=\"lhsNavSeparator\">-------------</span></td>\n",
      "\t\t\t\t</tr>\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t<td bgColor=\"#FFFFFF\" class=\"sectionStyle\" align=\"right\"><a href=\"/2/hi/programmes/default.stm\" class=\"index\"><b>Programmes</b></a></td><td bgcolor=\"#FFFFFF\"><img height=\"1\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t<tr>\n",
      "\t\t\t\t\t<td align=\"CENTER\" colspan=\"2\"><span class=\"lhsNavSeparator\">-------------</span></td>\n",
      "\t\t\t\t\t</tr>\n",
      "\t\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t<tr><td colspan=\"2\"><img height=\"5\" border=\"0\" width=\"1\" alt=\"\" src=\"http://newsimg.bbc.co.uk/shared/img/o.gif\"></td></tr>\n",
      "\t</table>\n",
      "\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\n",
      "<table width=\"100\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\n",
      "<tr>\n",
      "<td><a href=\"/sport2/hi/default.stm\"><img src=\"/nol/shared/img/nav/sport.gif\" width=\"100\" height=\"13\" alt=\"BBC Sport\" border=\"0\"></a></td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td><img src=\"/shared/img/o.gif\" height=\"3\" width=\"1\" border=\"0\"></td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td><a href=\"http://www.bbc.co.uk/weather/worldweather/index.shtml\"><img src=\"/nol/shared/img/nav/weather.gif\" width=\"100\" height=\"13\" alt=\"BBC Weather\" border=\"0\"></a></td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td><img src=\"/shared/img/o.gif\" height=\"10\" width=\"1\" border=\"0\"></td>\n",
      "</tr>\n",
      "\n",
      "</table>\n",
      "\n",
      "\n",
      "<table width=\"100\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\n",
      "<tr bgcolor=\"#990000\">\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"90\" height=\"1\" alt=\"\"></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "</tr>\n",
      "<tr bgcolor=\"#990000\">\n",
      "<td colspan=\"3\" align=\"right\"><div class=\"servicehead\">SERVICES\n",
      "</div></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "<td class=\"servicebg1\"><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\n",
      "<td align=\"right\" class=\"servicebg1\"><div class=\"servicesnav\"><a href=\"http://www.bbc.co.uk/email/news\">Daily E-mail\n",
      "</a></div></td>\n",
      "<td class=\"serviceoption1\"><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "</tr> \n",
      "<tr>\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "<td class=\"servicebg2\"><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\n",
      "<td align=\"right\" class=\"servicebg2\"><div class=\"servicesnav\"><a href=\"/2/shared/bsp/hi/services/ticker/html/default.stm\">News Ticker\n",
      "</a></div></td>\n",
      "<td class=\"serviceoption2\"><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "<td class=\"servicebg3\"><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\n",
      "<td align=\"right\" class=\"servicebg3\"><div class=\"servicesnav\"><a href=\"/2/shared/bsp/hi/services/mobiles/html/default.stm\">Mobile/PDAs\n",
      "</a></div></td>\n",
      "<td class=\"serviceoption3\"><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "<td align=\"center\" colspan=\"3\"><span class=\"lhsNavSeparator\">-------------\n",
      "</span></td>\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "</tr>\n",
      "</table>\n",
      "\n",
      "\n",
      "    <table width=\"100\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\n",
      "    <tr>\n",
      "    <td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "    <td><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\n",
      "    <td><img src=\"/shared/img/o.gif\" width=\"90\" height=\"1\" alt=\"\"></td>\n",
      "    <td><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\n",
      "    <td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "    <td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "    <td class=\"servicebg4\"><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\n",
      "    <td align=\"right\" class=\"servicebg4\"><div class=\"servicesnav\"><a href=\"/2/low/health/2284783.stm\">Text Only</a></div></td>\n",
      "    <td class=\"serviceoption4\"><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\n",
      "    <td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "    </tr>\n",
      "    </table>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<table width=\"100\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\n",
      "<tr>\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "<td class=\"servicebg5\"><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\n",
      "<td align=\"right\" class=\"servicebg5\"><div class=\"servicesnav\"><a href=\"/2/shared/bsp/hi/services/feedback/html/default.stm\">Feedback\n",
      "</a></div></td>\n",
      "<td class=\"serviceoption5\"><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "<td class=\"servicebg6\"><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\n",
      "<td align=\"right\" class=\"servicebg6\"><div class=\"servicesnav\"><a href=\"/2/shared/bsp/hi/services/help/html/default.stm\">Help\n",
      "</a></div></td>\n",
      "<td class=\"serviceoption6\"><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "</tr>\n",
      "<tr bgcolor=\"#CCCCCC\">\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"90\" height=\"1\" alt=\"\"></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td colspan=\"5\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"4\" alt=\"\"></td>\n",
      "</tr>\n",
      "</table>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<table width=\"100\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\n",
      "<tr bgcolor=\"#6699CC\">\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"90\" height=\"1\" alt=\"\"></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "</tr>\n",
      "<tr bgcolor=\"#336699\">\n",
      "<td colspan=\"3\" align=\"right\"><div class=\"servicehead\">EDITIONS\n",
      "</div></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\n",
      "<td align=\"right\"><div class=\"servicesnavtight\"><a href=\"/shared/hi/change_edition-news.stm\">Change to UK\n",
      "</a></div></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\n",
      "<td bgcolor=\"#CCCCCC\"><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "</tr>\n",
      "<tr bgcolor=\"#CCCCCC\">\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"3\" height=\"1\" alt=\"\"></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"90\" height=\"1\" alt=\"\"></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"5\" height=\"1\" alt=\"\"></td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"1\" height=\"1\" alt=\"\"></td>\n",
      "</tr>\n",
      "</table>\n",
      "</td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"5\" height=\"200\" alt=\"\"></td>\n",
      "<td valign=\"TOP\">\n",
      "    \t\n",
      "\t\n",
      "\n",
      "                \n",
      "\n",
      "\n",
      "<font face=\"sans-serif\" size=\"1\"><span class=\"date\">Friday, 27 September, 2002, 11:51 GMT 12:51 UK\n",
      "</span></font>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\t\n",
      "\t\t\t<div class=\"headlinestory\"><b>Blondes 'to die out in 200 years'</b><br></div>\n",
      "\t\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t\n",
      "                \n",
      "\t\n",
      "\t<div class=\"inlineimage\">\n",
      "\t\t<img height=\"180\" vspace=\"0\" border=\"0\" width=\"300\" alt=\" \" src=\"/media/images/38280000/jpg/_38280456_blonde300.jpg\">\n",
      "\t\t\n",
      "\t\t\t<div class=\"caption\"><font size=\"1\">Scientists believe the last blondes will be in Finland</font><br></div>\n",
      "\t\t\n",
      "\t</div>\n",
      "\t\n",
      "\n",
      "\t\n",
      "\n",
      "\t<font class=\"body\" face=\"sans-serif\" size=\"2\">\n",
      "\t<div class=\"bodytext\">\n",
      "\tThe last natural blondes will die out within 200 years, scientists believe. \n",
      "<P>\n",
      "A study by experts in Germany suggests people with blonde hair are an endangered species and will become extinct by 2202.\n",
      "<P>\n",
      "Researchers predict the last truly natural blonde will be born in Finland - the country with the highest proportion of blondes. \n",
      "<P>\n",
      "\n",
      "\n",
      "<!-- GENInlineBOX -->\n",
      "\n",
      "\t<table bgcolor=\"#FFFFCC\" class=\"boxbody\" cellspacing=\"0\" width=\"150\" border=\"0\" cellpadding=\"3\" align=\"right\">\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "<!-- GENInlineQUOTE -->\n",
      "\n",
      "\t<tr><td><img src=\"/nol/shared/img/startquote.gif\" width=\"23\" height=\"18\" border=\"0\" valign=\"TOP\" alt=\"\"><br><div class=\"boxbody\">\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\tThe frequency of blondes may drop but they won't disappear\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t</div><img align=\"RIGHT\" src=\"/nol/shared/img/endquote.gif\" width=\"23\" height=\"18\" border=\"0\" valign=\"ABSBOTTOM\" alt=\"\"><br clear=\"ALL\"></td></tr>\n",
      "\n",
      "\n",
      "\n",
      "<!-- GENInlineNAME -->\n",
      "\n",
      "\t<tr><td bgcolor=\"cccc99\"><div class=\"boxhead\">\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\tProf Jonathan Rees, University of Edinburgh\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t</div></td></tr>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t</table>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "But they say too few people now carry the gene for blondes to last beyond the next two centuries. \n",
      "<P>\n",
      "The problem is that blonde hair is caused by a recessive gene. \n",
      "<P>\n",
      "In order for a child to have blonde hair, it must have the gene on both sides of the family in the grandparents' generation. \n",
      "<P><B>Dyed rivals</B>\n",
      "<P>\n",
      "\n",
      "The researchers also believe that so-called bottle blondes may be to blame for the demise of their natural rivals. \n",
      "<P>\n",
      "They suggest that dyed-blondes are more attractive to men who choose them as partners over true blondes. \n",
      "<P>\n",
      "\n",
      "\n",
      "<!-- GENInlineIMAGE -->\n",
      "\n",
      "\t\t\n",
      "\t\t\t<table cellspacing=\"3\" align=\"RIGHT\" width=\"154\" border=\"0\" cellpadding=\"3\"><tr><td><font size=\"2\">\n",
      "\t\t\n",
      "\t\t<div class=\"inlineimage\">\n",
      "            <img alt=\"Tory MP Ann Widdecombe\" height=\"180\" vspace=\"0\" src=\"/media/images/38280000/jpg/_38280457_widders150.jpg\" border=\"0\" width=\"150\">\n",
      "            \n",
      "                <div class=\"caption\"><small>Bottle-blondes like Ann Widdecombe may be to blame</small><br></div>\n",
      "            \n",
      "\t\t</div>\n",
      "\t\t\n",
      "\t\t\t</font></td></tr></table>\n",
      "\t\t\n",
      "\n",
      "\t\n",
      "But Jonathan Rees, professor of dermatology at the University of Edinburgh said it was unlikely blondes would die out completely. \n",
      "<P>\n",
      "\"Genes don't die out unless there is a disadvantage of having that gene or by chance. They don't disappear,\" he told BBC News Online.\n",
      "<P>\n",
      "\"The only reason blondes would disappear is if having the gene was a disadvantage and I do not think that is the case. \n",
      "<P>\n",
      "\"The frequency of blondes may drop but they won't disappear.\"\n",
      "<P>\n",
      "\n",
      "\n",
      "\n",
      "</div>\n",
      "\t</font>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "</td>\n",
      "<td><img src=\"/shared/img/o.gif\" width=\"10\" height=\"1\" alt=\"\"></td>\n",
      "<td valign=\"TOP\"><font face=\"sans-serif\" size=\"2\">\n",
      "\t\n",
      "\t\n",
      "\n",
      "\t\n",
      "        \n",
      "\t<div class=\"rhslist\"><div class=\"rhshead\"><b>See also:</b><br><img src=\"/shared/img/999999.gif\" width=\"170\" vspace=\"2\" height=\"1\" alt=\"\"><br></div>\n",
      "\t\n",
      "\t\t<div class=\"aitem\">\n",
      "\t\t\t<span class=\"seealsodate\">28 Mar 01&nbsp;|&nbsp;Education</span>\n",
      "                        <div><a href=\"/2/hi/uk_news/education/1248103.stm\"><span>What is it about blondes?</span></a><br></div>\n",
      "\n",
      "\t\t</div>\n",
      "\t\n",
      "\t\t<div class=\"aitem\">\n",
      "\t\t\t<span class=\"seealsodate\">09 Apr 99&nbsp;|&nbsp;Health</span>\n",
      "                        <div><a href=\"/2/hi/health/315527.stm\"><span>Platinum blondes are labelled as dumb</span></a><br></div>\n",
      "\n",
      "\t\t</div>\n",
      "\t\n",
      "\t\t<div class=\"aitem\">\n",
      "\t\t\t<span class=\"seealsodate\">17 Apr 02&nbsp;|&nbsp;Health</span>\n",
      "                        <div><a href=\"/2/hi/health/1934496.stm\"><span>Hair dye cancer alert</span></a><br></div>\n",
      "\n",
      "\t\t</div>\n",
      "\t\n",
      "\t</div>\n",
      "\n",
      "\n",
      "\n",
      "\t\n",
      "<div class=\"rhslist\">\n",
      "<div class=\"rhshead\"><b>Internet links:</b><br><img src=\"/shared/img/999999.gif\" width=\"170\" vspace=\"2\" height=\"1\" alt=\"\"><br></div>\n",
      "<div class=\"aitem\"><a href=\"http://www.ed.ac.uk/\">University of Edinburgh</a></div>\n",
      "<span class=\"disclaimer\"><br>The BBC is not responsible for the content of external internet sites</span><br>\n",
      "</div>\n",
      "\n",
      "\t\n",
      "            \n",
      "    \n",
      "<div class=\"rhslist\">\n",
      "\t<div class=\"rhshead\"><b>Top Health stories now:</b><br><img src=\"/shared/img/999999.gif\" width=\"170\" vspace=\"2\" height=\"1\" alt=\"\"><br></div>\n",
      "\t\n",
      "            <div class=\"bulletheadline\"><a href=\"/2/hi/health/2770999.stm\"><span>Heart risk link to big families</span></a><br></div>\n",
      "\n",
      "\t\n",
      "            <div class=\"bulletheadline\"><a href=\"/2/hi/health/2761469.stm\"><span>Back pain drug 'may aid diabetics'</span></a><br></div>\n",
      "\n",
      "\t\n",
      "            <div class=\"bulletheadline\"><a href=\"/2/hi/africa/2776719.stm\"><span>Congo Ebola outbreak confirmed</span></a><br></div>\n",
      "\n",
      "\t\n",
      "            <div class=\"bulletheadline\"><a href=\"/2/hi/health/2772499.stm\"><span>Vegetables ward off Alzheimer's</span></a><br></div>\n",
      "\n",
      "\t\n",
      "            <div class=\"bulletheadline\"><a href=\"/2/hi/middle_east/2774951.stm\"><span>Polio campaign launched in Iraq</span></a><br></div>\n",
      "\n",
      "\t\n",
      "            <div class=\"bulletheadline\"><a href=\"/2/hi/health/2760843.stm\"><span>Gene defect explains high blood pressure</span></a><br></div>\n",
      "\n",
      "\t\n",
      "            <div class=\"bulletheadline\"><a href=\"/2/hi/health/2772263.stm\"><span>Botox 'may cause new wrinkles'</span></a><br></div>\n",
      "\n",
      "\t\n",
      "            <div class=\"bulletheadline\"><a href=\"/2/hi/in_depth/sci_tech/2003/denver_2003/2769875.stm\"><span>Alien 'abductees' show real symptoms</span></a><br></div>\n",
      "\n",
      "\t\n",
      "</div>\n",
      "<img src=\"/shared/img/999999.gif\" width=\"170\" height=\"1\" border=\"0\" alt=\"\">\n",
      "<div class=\"promotextbold\">Links to more Health stories are at the foot of the page.<br><img src=\"/shared/img/999999.gif\" width=\"170\" height=\"1\" border=\"0\" vspace=\"4\" alt=\"\"><br>\n",
      "</div>\n",
      "\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "\t\n",
      "</font></td>\n",
      "</tr>\n",
      "</table>\n",
      "<br>\n",
      "<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n",
      "<tr>\n",
      "  <td width=\"115\"><img src=\"/shared/img/o.gif\" width=\"105\" height=\"1\" border=\"0\" alt=\"\"></td>\n",
      "  <td width=\"315\"><img border=\"0\" alt=\"\" src=\"/shared/img/999999.gif\" width=\"315\" height=\"1\"></td>\n",
      "</tr>\n",
      "<tr>\n",
      "  <td width=\"115\" height=\"18\"><img src=\"/shared/img/o.gif\" width=\"115\" height=\"1\" border=\"0\" alt=\"\"></td>\n",
      "  <td width=\"315\" align=\"left\"><a onClick=\"window.open('http://newsvote.bbc.co.uk/cgi-bin/emailthisstory/emailthisstory.pl','Mailer','status=no,scrollbars=yes,resizable=yes,width=370,height=445');\" href=\"http://newsvote.bbc.co.uk/cgi-bin/emailthisstory/emailthisstory.pl\" class=\"index\" target=\"Mailer\"><img border=\"0\" alt=\"\" src=\"/sol/shared/img/mail_icon.gif\" width=\"13\" height=\"9\"> <span class=\"blueText\"><b>E-mail this story to a friend</b></span></td>\n",
      "</tr>\n",
      "</table>\n",
      "\n",
      "    <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\">\n",
      "  <tr>\n",
      "    <td width=\"115\"><img src=\"/shared/img/o.gif\" width=\"115\" height=\"1\" alt=\"\"></td>\n",
      "    <td width=\"315\"><img border=\"0\" alt=\"\" src=\"/shared/img/999999.gif\" width=\"315\" height=\"1\"></td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td><img src=\"/shared/img/o.gif\" width=\"115\" height=\"1\" alt=\"\"></td>\n",
      "    <td align=\"left\">\n",
      "\n",
      "<br clear=\"all\">\n",
      "<font size=\"2\">\n",
      " <span class=\"blackText\">\n",
      "<b>Links to more Health stories</b></span>\n",
      "<br>\n",
      "<form name=\"storyMenu\">\n",
      "<select name=\"storyLink\">\n",
      "<option value=\"#\">In This Section</option>\n",
      "\n",
      "        <OPTION value=\"/2/hi/health/2770999.stm\">Heart risk link to big families</OPTION>\n",
      "\n",
      "        <OPTION value=\"/2/hi/health/2761469.stm\">Back pain drug 'may aid diabetics'</OPTION>\n",
      "\n",
      "        <OPTION value=\"/2/hi/africa/2776719.stm\">Congo Ebola outbreak confirmed</OPTION>\n",
      "\n",
      "        <OPTION value=\"/2/hi/health/2772499.stm\">Vegetables ward off Alzheimer's</OPTION>\n",
      "\n",
      "        <OPTION value=\"/2/hi/middle_east/2774951.stm\">Polio campaign launched in Iraq</OPTION>\n",
      "\n",
      "        <OPTION value=\"/2/hi/health/2760843.stm\">Gene defect explains high blood pressure</OPTION>\n",
      "\n",
      "        <OPTION value=\"/2/hi/health/2772263.stm\">Botox 'may cause new wrinkles'</OPTION>\n",
      "\n",
      "        <OPTION value=\"/2/hi/in_depth/sci_tech/2003/denver_2003/2769875.stm\">Alien 'abductees' show real symptoms</OPTION>\n",
      "\n",
      "        <OPTION value=\"/2/hi/health/2760623.stm\">How sperm wriggle</OPTION>\n",
      "\n",
      "        <OPTION value=\"/2/hi/south_asia/2770437.stm\">Bollywood told to stub it out</OPTION>\n",
      "\n",
      "        <OPTION value=\"/2/hi/health/2772005.stm\">Fears over tuna health risk to babies</OPTION>\n",
      "\n",
      "        <OPTION value=\"/2/hi/health/2758249.stm\">Public can be taught to spot strokes</OPTION>\n",
      "\n",
      "</select>\n",
      "<INPUT VALUE=\"Go\" TYPE=\"BUTTON\" onClick=\"window.location = document.storyMenu.storyLink.options[document.storyMenu.storyLink.options.selectedIndex].value\">\n",
      "</form>\n",
      "</font>\n",
      "\n",
      "</td>\n",
      "  </tr>\n",
      "</table>\n",
      "\n",
      "    \n",
      "    \n",
      "\n",
      "<br clear=\"ALL\">\n",
      "<table width=\"610\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\">\n",
      "<tr>\n",
      "<td><img border=\"0\" alt=\"\" src=\"/shared/img/o.gif\" width=\"100\" height=\"1\"></td>\n",
      "<td><img border=\"0\" alt=\"\" src=\"/shared/img/o.gif\" width=\"10\" height=\"1\"></td>\n",
      "<td><img border=\"0\" alt=\"\" src=\"/shared/img/o.gif\" width=\"500\" height=\"1\"></td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td colspan=\"3\"><img vspace=\"4\" alt=\"\" src=\"/shared/img/000000.gif\" width=\"610\" height=\"1\"></td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td align=\"right\" valign=\"top\"><a href=\"/2/shared/bsp/hi/services/copyright/html/default.stm\"><img src=\"/nol/shared/img/specials_nav/copyright_bbc.gif\" alt=\"&copy; BBC\" border=\"0\"></a></td>\n",
      "<td><img border=\"0\" alt=\"\" src=\"/shared/img/o.gif\" width=\"10\" height=\"1\"></td>\n",
      "<td>\n",
      "<font size=\"2\">\n",
      "<span class=\"footerarrow\">^^  </span>\n",
      "<span class=\"footer\"><a href=\"#top\">Back to top</a>\n",
      "<p>\n",
      "\n",
      "    <table width=\"500\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\">\n",
      "<tr>\n",
      "<td><img border=\"0\" alt=\"\" src=\"/shared/img/o.gif\" width=\"500\" height=\"1\"></td>\n",
      "</tr>\n",
      "<tr>\n",
      "<td><b class=\"footer\"><span class=\"footerpiping\">\n",
      "<a href=\"/2/hi/default.stm\" class=\"index\">News Front Page</a>\n",
      " | \n",
      "\n",
      "\n",
      "<a href=\"/2/hi/africa/default.stm\" class=\"index\">Africa</a>\n",
      " | \n",
      "\n",
      "\n",
      "<a href=\"/2/hi/americas/default.stm\" class=\"index\">Americas</a>\n",
      " | \n",
      "\n",
      "\n",
      "<a href=\"/2/hi/asia-pacific/default.stm\" class=\"index\">Asia-Pacific</a>\n",
      " | \n",
      "\n",
      "\n",
      "<a href=\"/2/hi/europe/default.stm\" class=\"index\">Europe</a>\n",
      " | \n",
      "\n",
      "\n",
      "<a href=\"/2/hi/middle_east/default.stm\" class=\"index\">Middle East</a>\n",
      " | \n",
      "<br>\n",
      "\n",
      "<a href=\"/2/hi/south_asia/default.stm\" class=\"index\">South Asia</a>\n",
      " | \n",
      "\n",
      "\n",
      "<a href=\"/2/hi/uk_news/default.stm\" class=\"index\">UK</a>\n",
      " | \n",
      "\n",
      "\n",
      "<a href=\"/2/hi/business/default.stm\" class=\"index\">Business</a>\n",
      " | \n",
      "\n",
      "\n",
      "<a href=\"/2/hi/entertainment/default.stm\" class=\"index\">Entertainment</a>\n",
      " | \n",
      "\n",
      "\n",
      "<a href=\"/2/hi/science/nature/default.stm\" class=\"index\">Science/Nature</a>\n",
      " | \n",
      "<br>\n",
      "\n",
      "<a href=\"/2/hi/technology/default.stm\" class=\"index\">Technology</a>\n",
      " | \n",
      "\n",
      "\n",
      "<a href=\"/2/hi/health/default.stm\" class=\"index\">Health</a>\n",
      " | \n",
      "\n",
      "\n",
      "<a href=\"/2/hi/talking_point/default.stm\" class=\"index\">Talking Point</a>\n",
      " | \n",
      "\n",
      "<a href=\"/2/shared/bsp/hi/country_profiles/html/default.stm\" class=\"index\">Country Profiles</a>\n",
      "\n",
      " | \n",
      "\n",
      "<a href=\"/2/shared/bsp/hi/in_depth/html/default.stm\" class=\"index\">In Depth</a>\n",
      "\n",
      " | \n",
      "<br>\n",
      "\n",
      "<a href=\"/2/hi/programmes/default.stm\" class=\"index\">Programmes</a>\n",
      "\n",
      "\n",
      "</span></b></td>\n",
      "</tr>\n",
      "</table>\n",
      "    \n",
      "    \n",
      "</span></font></td>\n",
      "</tr>\n",
      "</table>\n",
      "    <table width=\"610\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\">\n",
      "    <tr>\n",
      "    <td><img src=\"/shared/img/o.gif\" width=\"110\" height=\"1\" alt=\"\"></td>\n",
      "    <!-- black line row -->\n",
      "    <td class=\"footer\" align=\"left\" valign=\"top\" width=\"600\" bgcolor=\"#FFFFFF\"><b><span style=\"color : #999999;\">----------------------------------------------------------------------------------\n",
      "</span>\n",
      "    <br>\n",
      "    <a class=\"index\" href=\"/sport2/\">To BBC Sport&gt;&gt;\n",
      "</a> <span style=\"color : #999999;\">|\n",
      "</span> <a class=\"index\" href=\"http://www.bbc.co.uk/weather/\">To BBC Weather&gt;&gt;\n",
      "</a> <span style=\"color : #999999;\">|\n",
      "</span> <a class=\"index\" href=\"http://www.bbc.co.uk/worldservice/index.shtml\">To BBC World Service&gt;&gt;\n",
      "</a>\n",
      "    <br>\n",
      "    <b><span style=\"color : #999999;\">----------------------------------------------------------------------------------\n",
      "</span>\n",
      "    <br>\n",
      "    <a class=\"footer\" href=\"/2/shared/bsp/hi/services/copyright/html/default.stm\"><span style=\"font-size : 10px\">&copy; MMIII\n",
      "</span></a> <font size=\"1\">|\n",
      "</font> <a class=\"footer\" href=\"/2/shared/bsp/hi/services/help/html/sources.stm\"><span style=\"font-size : 10px\">News Sources\n",
      "</span></a> <font size=\"1\">|\n",
      "</font> <a class=\"footer\" href=\"http://www.bbc.co.uk/privacy/\"><span style=\"font-size : 10px\">Privacy\n",
      "</span></a></b>\n",
      "    <br><br><br>\n",
      "    </td>\n",
      "    </tr>\n",
      "    </table>\n",
      "<!-- START RedMeasure V4 - Java v1.1  $Revision: 1.9 $ -->\n",
      "<!-- COPYRIGHT 2000 Red Sheriff Limited -->\n",
      "\n",
      "<script language=\"JavaScript\"><!--\n",
      "var pCid=\"uk_bbc_0\";\n",
      "var w0=1;\n",
      "var refR=escape(document.referrer);\n",
      "if (refR.length>=252) refR=refR.substring(0,252)+\"...\";\n",
      "//--></script>\n",
      "<script language=\"JavaScript1.1\"><!--\n",
      "var w0=0;\n",
      "//--></script>\n",
      "<script language=\"JavaScript1.1\" src=\"http://server-uk.imrworldwide.com/a1.js\">\n",
      "</script>\n",
      "<script language=\"JavaScript\"><!--\n",
      "if(w0){\n",
      "var imgN='<img src=\"http://server-uk.imrworldwide.com/cgi-bin/count?ref='+\n",
      "\trefR+'&cid='+pCid+'\" width=1 height=1>';\n",
      "if(navigator.userAgent.indexOf('Mac')!=-1){document.write(imgN);\n",
      "}else{\n",
      "\tdocument.write('<applet code=\"Measure.class\" '+\n",
      "\t'codebase=\"http://server-uk.imrworldwide.com/\"'+'width=1 height=2>'+\n",
      "\t'<param name=\"ref\" value=\"'+refR+'\">'+'<param name=\"cid\" value=\"'+pCid+\n",
      "\t'\"><textflow>'+imgN+'</textflow></applet>');\n",
      "\t}\n",
      "}\n",
      "document.write(\"<COMMENT>\");\n",
      "//-->\n",
      "</script>\n",
      "<noscript>\n",
      "<img src=\"http://server-uk.imrworldwide.com/cgi-bin/count?cid=uk_bbc_0\" width=1 height=1>\n",
      "</noscript>\n",
      "</COMMENT>\n",
      "\n",
      "<!-- END RedMeasure V4 -->\n",
      "\n",
      "<script>\n",
      "\tvar si = document.location+\"\";\n",
      "\tvar tsi = si.replace(\".stm\",\"\").substr(si.length-11, si.length);\n",
      "\tif (!tsi.match(/\\d\\d\\d\\d\\d\\d\\d/)) {tsi = 0;}\n",
      "\tdocument.write('<img src=\"http://stats.bbc.co.uk/o.gif?~RS~s~RS~News~RS~t~RS~HighWeb_Legacy~RS~i~RS~' + tsi + '~RS~p~RS~0~RS~u~RS~/2/hi/health/2284783.stm~RS~r~RS~(none)~RS~a~RS~International~RS~q~RS~~RS~z~RS~46~RS~\">');\n",
      "</script>\n",
      "<noscript>\n",
      "\t<img src=\"http://stats.bbc.co.uk/o.gif?~RS~s~RS~News~RS~t~RS~HighWeb_Legacy~RS~i~RS~0~RS~p~RS~0~RS~u~RS~/2/hi/health/2284783.stm~RS~r~RS~(none)~RS~a~RS~International~RS~q~RS~~RS~z~RS~46~RS~\">\n",
      "</noscript>\n",
      "\n",
      "\n",
      "\n",
      "<br>\n",
      "<link type=\"text/css\" rel=\"stylesheet\" href=\"/nol/shared/stylesheets/uki_globalstylesheet.css\">\n",
      "\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We can use __BeautifulSoup__ to get text out of HTML:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BBC', 'NEWS', '|', 'Health', '|', 'Blondes', \"'to\", 'die', 'out', 'in', '200', \"years'\", 'NEWS', 'SPORT', 'WEATHER', 'WORLD', 'SERVICE', 'A-Z', 'INDEX', 'SEARCH', 'You', 'are', 'in', ':', 'Health', 'News', 'Front', 'Page', 'Africa', 'Americas', 'Asia-Pacific', 'Europe', 'Middle', 'East', 'South', 'Asia', 'UK', 'Business', 'Entertainment', 'Science/Nature', 'Technology', 'Health', 'Medical', 'notes', '--', '--', '--', '--', '--', '--', '-', 'Talking', 'Point', '--', '--', '--', '--', '--', '--', '-', 'Country', 'Profiles', 'In', 'Depth', '--', '--', '--', '--', '--', '--', '-', 'Programmes', '--', '--', '--', '--', '--', '--', '-', 'SERVICES', 'Daily', 'E-mail', 'News', 'Ticker', 'Mobile/PDAs', '--', '--', '--', '--', '--', '--', '-', 'Text', 'Only', 'Feedback', 'Help', 'EDITIONS', 'Change', 'to', 'UK', 'Friday', ',', '27', 'September', ',', '2002', ',', '11:51', 'GMT', '12:51', 'UK', 'Blondes', \"'to\", 'die', 'out', 'in', '200', \"years'\", 'Scientists', 'believe', 'the', 'last', 'blondes', 'will', 'be', 'in', 'Finland', 'The', 'last', 'natural', 'blondes', 'will', 'die', 'out', 'within', '200', 'years', ',', 'scientists', 'believe', '.', 'A', 'study', 'by', 'experts', 'in', 'Germany', 'suggests', 'people', 'with', 'blonde', 'hair', 'are', 'an', 'endangered', 'species', 'and', 'will', 'become', 'extinct', 'by', '2202', '.', 'Researchers', 'predict', 'the', 'last', 'truly', 'natural', 'blonde', 'will', 'be', 'born', 'in', 'Finland', '-', 'the', 'country', 'with', 'the', 'highest', 'proportion', 'of', 'blondes', '.', 'The', 'frequency', 'of', 'blondes', 'may', 'drop', 'but', 'they', 'wo', \"n't\", 'disappear', 'Prof', 'Jonathan', 'Rees', ',', 'University', 'of', 'Edinburgh', 'But', 'they', 'say', 'too', 'few', 'people', 'now', 'carry', 'the', 'gene', 'for', 'blondes', 'to', 'last', 'beyond', 'the', 'next', 'two', 'centuries', '.', 'The', 'problem', 'is', 'that', 'blonde', 'hair', 'is', 'caused', 'by', 'a', 'recessive', 'gene', '.', 'In', 'order', 'for', 'a', 'child', 'to', 'have', 'blonde', 'hair', ',', 'it', 'must', 'have', 'the', 'gene', 'on', 'both', 'sides', 'of', 'the', 'family', 'in', 'the', 'grandparents', \"'\", 'generation', '.', 'Dyed', 'rivals', 'The', 'researchers', 'also', 'believe', 'that', 'so-called', 'bottle', 'blondes', 'may', 'be', 'to', 'blame', 'for', 'the', 'demise', 'of', 'their', 'natural', 'rivals', '.', 'They', 'suggest', 'that', 'dyed-blondes', 'are', 'more', 'attractive', 'to', 'men', 'who', 'choose', 'them', 'as', 'partners', 'over', 'true', 'blondes', '.', 'Bottle-blondes', 'like', 'Ann', 'Widdecombe', 'may', 'be', 'to', 'blame', 'But', 'Jonathan', 'Rees', ',', 'professor', 'of', 'dermatology', 'at', 'the', 'University', 'of', 'Edinburgh', 'said', 'it', 'was', 'unlikely', 'blondes', 'would', 'die', 'out', 'completely', '.', '``', 'Genes', 'do', \"n't\", 'die', 'out', 'unless', 'there', 'is', 'a', 'disadvantage', 'of', 'having', 'that', 'gene', 'or', 'by', 'chance', '.', 'They', 'do', \"n't\", 'disappear', ',', \"''\", 'he', 'told', 'BBC', 'News', 'Online', '.', '``', 'The', 'only', 'reason', 'blondes', 'would', 'disappear', 'is', 'if', 'having', 'the', 'gene', 'was', 'a', 'disadvantage', 'and', 'I', 'do', 'not', 'think', 'that', 'is', 'the', 'case', '.', '``', 'The', 'frequency', 'of', 'blondes', 'may', 'drop', 'but', 'they', 'wo', \"n't\", 'disappear', '.', \"''\", 'See', 'also', ':', '28', 'Mar', '01', '|', 'Education', 'What', 'is', 'it', 'about', 'blondes', '?', '09', 'Apr', '99', '|', 'Health', 'Platinum', 'blondes', 'are', 'labelled', 'as', 'dumb', '17', 'Apr', '02', '|', 'Health', 'Hair', 'dye', 'cancer', 'alert', 'Internet', 'links', ':', 'University', 'of', 'Edinburgh', 'The', 'BBC', 'is', 'not', 'responsible', 'for', 'the', 'content', 'of', 'external', 'internet', 'sites', 'Top', 'Health', 'stories', 'now', ':', 'Heart', 'risk', 'link', 'to', 'big', 'families', 'Back', 'pain', 'drug', \"'may\", 'aid', \"diabetics'\", 'Congo', 'Ebola', 'outbreak', 'confirmed', 'Vegetables', 'ward', 'off', \"Alzheimer's\", 'Polio', 'campaign', 'launched', 'in', 'Iraq', 'Gene', 'defect', 'explains', 'high', 'blood', 'pressure', 'Botox', \"'may\", 'cause', 'new', \"wrinkles'\", 'Alien', \"'abductees\", \"'\", 'show', 'real', 'symptoms', 'Links', 'to', 'more', 'Health', 'stories', 'are', 'at', 'the', 'foot', 'of', 'the', 'page', '.', 'E-mail', 'this', 'story', 'to', 'a', 'friend', 'Links', 'to', 'more', 'Health', 'stories', 'In', 'This', 'Section', 'Heart', 'risk', 'link', 'to', 'big', 'families', 'Back', 'pain', 'drug', \"'may\", 'aid', \"diabetics'\", 'Congo', 'Ebola', 'outbreak', 'confirmed', 'Vegetables', 'ward', 'off', \"Alzheimer's\", 'Polio', 'campaign', 'launched', 'in', 'Iraq', 'Gene', 'defect', 'explains', 'high', 'blood', 'pressure', 'Botox', \"'may\", 'cause', 'new', \"wrinkles'\", 'Alien', \"'abductees\", \"'\", 'show', 'real', 'symptoms', 'How', 'sperm', 'wriggle', 'Bollywood', 'told', 'to', 'stub', 'it', 'out', 'Fears', 'over', 'tuna', 'health', 'risk', 'to', 'babies', 'Public', 'can', 'be', 'taught', 'to', 'spot', 'strokes', '^^', 'Back', 'to', 'top', 'News', 'Front', 'Page', '|', 'Africa', '|', 'Americas', '|', 'Asia-Pacific', '|', 'Europe', '|', 'Middle', 'East', '|', 'South', 'Asia', '|', 'UK', '|', 'Business', '|', 'Entertainment', '|', 'Science/Nature', '|', 'Technology', '|', 'Health', '|', 'Talking', 'Point', '|', 'Country', 'Profiles', '|', 'In', 'Depth', '|', 'Programmes', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', 'To', 'BBC', 'Sport', '>', '>', '|', 'To', 'BBC', 'Weather', '>', '>', '|', 'To', 'BBC', 'World', 'Service', '>', '>', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '©', 'MMIII', '|', 'News', 'Sources', '|', 'Privacy']"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "raw = BeautifulSoup(html, 'html.parser').get_text()\n",
    "tokens = word_tokenize(raw)\n",
    "print(tokens, end = '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Using trial and error to find the start/finish of the text.  Again, the indices given in the book are not correct.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 5 matches:\n",
      "hey say too few people now carry the gene for blondes to last beyond the next \n",
      "blonde hair is caused by a recessive gene . In order for a child to have blond\n",
      " have blonde hair , it must have the gene on both sides of the family in the g\n",
      "ere is a disadvantage of having that gene or by chance . They do n't disappear\n",
      "des would disappear is if having the gene was a disadvantage and I do not thin\n"
     ]
    }
   ],
   "source": [
    "tokens = tokens[111:403]\n",
    "text = nltk.Text(tokens)\n",
    "text.concordance('gene')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Processing Search Engine Results\n",
    "\n",
    "*__Your Turn__: Search the web for `\"the of\"` (inside quotes). Based on the large count, can we conclude that the of is a frequent collocation in English?*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I got 165,000,000 results, which of course would be different than the number that the authors got while they were writing the book.*\n",
    "\n",
    "*Despite the high number, it would be very wrong to assume \"the of\" is a common English collocation.  A large percentage of the hits were the result of transposition errors in the text: e.g. someone might type \"the of point this...\" when they meant to type \"the point of this...\"; another large contingent of results were phrases where 'the' and 'of' were separated by punctuation (e.g., \"the # of\"), which was presumably ignored by the search engine.  However, it has to be said that the vast majority of results did not feature \"the of\" in the summary, leading me to belief that Google does not always look at literal strings (i.e., strings inside quotes) when ranking results.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Processing RSS Feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Language Log'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import feedparser\n",
    "\n",
    "llog = feedparser.parse(\"http://languagelog.ldc.upenn.edu/nll/?feed=atom\")\n",
    "llog['feed']['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(llog.entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI without human oversight'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post = llog.entries[2]\n",
    "post.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<p>Despite the panic over AI we're seeing in many sectors of society, \""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = post.content[0].value\n",
    "content[:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Despite', 'the', 'panic', 'over', 'AI', 'we', \"'re\", 'seeing', 'in', 'many', 'sectors', 'of', 'society', ',', 'including', 'academia', ',', 'the', 'juggernaut', 'rolls', 'on', ',', 'seeming', 'set', 'to', 'crush', 'everything', 'in', 'its', 'way', ':', \"''\", 'EU', 'gives', 'more', 'power', 'to', 'AI', 'translation', 'machines', \"''\", 'The', 'European', 'Commission', 'has', 'launched', 'a', 'pilot', 'project', 'to']"
     ]
    }
   ],
   "source": [
    "raw = BeautifulSoup(content, 'html.parser').get_text()\n",
    "print(word_tokenize(raw)[:50], end = '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading Local Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mUsers\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mmjcor\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mDesktop\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mProgrammingStuff\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mnltk\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m os\u001b[39m.\u001b[39;49mchdir(path)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# path = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\"\n",
    "# os.chdir(path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Your Turn:__ Create a file called `document.txt` using a text editor, and type in a few lines of text, and save it as plain text. If you are using IDLE, select the __New Window__ command in the File menu, typing the required text into this window, and then saving the file as `document.txt` inside the directory that IDLE offers in the pop-up dialogue box. Next, in the Python interpreter, open the file using `f = open('document.txt')`, then inspect its contents using `print(f.read())`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dddd\n"
     ]
    }
   ],
   "source": [
    "f = open('data/doc.txt')\n",
    "print(f.read())\n",
    "\n",
    "# f = open('document.txt', 'rU')\n",
    "# for line in f:\n",
    "#     print line.strip()\n",
    "\n",
    "# path = nltk.data.find('corpora/gutenberg/melville-moby_dick.txt')\n",
    "# raw = open(path, 'rU').read()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting Text from PDF, MSWord and other Binary Formats\n",
    "\n",
    "*__No notes__*\n",
    "\n",
    "##### Capturing User Input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = input(\"Enter some text: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You typed 3 words.\n"
     ]
    }
   ],
   "source": [
    "print(\"You typed\", len(word_tokenize(s)), \"words.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*It seems the `?` was tokenized and counted as a word.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\pipeline1.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m display, Image\n\u001b[1;32m----> 3\u001b[0m display(Image(filename \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mC:\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mUsers\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mmjcor\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mDesktop\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mProgrammingStuff\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mnltk\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mpipeline1.png\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\display.py:970\u001b[0m, in \u001b[0;36mImage.__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munconfined \u001b[39m=\u001b[39m unconfined\n\u001b[0;32m    969\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malt \u001b[39m=\u001b[39m alt\n\u001b[1;32m--> 970\u001b[0m \u001b[39msuper\u001b[39;49m(Image, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(data\u001b[39m=\u001b[39;49mdata, url\u001b[39m=\u001b[39;49murl, filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[0;32m    971\u001b[0m         metadata\u001b[39m=\u001b[39;49mmetadata)\n\u001b[0;32m    973\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mwidth\u001b[39m\u001b[39m'\u001b[39m, {}):\n\u001b[0;32m    974\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth \u001b[39m=\u001b[39m metadata[\u001b[39m'\u001b[39m\u001b[39mwidth\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\display.py:327\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 327\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreload()\n\u001b[0;32m    328\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_data()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\display.py:1005\u001b[0m, in \u001b[0;36mImage.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed:\n\u001b[1;32m-> 1005\u001b[0m     \u001b[39msuper\u001b[39;49m(Image,\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mreload()\n\u001b[0;32m   1006\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretina:\n\u001b[0;32m   1007\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retina_shape()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\display.py:353\u001b[0m, in \u001b[0;36mDisplayObject.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     encoding \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_flags \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 353\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilename, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_flags, encoding\u001b[39m=\u001b[39;49mencoding) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    354\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[0;32m    355\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m     \u001b[39m# Deferred import\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\pipeline1.png'"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(filename = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\pipeline1.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw = open('document.txt').read()\n",
    "# print(type(raw))\n",
    "# When we tokenize a string we produce a list (of words), and this is Python’s <list> type. Normalizing and sorting lists produces other lists:\n",
    "# tokens = nltk.word_tokenize(raw)\n",
    "# print(type(tokens))\n",
    "# words = [w.lower() for w in tokens]\n",
    "# print(type(words))\n",
    "# vocab = sorted(set(words))\n",
    "# print(type(vocab))\n",
    "\n",
    "# vocab.append('blog')\n",
    "# raw.append('blog') # causes error\n",
    "\n",
    "# # Similarly, we can concatenate strings with strings, and lists with lists, but we cannot concatenate strings with lists:\n",
    "# query = 'Who knows?'\n",
    "# beatles = ['john', 'paul', 'george', 'ringo']\n",
    "# query + beatles\n",
    "# # Traceback (most recent call last):\n",
    "# # File \"<stdin>\", line 1, in <module>\n",
    "# # TypeError: cannot concatenate 'str' and 'list' objects"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Strings: Text Processing at the Lowest Level\n",
    "\n",
    "##### Basic Operations with Strings\n",
    "\n",
    "*Use `\\` or `( )` to extend a string over several lines:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monty Python\n",
      "Monty Python's Flying Circus\n",
      "Monty Python's Flying Circus\n",
      "When I was a little bitty boyMy grandmother bought me a cute little toy\n"
     ]
    }
   ],
   "source": [
    "monty = 'Monty Python'\n",
    "print(monty)\n",
    "circus = \"Monty Python's Flying Circus\"\n",
    "print(circus)\n",
    "circus = 'Monty Python\\'s Flying Circus'\n",
    "print(circus)\n",
    "# circus = 'Monty Python's Flying Circus'\n",
    "# File \"<stdin>\", line 1\n",
    "# circus = 'Monty Python's Flying Circus'\n",
    "\n",
    "couplet =   \"When I was a little bitty boy\" \\\n",
    "            \"My grandmother bought me a cute little toy\" \n",
    "print(couplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silver bells hanging on a stringShe told me it was my ding-a-ling-a-ling\n"
     ]
    }
   ],
   "source": [
    "couplet =   (\"Silver bells hanging on a string\" \n",
    "            \"She told me it was my ding-a-ling-a-ling\")\n",
    "\n",
    "print(couplet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*To get a newline between the lines we should use a triple-quoted string:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You know, then mama took me to Sunday school\n",
      "They tried to teach me the golden rule\n"
     ]
    }
   ],
   "source": [
    "couplet = \"\"\"You know, then mama took me to Sunday school\n",
    "They tried to teach me the golden rule\"\"\"\n",
    "print(couplet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>__Your Turn__: Try running the following code, then try to use your understanding of the string `+` and `*` operations to figure out how it works. Be careful to distinguish between the string `' '`, which is a single whitespace character, and `''`, which is the empty string.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "veryveryvery\n",
      "veryveryvery\n",
      "            very\n",
      "          veryvery\n",
      "        veryveryvery\n",
      "      veryveryveryvery\n",
      "    veryveryveryveryvery\n",
      "  veryveryveryveryveryvery\n",
      "veryveryveryveryveryveryvery\n",
      "  veryveryveryveryveryvery\n",
      "    veryveryveryveryvery\n",
      "      veryveryveryvery\n",
      "        veryveryvery\n",
      "          veryvery\n",
      "            very\n"
     ]
    }
   ],
   "source": [
    "print('very' * 3)\n",
    "print('very' + 'very' + 'very')\n",
    "\n",
    "a = [1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2, 1]\n",
    "b = [' ' * 2 * (7 - i) + 'very' * i for i in a]\n",
    "for line in b:\n",
    "     print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'very' - 'y'\n",
    "# Traceback (most recent call last):\n",
    "# File \"<stdin>\", line 1, in <module>\n",
    "# TypeError: unsupported operand type(s) for -: 'str' and 'str'\n",
    "# 'very' / 2\n",
    "# Traceback (most recent call last):\n",
    "# File \"<stdin>\", line 1, in <module>\n",
    "# TypeError: unsupported operand type(s) for /: 'str' and 'int'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Printing Strings\n",
    "\n",
    "*__No notes.__*\n",
    "\n",
    "##### Accessing Individual Characters\n",
    "\n",
    "*Frequency Distribution of individual characters in a text:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monty PythonHoly Grail\n",
      "Monty Python Holy Grail\n",
      "Monty Python and the Holy Grail\n",
      "M\n",
      "t\n",
      " \n",
      "n\n",
      " \n",
      " \n",
      "colorless green ideas sleep furiously"
     ]
    }
   ],
   "source": [
    "monty = 'Monty Python'\n",
    "grail = 'Holy Grail'\n",
    "print(monty + grail)\n",
    "print(monty, grail)\n",
    "print(monty, \"and the\", grail)\n",
    "\n",
    "print(monty[0])\n",
    "print(monty[3])\n",
    "print(monty[5])\n",
    "# print(monty[20]) # causes error\n",
    "\n",
    "print(monty[-1])\n",
    "print(monty[5])\n",
    "print(monty[-7])\n",
    "\n",
    "sent = 'colorless green ideas sleep furiously'\n",
    "for char in sent:\n",
    "    print(char, end = '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('e', 117092), ('t', 87996), ('a', 77916), ('o', 69326), ('n', 65617)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "raw = gutenberg.raw('melville-moby_dick.txt')\n",
    "fdist = nltk.FreqDist(ch.lower() for ch in raw if ch.isalpha())\n",
    "fdist.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e', 't', 'a', 'o', 'n', 'i', 's', 'h', 'r', 'l', 'd', 'u', 'm', 'c', 'w', 'f', 'g', 'p', 'b', 'y', 'v', 'k', 'q', 'j', 'x', 'z']"
     ]
    }
   ],
   "source": [
    "print([char for (char, count) in fdist.most_common()], end = '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*As a plot:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "fdist.plot(cumulative = True);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accessing Substrings\n",
    "\n",
    "*__Your Turn__: Make up a sentence and assign it to a variable, e.g. `sent = 'my sentence...'`. Now write slice expressions to pull out individual words. (This is obviously not a convenient way to process the words of a text!)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pyth\n",
      "Monty\n",
      "Monty\n",
      "Python\n"
     ]
    }
   ],
   "source": [
    "print(monty[6:10])\n",
    "print(monty[-12:-7])\n",
    "print(monty[:5])\n",
    "print(monty[6:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \n",
      "cut\n",
      "down\n",
      "trees,\n",
      "I\n",
      "eat\n",
      "my\n",
      "lunch,\n",
      "I\n",
      "go\n",
      "to\n",
      "the\n",
      "lavatory.\n",
      "On\n",
      "Wednesdays\n",
      "I\n",
      "go\n",
      "shopping,\n",
      "and\n",
      "have\n",
      "buttered\n",
      "scones\n",
      "for\n",
      "tea.\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sent = \"I cut down trees, I eat my lunch, I go to the lavatory. \" \\\n",
    "       \"On Wednesdays I go shopping, and have buttered scones for tea.\"\n",
    "\n",
    "spaces = []\n",
    "for ch in range(len(sent)):\n",
    "    if sent[ch] == \" \":\n",
    "        spaces.append(ch)\n",
    "        \n",
    "spaces.append(len(sent))\n",
    "\n",
    "print(sent[0:2])\n",
    "\n",
    "for s in range(len(spaces) - 1):\n",
    "    print(sent[spaces[s] + 1:spaces[s + 1]])\n",
    "\n",
    "print(sent.find(\"shopping\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### More operations on strings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|       Method      |                            Functionality                            |\n",
    "|:------------------|:--------------------------------------------------------------------|\n",
    "| `s.find(t)`       | index of first instance of   string `t` inside `s` (`-1` if not found)    |\n",
    "| `s.rfind(t)`      | index of last instance of   string `t` inside `s` (`-1` if not found)     |\n",
    "| `s.index(t)`      | like `s.find(t)` except it raises `ValueError` if not   found           |\n",
    "| `s.rindex(t)`     | like `s.rfind(t)` except it raises `ValueError` if not   found          |\n",
    "| `s.join(text)`    | combine the words of the text into a string using `s` as the glue     |\n",
    "| `s.split(t)`      | split `s` into a list wherever a `t` is found (whitespace   by default) |\n",
    "| `s.splitlines()`  | split `s` into a list of strings, one per line                        |\n",
    "| `s.lower()`       | a lowercased version of the string `s`                                |\n",
    "| `s.upper()`       | an uppercased version of the string `s`                               |\n",
    "| `s.title()`       | a titlecased version of the string `s`                                |\n",
    "| `s.strip()`       | a copy of `s` without leading or trailing whitespace                  |\n",
    "| `s.replace(t, u)` | replace instances of `t` with `u` inside `s`                              |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Difference between Lists and Strings\n",
    "\n",
    "*__No Notes.__*\n",
    "\n",
    "#### 3.3 Text Processing with Unicode\n",
    "\n",
    "##### What is Unicode?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\unicode.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m display(Image(filename \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mC:\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mUsers\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mmjcor\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mDesktop\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mProgrammingStuff\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mnltk\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39municode.png\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\display.py:970\u001b[0m, in \u001b[0;36mImage.__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munconfined \u001b[39m=\u001b[39m unconfined\n\u001b[0;32m    969\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malt \u001b[39m=\u001b[39m alt\n\u001b[1;32m--> 970\u001b[0m \u001b[39msuper\u001b[39;49m(Image, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(data\u001b[39m=\u001b[39;49mdata, url\u001b[39m=\u001b[39;49murl, filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[0;32m    971\u001b[0m         metadata\u001b[39m=\u001b[39;49mmetadata)\n\u001b[0;32m    973\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mwidth\u001b[39m\u001b[39m'\u001b[39m, {}):\n\u001b[0;32m    974\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth \u001b[39m=\u001b[39m metadata[\u001b[39m'\u001b[39m\u001b[39mwidth\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\display.py:327\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 327\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreload()\n\u001b[0;32m    328\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_data()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\display.py:1005\u001b[0m, in \u001b[0;36mImage.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed:\n\u001b[1;32m-> 1005\u001b[0m     \u001b[39msuper\u001b[39;49m(Image,\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mreload()\n\u001b[0;32m   1006\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretina:\n\u001b[0;32m   1007\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retina_shape()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\display.py:353\u001b[0m, in \u001b[0;36mDisplayObject.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     encoding \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_flags \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 353\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilename, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_flags, encoding\u001b[39m=\u001b[39;49mencoding) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    354\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[0;32m    355\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m     \u001b[39m# Deferred import\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\unicode.png'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "display(Image(filename = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\unicode.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o\n",
      "George\n",
      "Wh\n",
      "['John', 'Paul']\n",
      "Who knows? I don't\n",
      "['John', 'Paul', 'George', 'Ringo', 'Brian']\n"
     ]
    }
   ],
   "source": [
    "# The difference Between Lists and Strings\n",
    "query = 'Who knows?'\n",
    "beatles = ['John', 'Paul', 'George', 'Ringo']\n",
    "print(query[2])\n",
    "print(beatles[2])\n",
    "print(query[:2])\n",
    "print(beatles[:2])\n",
    "print(query + \" I don't\")\n",
    "# print(beatles + 'Brian') # causes error\n",
    "print(beatles + ['Brian'])\n",
    "\n",
    "beatles[0] = 'John Lennon'\n",
    "print(beatles)\n",
    "del beatles[-1]\n",
    "print(beatles)\n",
    "\n",
    "# Strings are immutable\n",
    "query[0] = 'F'\n",
    "# Traceback (most recent call last):\n",
    "# File \"<stdin>\", line 1, in <module>\n",
    "# TypeError: 'str' object does not support item assignment\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting encoded text from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = nltk.data.find('corpora/unicode_samples/polish-lat2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruska Biblioteka Państwowa. Jej dawne zbiory znane pod nazwą\n",
      "\"Berlinka\" to skarb kultury i sztuki niemieckiej. Przewiezione przez\n",
      "Niemców pod koniec II wojny światowej na Dolny Śląsk, zostały\n",
      "odnalezione po 1945 r. na terytorium Polski. Trafiły do Biblioteki\n",
      "Jagiellońskiej w Krakowie, obejmują ponad 500 tys. zabytkowych\n",
      "archiwaliów, m.in. manuskrypty Goethego, Mozarta, Beethovena, Bacha.\n"
     ]
    }
   ],
   "source": [
    "f = open(path, encoding = 'latin2')\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    print(line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Converting all non-ASCII characters into two-digit \\xXX and four-digit \\uXXXX representations:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Pruska Biblioteka Pa\\\\u0144stwowa. Jej dawne zbiory znane pod nazw\\\\u0105'\n",
      "b'\"Berlinka\" to skarb kultury i sztuki niemieckiej. Przewiezione przez'\n",
      "b'Niemc\\\\xf3w pod koniec II wojny \\\\u015bwiatowej na Dolny \\\\u015al\\\\u0105sk, zosta\\\\u0142y'\n",
      "b'odnalezione po 1945 r. na terytorium Polski. Trafi\\\\u0142y do Biblioteki'\n",
      "b'Jagiello\\\\u0144skiej w Krakowie, obejmuj\\\\u0105 ponad 500 tys. zabytkowych'\n",
      "b'archiwali\\\\xf3w, m.in. manuskrypty Goethego, Mozarta, Beethovena, Bacha.'\n",
      "<codecs.StreamReaderWriter object at 0x00000193558A63E0>\n"
     ]
    }
   ],
   "source": [
    "f = open(path, encoding = 'latin2')\n",
    "for line in f:\n",
    "    line = line.strip()\n",
    "    print(line.encode('unicode_escape'))\n",
    "\n",
    "import codecs\n",
    "ff = codecs.open(path, encoding='latin2')\n",
    "print(ff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Getting the integer ordinal of a character:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('ń')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Converting hexadecimal to 4 digit notation:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0x144'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(324)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Print 4 digit notation:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ń'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nacute = '\\u0144'\n",
    "nacute"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*To see the representation of bytes:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xc5\\x84'\n",
      "b'\\xc5\\x84'\n",
      "b'\\xc5\\x84'\n",
      "ń\n"
     ]
    }
   ],
   "source": [
    "print(nacute.encode('utf8'))\n",
    "nacute_utf = nacute.encode('utf8')\n",
    "print(nacute_utf)\n",
    "print(repr(nacute_utf))\n",
    "print(nacute_utf.decode('utf8'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We can use the module `unicodedata` to inspect the properties of Unicode characters.  Here are the Polish characters outside the ASCII range in the text above:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Niemc\\\\xf3w pod koniec II wojny \\\\u015bwiatowej na Dolny \\\\u015al\\\\u0105sk, zosta\\\\u0142y\\\\n'\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "lines = open(path, encoding = 'latin2').readlines()\n",
    "line = lines[2]\n",
    "print(line.encode('unicode_escape'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xc3\\xb3' U+00f3 LATIN SMALL LETTER O WITH ACUTE\n",
      "b'\\xc5\\x9b' U+015b LATIN SMALL LETTER S WITH ACUTE\n",
      "b'\\xc5\\x9a' U+015a LATIN CAPITAL LETTER S WITH ACUTE\n",
      "b'\\xc4\\x85' U+0105 LATIN SMALL LETTER A WITH OGONEK\n",
      "b'\\xc5\\x82' U+0142 LATIN SMALL LETTER L WITH STROKE\n"
     ]
    }
   ],
   "source": [
    "for c in line:\n",
    "    if ord(c) > 127:\n",
    "        print(\"{} U+{:04x} {}\".format(c.encode('utf8'), ord(c), unicodedata.name(c)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*With UTF-8:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ó U+00f3 LATIN SMALL LETTER O WITH ACUTE\n",
      "ś U+015b LATIN SMALL LETTER S WITH ACUTE\n",
      "Ś U+015a LATIN CAPITAL LETTER S WITH ACUTE\n",
      "ą U+0105 LATIN SMALL LETTER A WITH OGONEK\n",
      "ł U+0142 LATIN SMALL LETTER L WITH STROKE\n"
     ]
    }
   ],
   "source": [
    "for c in line:\n",
    "    if ord(c) > 127:\n",
    "        print(\"{} U+{:04x} {}\".format(c, ord(c), unicodedata.name(c)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Using `re` with Unicode characters:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line.find('zosta\\u0142y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'niemców pod koniec ii wojny światowej na dolny śląsk, zostały\\n'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = line.lower()\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'niemc\\\\xf3w pod koniec ii wojny \\\\u015bwiatowej na dolny \\\\u015bl\\\\u0105sk, zosta\\\\u0142y\\\\n'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line.encode('unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'światowej'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = re.search('\\u015b\\w*', line)\n",
    "m.group()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NLTK tokenizers also work with Unicode strings:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['niemców', 'pod', 'koniec', 'ii', 'wojny', 'światowej', 'na', 'dolny', 'śląsk', ',', 'zostały']"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(line), end = '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using your local encoding in Python\n",
    "\n",
    "*__No notes.__*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4   Regular Expressions for Detecting Word Patterns\n",
    "\n",
    "*We'll use the Words Corpus, but we need to remove proper names:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = [w for w in nltk.corpus.words.words('en') if w.lower()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Basic Meta-Characters\n",
    "\n",
    "*Using RegEx to find the first fify words ending with __ed__:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abaissed', 'abandoned', 'abased', 'abashed', 'abatised', 'abed', 'aborted', 'abridged', 'abscessed', 'absconded', 'absorbed', 'abstracted', 'abstricted', 'accelerated', 'accepted', 'accidented', 'accoladed', 'accolated', 'accomplished', 'accosted', 'accredited', 'accursed', 'accused', 'accustomed', 'acetated', 'acheweed', 'aciculated', 'aciliated', 'acknowledged', 'acorned', 'acquainted', 'acquired', 'acquisited', 'acred', 'aculeated', 'addebted', 'added', 'addicted', 'addlebrained', 'addleheaded', 'addlepated', 'addorsed', 'adempted', 'adfected', 'adjoined', 'admired', 'admitted', 'adnexed', 'adopted', 'adossed']"
     ]
    }
   ],
   "source": [
    "print([w for w in wordlist if re.search('ed$', w)][:50], end = '')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Using `.` as a __wildcard__ to find 8-letter words whose respective third and sixth letters are __j__ and __t__:* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abjectly', 'adjuster', 'dejected', 'dejectly', 'injector', 'majestic', 'objectee', 'objector', 'rejecter', 'rejector', 'unjilted', 'unjolted', 'unjustly']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in wordlist if re.search('^..j..t..$', w)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Your Turn:__ The caret symbol `^` matches the start of a string, just like the `$` matches the end. What results do we get with the above example if we leave out both of these, and search for `«..j..t..»`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abjectedness', 'abjection', 'abjective', 'abjectly', 'abjectness', 'adjection', 'adjectional', 'adjectival', 'adjectivally', 'adjective', 'adjectively', 'adjectivism', 'adjectivitis', 'adjustable', 'adjustably', 'adjustage', 'adjustation', 'adjuster', 'adjustive', 'adjustment', 'antejentacular', 'antiprojectivity', 'bijouterie', 'coadjustment', 'cojusticiar', 'conjective', 'conjecturable', 'conjecturably', 'conjectural', 'conjecturalist', 'conjecturality', 'conjecturally', 'conjecture', 'conjecturer', 'coprojector', 'counterobjection', 'dejected', 'dejectedly', 'dejectedness', 'dejectile', 'dejection', 'dejectly', 'dejectory', 'dejecture', 'disjection', 'guanajuatite', 'inadjustability', 'inadjustable', 'injectable', 'injection']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in wordlist if re.search('..j..t..', w)][:50])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The result will be all words of at least eight letters with at least two letters before a __j__, two additional letters, a __t__, and at least two more letters.*\n",
    "\n",
    "*The `?` means the preceding character is optional.  The following code will find all the words with __judg__ or __judge__ in the wordlist:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abjudge', 'adjudge', 'adjudgeable', 'adjudger', 'adjudgment', 'cojudge', 'counterjudging', 'forejudge', 'forejudgment', 'forjudge', 'forjudger', 'interjudgment', 'judge', 'judgeable', 'judgelike', 'judger', 'judgeship', 'judgingly', 'judgmatic', 'judgmatical', 'judgmatically', 'judgment', 'misjudge', 'misjudgement', 'misjudger', 'misjudgingly', 'misjudgment', 'overjudge', 'overjudging', 'overjudgment', 'prejudge', 'prejudgement', 'prejudger', 'prejudgment', 'rejudge', 'stockjudging', 'subjudge', 'unadjudged', 'underjudge', 'unjudgable', 'unjudge', 'unjudged', 'unjudgelike', 'unjudging', 'unprejudged']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in wordlist if re.search('judge?', w)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ranges and Closures\n",
    "\n",
    "*The T9 system of entering text on older mobile phones:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\T9.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m display(Image(filename \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mC:\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mUsers\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mmjcor\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mDesktop\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mProgrammingStuff\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mnltk\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mT9.png\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\display.py:970\u001b[0m, in \u001b[0;36mImage.__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munconfined \u001b[39m=\u001b[39m unconfined\n\u001b[0;32m    969\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malt \u001b[39m=\u001b[39m alt\n\u001b[1;32m--> 970\u001b[0m \u001b[39msuper\u001b[39;49m(Image, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(data\u001b[39m=\u001b[39;49mdata, url\u001b[39m=\u001b[39;49murl, filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[0;32m    971\u001b[0m         metadata\u001b[39m=\u001b[39;49mmetadata)\n\u001b[0;32m    973\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mwidth\u001b[39m\u001b[39m'\u001b[39m, {}):\n\u001b[0;32m    974\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth \u001b[39m=\u001b[39m metadata[\u001b[39m'\u001b[39m\u001b[39mwidth\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\display.py:327\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 327\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreload()\n\u001b[0;32m    328\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_data()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\display.py:1005\u001b[0m, in \u001b[0;36mImage.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed:\n\u001b[1;32m-> 1005\u001b[0m     \u001b[39msuper\u001b[39;49m(Image,\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mreload()\n\u001b[0;32m   1006\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretina:\n\u001b[0;32m   1007\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retina_shape()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\display.py:353\u001b[0m, in \u001b[0;36mDisplayObject.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     encoding \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_flags \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 353\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilename, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_flags, encoding\u001b[39m=\u001b[39;49mencoding) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    354\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[0;32m    355\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m     \u001b[39m# Deferred import\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\T9.png'"
     ]
    }
   ],
   "source": [
    "display(Image(filename = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\T9.png\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finding words that could have been written with the sequence 4653:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gold', 'golf', 'hold', 'hole']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in wordlist if re.search('^[ghi][mno][jkl][def]$', w)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Your Turn:__ Look for some \"finger-twisters\", by searching for words that only use part of the number-pad. For example `«^[ghijklmno]+$»`, or more concisely, `«^[g-o]+$»`, will match words that only use keys 4, 5, 6 in the center row, and `«^[a-fj-o]+$»` will match words that use keys 2, 3, 5, 6 in the top-right corner. What do `-` and `+` mean?*\n",
    "\n",
    "*`-` is used for a range of letters: e.g., `a-d` would be the same as `abcd`; `+` means 1 or more of the previous: e.g., `[a-c]+` would be one or more of any combination of the letters `a`, `b`, and `c`.*\n",
    "\n",
    "*I tried to automate as much as possible with iterators.  Detailed notes are above the code in the cell below;*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['miiiiiiiiiiiiinnnnnnnnnnneeeeeeeeee', 'miiiiiinnnnnnnnnneeeeeeee', 'mine', 'mmmmmmmmiiiiiiiiinnnnnnnnneeeeeeee']\n",
      "['a', 'aaaaaaaaaaaaaaaaa', 'aaahhhh', 'ah', 'ahah', 'ahahah', 'ahh', 'ahhahahaha', 'ahhh', 'ahhhh', 'ahhhhhh', 'ahhhhhhhhhhhhhh', 'h', 'ha', 'haaa', 'hah', 'haha', 'hahaaa', 'hahah', 'hahaha', 'hahahaa', 'hahahah', 'hahahaha', 'hahahahaaa', 'hahahahahaha', 'hahahahahahaha', 'hahahahahahahahahahahahahahahaha', 'hahahhahah', 'hahhahahaha']\n",
      "['0.0085', '0.05', '0.1', '0.16', '0.2', '0.25', '0.28', '0.3', '0.4', '0.5', '0.50', '0.54', '0.56', '0.60', '0.7', '0.82', '0.84', '0.9', '0.95', '0.99', '1.01', '1.1', '1.125', '1.14', '1.1650', '1.17', '1.18', '1.19', '1.2', '1.20', '1.24', '1.25', '1.26', '1.28', '1.35', '1.39', '1.4', '1.457', '1.46', '1.49', '1.5', '1.50', '1.55', '1.56', '1.5755', '1.5805', '1.6', '1.61', '1.637', '1.64', '1.65', '1.7', '1.75', '1.76', '1.8', '1.82', '1.8415', '1.85', '1.8500', '1.9', '1.916', '1.92', '10.19', '10.2', '10.5', '107.03', '107.9', '109.73', '11.10', '11.5', '11.57', '11.6', '11.72', '11.95', '112.9', '113.2', '116.3', '116.4', '116.7', '116.9', '118.6', '12.09', '12.5', '12.52', '12.68', '12.7', '12.82', '12.97', '120.7', '1206.26', '121.6', '126.1', '126.15', '127.03', '129.91', '13.1', '13.15', '13.5', '13.50', '13.625', '13.65', '13.73', '13.8', '13.90', '130.6', '130.7', '131.01', '132.9', '133.7', '133.8', '14.00', '14.13', '14.26', '14.28', '14.43', '14.5', '14.53', '14.54', '14.6', '14.75', '14.99', '141.9', '142.84', '142.85', '143.08', '143.80', '143.93', '148.9', '149.9', '15.5', '150.00', '153.3', '154.2', '16.05', '16.09', '16.125', '16.2', '16.5', '16.68', '16.7', '16.9', '169.9', '17.3', '17.4', '17.5', '17.95', '1738.1', '176.1', '18.3', '18.6', '18.95', '185.9', '188.84', '19.3', '19.50', '19.6', '19.94', '19.95', '191.9', '2.07', '2.1', '2.15', '2.19', '2.2', '2.25', '2.29', '2.3', '2.30', '2.35', '2.375', '2.4', '2.42', '2.44', '2.46', '2.47', '2.5', '2.50', '2.6', '2.62', '2.65', '2.7', '2.75', '2.8', '2.80', '2.87', '2.875', '2.9', '2.95', '20.07', '20.5', '21.1', '21.9', '2141.7', '2160.1', '2163.2', '22.75', '220.45', '221.4', '225.6', '23.25', '23.4', '23.5', '23.72', '234.4', '236.74', '236.79', '24.95', '25.50', '25.6', '251.2', '26.2', '26.5', '26.8', '263.07', '2645.90', '2691.19', '27.1', '27.4', '273.5', '278.7', '28.25', '28.36', '28.4', '28.5', '28.53', '28.6', '29.3', '29.4', '29.9', '292.32', '3.01', '3.04', '3.1', '3.16', '3.18', '3.19', '3.2', '3.20', '3.23', '3.253', '3.28', '3.3', '3.35', '3.375', '3.4', '3.42', '3.43', '3.5', '3.55', '3.6', '3.61', '3.625', '3.7', '3.75', '3.8', '3.80', '3.9', '30.6', '30.9', '319.75', '32.8', '334.5', '34.625', '341.20', '3436.58', '35.2', '35.7', '352.7', '352.9', '35500.64', '35564.43', '36.9', '361.8', '3648.82', '37.3', '37.5', '372.14', '372.9', '374.19', '374.20', '377.60', '38.3', '38.375', '38.5', '38.875', '387.8', '4.1', '4.10', '4.2', '4.25', '4.3', '4.4', '4.5', '4.55', '4.6', '4.7', '4.75', '4.8', '4.875', '4.898', '4.9', '40.21', '41.60', '415.6', '415.8', '42.1', '42.5', '422.5', '43.875', '434.4', '436.01', '446.62', '449.04', '45.2', '45.3', '45.75', '456.64', '46.1', '47.1', '47.125', '47.5', '47.6', '49.9', '494.50', '497.34', '5.1', '5.2180', '5.276', '5.29', '5.3', '5.39', '5.4', '5.435', '5.5', '5.57', '5.6', '5.63', '5.7', '5.70', '5.8', '5.82', '5.9', '5.92', '50.1', '50.38', '50.45', '51.25', '51.6', '55.1', '566.54', '57.50', '57.6', '57.7', '58.64', '59.6', '59.9', '6.03', '6.1', '6.20', '6.21', '6.25', '6.4', '6.40', '6.44', '6.5', '6.50', '6.53', '6.6', '6.7', '6.70', '6.79', '6.84', '6.9', '60.36', '618.1', '62.1', '62.5', '62.625', '63.79', '630.9', '64.5', '66.5', '7.15', '7.2', '7.20', '7.272', '7.3', '7.4', '7.40', '7.422', '7.45', '7.458', '7.5', '7.50', '7.52', '7.55', '7.60', '7.62', '7.63', '7.65', '7.74', '7.78', '7.79', '7.8', '7.80', '7.84', '7.88', '7.90', '7.95', '70.2', '70.7', '705.6', '72.7', '734.9', '737.5', '77.56', '77.6', '77.70', '8.04', '8.06', '8.07', '8.1', '8.12', '8.14', '8.15', '8.19', '8.2', '8.22', '8.25', '8.30', '8.35', '8.45', '8.467', '8.47', '8.48', '8.5', '8.50', '8.53', '8.55', '8.56', '8.575', '8.60', '8.64', '8.65', '8.70', '8.75', '8.9', '80.50', '80.8', '81.8', '811.9', '83.4', '84.29', '84.9', '85.1', '85.7', '86.12', '87.5', '88.32', '89.7', '89.9', '9.3', '9.32', '9.37', '9.45', '9.5', '9.625', '9.75', '9.8', '9.82', '9.9', '92.9', '93.3', '93.9', '94.2', '94.8', '95.09', '96.4', '98.3', '99.1', '99.3']\n",
      "['C$', 'US$']\n",
      "['1614', '1637', '1787', '1901', '1903', '1917', '1925', '1929', '1933', '1934', '1948', '1953', '1955', '1956', '1961', '1965', '1966', '1967', '1968', '1969', '1970', '1971', '1972', '1973', '1975', '1976', '1977', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986', '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2005', '2009', '2017', '2019', '2029', '3057', '8300']\n",
      "['10-day', '10-lap', '10-year', '100-share', '12-point', '12-year', '14-hour', '15-day', '150-point', '190-point', '20-point', '20-stock', '21-month', '237-seat', '240-page', '27-year', '30-day', '30-point', '30-share', '30-year', '300-day', '36-day', '36-store', '42-year', '50-state', '500-stock', '52-week', '69-point', '84-month', '87-store', '90-day']\n",
      "['62%-owned', 'Absorbed', 'According', 'Adopting', 'Advanced', 'Advancing', 'Alfred', 'Allied', 'Annualized', 'Anything', 'Arbitrage-related', 'Arbitraging', 'Asked', 'Assuming', 'Atlanta-based', 'Baking', 'Banking', 'Beginning', 'Beijing', 'Being', 'Bermuda-based', 'Betting', 'Boeing', 'Broadcasting', 'Bucking', 'Buying', 'Calif.-based', 'Change-ringing', 'Citing', 'Concerned', 'Confronted', 'Conn.based', 'Consolidated', 'Continued', 'Continuing', 'Declining', 'Defending', 'Depending', 'Designated', 'Determining', 'Developed', 'Died', 'During', 'Encouraged', 'Encouraging', 'English-speaking', 'Estimated', 'Everything', 'Excluding', 'Exxon-owned', 'Faulding', 'Fed', 'Feeding', 'Filling', 'Filmed', 'Financing', 'Following', 'Founded', 'Fracturing', 'Francisco-based', 'Fred', 'Funded', 'Funding', 'Generalized', 'Germany-based', 'Getting', 'Guaranteed', 'Having', 'Heating', 'Heightened', 'Holding', 'Housing', 'Illuminating', 'Indeed', 'Indexing', 'Irving', 'Jersey-based', 'Judging', 'Knowing', 'Learning', 'Legislating', 'Leming', 'Limited', 'London-based', 'Manfred', 'Manufacturing', 'Melamed', 'Miami-based', 'Mich.-based', 'Mining', 'Minneapolis-based', 'Mo.-based', 'Mortgage-Backed', 'Moving', 'Muzzling', 'N.J.-based', 'NBC-owned', 'NIH-appointed', 'Named', 'No-Smoking', 'Observing', 'Offering', 'Ohio-based', 'Orleans-based', 'Packaging', 'Performing', 'Philadelphia-based', 'Posted', 'Provided', 'Publishing', 'Purchasing', 'Rated', 'Reached', 'Red', 'Red-blooded', 'Reducing', 'Reed', 'Regarded', 'Rekindled', 'Related', 'Ringing', 'Rolling', 'Sacramento-based', 'Scoring', 'Seattle-based', 'Seed', 'Skilled', 'Smelting', 'Something', 'Spending', 'Standardized', 'Standing', 'Starting', 'Sterling', 'Taking', 'Texas-based', 'Toronto-based', 'Traded', 'Trading', 'Troubled', 'U.N.-supervised', 'U.S.-backed', 'United', 'Used', 'Varying', 'Washington-based', 'Whiting', 'Wilfred', 'Winning', 'Xiaoping', 'York-based', 'Zayed', 'abandoned', 'abating', 'abolishing', 'abortion-related', 'abounding', 'abridging', 'absorbed', 'acceded', 'accelerated', 'accepted', 'accepting', 'according', 'accounted', 'accounting', 'accrued', 'accumulated', 'accused', 'accusing', 'achieved', 'achieving', 'acknowledging', 'acquired', 'acquiring', 'acquisition-minded', 'acted', 'acting', 'adapted', 'adapting', 'added', 'adding', 'addressing', 'adjusted', 'adjusting', 'admitted', 'admitting', 'adopted', 'advanced', 'advancing', 'advertised', 'advertising', 'advised', 'advocated', 'advocating', 'affecting', 'afflicted', 'aggravated', 'agreed', 'agreeing', 'ailing', 'aimed', 'aiming', 'aired', 'airline-related', 'alarmed', 'alienated', 'alleged', 'alleging', 'allocated', 'allowed', 'altered', 'altering', 'amended', 'amending', 'amounted', 'amusing', 'angered', 'announced', 'annoyed', 'annualized', 'answered', 'anti-dumping', 'anticipated', 'anticipating', 'anything', 'apologizing', 'appealing', 'appeared', 'appearing', 'applied', 'appointed', 'approached', 'appropriated', 'approved', 'arched', 'argued', 'arguing', 'arising', 'armed', 'arranged', 'arrested', 'arrived', 'asbestos-related', 'asked', 'asking', 'assassinated', 'assembled', 'asserted', 'asserting', 'assessed', 'assigned', 'assisted', 'associated', 'assumed', 'assuming', 'assured', 'attached', 'attacking', 'attempted', 'attempting', 'attended', 'attending', 'attracted', 'attracting', 'attributed', 'auctioned', 'authorized', 'authorizing', 'automated', 'automotive-lighting', 'averaged', 'averted', 'avoiding', 'awarded', 'awarding', 'backed', 'backing', 'balanced', 'bald-faced', 'balkanized', 'balked', 'balloting', 'bank-backed', 'banking', 'banned', 'banning', 'barking', 'barred', 'based', 'battered', 'battery-operated', 'batting', 'bearing', 'becoming', 'bedding', 'befuddled', 'beginning', 'behaving', 'beheading', 'being', 'beleaguered', 'believed', 'bell-ringing', 'belonging', 'benefited', 'best-selling', 'betting', 'bickering', 'bidding', 'billed', 'billing', 'blamed', 'bled', 'blessing', 'blighted', 'blocked', 'blurred', 'boarding', 'bolstered', 'bombarding', 'booked', 'booming', 'boosted', 'boosting', 'borrowed', 'borrowing', 'botched', 'bothered', 'bounced', 'bowed', 'breaking', 'breathed', 'breathtaking', 'breed', 'bribed', 'bribing', 'briefing', 'brightened', 'bring', 'bringing', 'broad-based', 'broadcasting', 'broadened', 'brokering', 'brushed', 'budding', 'building', 'bundling', 'buoyed', 'burned', 'buying', 'calculated', 'called', 'calling', 'campaigning', 'cancer-causing', 'capitalized', 'capped', 'captivating', 'cared', 'carried', 'carrying', 'cascading', 'casting', 'caused', 'causing', 'cautioned', 'ceiling', 'centralized', 'certified', 'chaired', 'challenging', 'championing', 'change-ringing', 'changed', 'changing', 'characterized', 'characterizing', 'charged', 'charging', 'chastised', 'cheating', 'checking', 'cheerleading', 'chilled', 'choosing', 'chopped', 'circulated', 'cited', 'citing', 'citizen-sparked', 'city-owned', 'claimed', 'claiming', 'clamped', 'clarified', 'clashed', 'classed', 'classified', 'cleaned', 'cleaner-burning', 'cleared', 'clearing', 'clicked', 'climbed', 'climbing', 'clipped', 'clobbered', 'closed', 'closing', 'clothing', 'clouding', 'cluttered', 'co-founded', 'coaching', 'coal-fired', 'coated', 'codified', 'collaborated', 'collapsed', 'collected', 'collecting', 'collective-bargaining', 'colored', 'combined', 'coming', 'commanded', 'commenting', 'committed', 'committing', 'compared', 'compelling', 'competed', 'competing', 'compiled', 'complained', 'complaining', 'completed', 'completing', 'complicated', 'composed', 'composting', 'compressed', 'computer-aided', 'computer-assisted', 'computer-generated', 'computerized', 'computing', 'conceding', 'concentrated', 'concentrating', 'concerned', 'concluded', 'condemned', 'condemning', 'conducted', 'conducting', 'confined', 'confirmed', 'confused', 'connected', 'consented', 'considered', 'considering', 'consisting', 'construed', 'consulting', 'contacted', 'contained', 'containing', 'contesting', 'continued', 'continuing', 'contracted', 'contributed', 'contributing', 'controlled', 'controlling', 'converted', 'converting', 'convicted', 'convinced', 'cooled', 'cooperating', 'copied', 'copying', 'corn-buying', 'corrected', 'correcting', 'cost-cutting', 'cost-sharing', 'counseling', 'counting', 'coupled', 'court-ordered', 'covered', 'covering', 'cranked', 'crashing', 'created', 'creating', 'credit-rating', 'crippled', 'criticized', 'crossed', 'crossing', 'crowded', 'cruising', 'crushed', 'crying', 'cultivated', 'curbed', 'curbing', 'curled', 'current-carrying', 'curtailed', 'cushioned', 'customized', 'cutting', 'damaged', 'damaging', 'dancing', 'darned', 'dashed', 'dating', 'dead-eyed', 'dealing', 'decided', 'declared', 'declaring', 'declined', 'declining', 'decorated', 'decried', 'deducting', 'deemed', 'defeated', 'defended', 'defined', 'defying', 'delayed', 'deliberating', 'delisted', 'delivered', 'delivering', 'demanding', 'demonstrating', 'denied', 'denouncing', 'denying', 'depended', 'depending', 'depleted', 'depressed', 'deprived', 'derived', 'descending', 'described', 'deserving', 'designated', 'designed', 'designing', 'desired', 'despised', 'detailed', 'deteriorated', 'deteriorating', 'determined', 'deterring', 'devastating', 'developed', 'developing', 'devised', 'devoted', 'devouring', 'diagnosed', 'died', 'diluted', 'diming', 'diminished', 'directed', 'directing', 'disaffected', 'disagreed', 'disappointed', 'disappointing', 'disapproved', 'discarded', 'disciplined', 'disclosed', 'disclosing', 'discontinued', 'discontinuing', 'discouraging', 'discovered', 'discussed', 'discussing', 'disembodied', 'dismayed', 'dismissed', 'disposed', 'disputed', 'disseminating', 'distinguished', 'distorted', 'distributed', 'disturbing', 'diversified', 'diversifying', 'divided', 'dividing', 'documented', 'doing', 'doling', 'dollar-denominated', 'dominated', 'dominating', 'doubled', 'doubted', 'downgraded', 'downgrading', 'drafted', 'drawing', 'dreamed', 'dressed', 'drifted', 'drinking', 'driving', 'drooled', 'dropped', 'dubbed', 'duckling', 'dumbfounded', 'dumped', 'during', 'dwindling', 'earned', 'earning', 'eased', 'easing', 'eating', 'echoed', 'edged', 'editing', 'educated', 'elected', 'eliminated', 'eliminating', 'embarrassing', 'embroiled', 'emerged', 'emerging', 'emphasized', 'employed', 'empowered', 'enabled', 'enabling', 'enacted', 'encircling', 'enclosed', 'encouraging', 'encroaching', 'ended', 'ending', 'endorsed', 'engaged', 'engaging', 'engineered', 'engineering', 'enhanced', 'enjoyed', 'enjoying', 'enlarged', 'enraged', 'ensnarled', 'entangled', 'entered', 'entering', 'entertaining', 'enticed', 'entitled', 'entrenched', 'entrusted', 'equaling', 'equipped', 'escalated', 'escaped', 'established', 'establishing', 'estimated', 'evaluated', 'evaluating', 'evaporated', 'evening', 'everything', 'evoking', 'evolved', 'exacerbated', 'examined', 'exceed', 'exceeded', 'exceeding', 'exchanging', 'excited', 'exciting', 'executed', 'executing', 'exercised', 'exerting', 'exhausted', 'exhibited', 'existed', 'existing', 'expanded', 'expanding', 'expected', 'expecting', 'expedited', 'expelled', 'experienced', 'experiencing', 'expired', 'explained', 'explaining', 'exploded', 'export-oriented', 'exposed', 'expressed', 'expressing', 'expunged', 'extended', 'extending', 'exuded', 'eyeing', 'fabled', 'faced', 'facing', 'factoring', 'faded', 'failed', 'failing', 'fainting', 'falling', 'faltered', 'famed', 'family-planning', 'fared', 'fashioned', 'fast-growing', 'fastest-growing', 'fattened', 'favored', 'fawning', 'feared', 'featured', 'featuring', 'fed', 'feed', 'feeling', 'fetching', 'fielded', 'fighting', 'filed', 'filing', 'filled', 'filling', 'finalized', 'financed', 'financing', 'finding', 'fined', 'finished', 'fired', 'firmed', 'fixed', 'fizzled', 'fled', 'fledgling', 'fleeting', 'flirted', 'floated', 'flooded', 'focused', 'focusing', 'folded', 'followed', 'following', 'forced', 'forcing', 'forecasting', 'foreign-led', 'formed', 'forthcoming', 'founded', 'foundering', 'fretted', 'frightened', 'frustrating', 'fueled', 'fueling', 'full-fledged', 'fuming', 'functioning', 'funded', 'funding', 'fundraising', 'futures-related', 'gained', 'gaining', 'galling', 'galvanized', 'gambling', 'gauging', 'generated', 'getting', 'giving', 'going', 'good-hearted', 'good-natured', 'gored', 'government-certified', 'government-funded', 'government-owned', 'graduated', 'granted', 'granting', 'greed', 'gripping', 'growing', 'guaranteed', 'guarding', 'guided', 'gut-wrenching', 'hailed', 'hailing', 'halted', 'hampered', 'handed', 'handled', 'handling', 'happened', 'happening', 'hard-charging', 'hard-drinking', 'hard-hitting', 'harmed', 'harped', 'harvested', 'hauled', 'hauling', 'having', 'headed', 'heading', 'headlined', 'healing', 'hearing', 'heated', 'heating', 'hedging', 'heightened', 'helped', 'helping', 'high-flying', 'high-minded', 'high-polluting', 'high-priced', 'high-rolling', 'high-speed', 'higher-salaried', 'highest-pitched', 'hired', 'hitting', 'holding', 'hoped', 'hosted', 'housing', 'hugging', 'hundred', 'hunted', 'hurting', 'identified', 'ignored', 'ignoring', 'impaired', 'impeding', 'impending', 'implemented', 'implied', 'imported', 'imposed', 'imposing', 'impressed', 'improved', 'improving', 'incentive-backed', 'inched', 'inching', 'included', 'including', 'incorporated', 'increased', 'increasing', 'incurred', 'indeed', 'index-related', 'indicated', 'indicating', 'indulging', 'industrialized', 'industry-supported', 'inflated', 'influenced', 'influencing', 'infringed', 'inherited', 'initialing', 'initiated', 'initiating', 'injecting', 'injuring', 'inkling', 'inquiring', 'inserted', 'insider-trading', 'insinuating', 'insisted', 'inspired', 'installed', 'installing', 'instituted', 'instructed', 'insured', 'integrated', 'intended', 'intentioned', 'interest-bearing', 'interested', 'interesting', 'interrogated', 'interviewed', 'intriguing', 'introduced', 'introducing', 'invented', 'inverted', 'invested', 'investigating', 'investing', 'inviting', 'involved', 'involving', 'issued', 'issuing', 'jeopardizing', 'joined', 'joining', 'judged', 'jumped', 'jumping', 'justified', 'justifying', 'keeping', 'kicked', 'kidnapping', 'killed', 'killing', 'knitted', 'knocked', 'labeled', 'labeling', 'labor-backed', 'lacked', 'lagging', 'land-idling', 'landing', 'lasted', 'lasting', 'lauded', 'laughing', 'launched', 'lawmaking', 'laying', 'leading', 'learned', 'learning', 'leasing', 'leaving', 'led', 'lending', 'lengthened', 'lessening', 'letter-writing', 'letting', 'leveling', 'leveraged', 'leveraging', 'licensed', 'licensing', 'lifted', 'lifting', 'limited', 'limiting', 'limping', 'linked', 'liquidated', 'listed', 'listing', 'living', 'loaded', 'loading', 'located', 'locked', 'long-tenured', 'longstanding', 'looked', 'looking', 'looming', 'losing', 'loved', 'low-priced', 'lower-priced', 'lowered', 'lowering', 'lying', 'machine-gun-toting', 'magnified', 'mailed', 'mailing', 'maintained', 'maintaining', 'making', 'male-dominated', 'managed', 'managing', 'manufactured', 'manufacturing', 'marching', 'market-based', 'market-oriented', 'marketed', 'marketing', 'matched', 'matching', 'materialized', 'mating', 'maturing', 'meaning', 'measured', 'meatpacking', 'medium-sized', 'meeting', 'melt-textured', 'mentioned', 'merchandising', 'merged', 'merger-related', 'midsized', 'milked', 'mind-boggling', 'mining', 'minority-owned', 'minted', 'mired', 'missed', 'mixed', 'mobilizing', 'moderated', 'mollified', 'money-losing', 'monied', 'morale-damaging', 'more-advanced', 'morning', 'mortgage-backed', 'mortgage-based', 'mortgaged', 'mounted', 'moved', 'moving', 'mudslinging', 'muffled', 'mulling', 'multiplying', 'murdered', 'muscling', 'muted', 'muzzling', 'named', 'naming', 'narrowed', 'need', 'needed', 'needing', 'negotiated', 'negotiating', 'neighboring', 'networking', 'newspaper-printing', 'nominated', 'non-encapsulating', 'nonrecurring', 'notched', 'noted', 'nothing', 'noticed', 'noticing', 'notified', 'noting', 'notwithstanding', 'nullified', 'numbered', 'nurtured', 'obligated', 'observed', 'obsessed', 'obtained', 'obtaining', 'occupying', 'occurred', 'odd-sounding', 'offending', 'offered', 'offering', 'offsetting', 'old-fashioned', 'omitted', 'ongoing', 'opened', 'opening', 'operated', 'operating', 'opposed', 'orchestrated', 'ordered', 'ordering', 'organized', 'oriented', 'outdistanced', 'outlawed', 'outlawing', 'outnumbered', 'outpaced', 'outraged', 'outstanding', 'overcrowding', 'overleveraged', 'overpaying', 'overpriced', 'overriding', 'overstated', 'overused', 'overvalued', 'owed', 'owned', 'owning', 'packaging', 'packed', 'painted', 'painting', 'parched', 'parking', 'participated', 'parts-engineering', 'passed', 'passing', 'patented', 'paying', 'peaked', 'pealing', 'peddling', 'pegged', 'pending', 'perceived', 'performed', 'performing', 'permitted', 'permitting', 'phasing', 'photocopying', 'picked', 'picking', 'pinning', 'pitting', 'placed', 'placing', 'plagued', 'planned', 'planning', 'planted', 'planting', 'played', 'playing', 'pleaded', 'pleased', 'pledged', 'plugged', 'plummeted', 'plunged', 'plunging', 'pointed', 'pointing', 'polarized', 'policy-making', 'polled', 'populated', 'portrayed', 'posing', 'positioned', 'possessed', 'post-hearing', 'posted', 'posting', 'postponed', 'poured', 'practiced', 'practicing', 'praised', 'pre-approved', 'pre-cooked', 'pre-existing', 'preapproved', 'predicated', 'predicted', 'predicting', 'preferred', 'prepared', 'presented', 'preserving', 'pressed', 'pressing', 'pressured', 'prevailing', 'preventing', 'price-depressing', 'priced', 'pricing', 'printed', 'privileged', 'processing', 'produced', 'producing', 'profit-taking', 'profited', 'program-trading', 'programming', 'prohibited', 'prohibiting', 'prolonged', 'promised', 'promising', 'promoting', 'prompted', 'propelling', 'proposed', 'proposing', 'prosecuted', 'prosecuting', 'protected', 'protecting', 'protracted', 'proved', 'provided', 'providing', 'proving', 'provoked', 'prying', 'publicized', 'published', 'publishing', 'pulled', 'pulling', 'pumping', 'punishing', 'purchased', 'purchasing', 'purhasing', 'pursued', 'pushed', 'pushing', 'putting', 'puzzled', 'qualified', 'quashing', 'questioned', 'queuing', 'quipped', 'quitting', 'quoted', 'quoting', 'raced', 'racing', 'railing', 'raised', 'raising', 'rallying', 'ranged', 'ranging', 'ranked', 'rarefied', 'raring', 'ratcheting', 'rated', 'ratified', 'rating', 'rationed', 'reached', 'reaching', 'reacted', 'reading', 'reaffirmed', 'realized', 'reallocated', 'reaped', 'reaping', 'reasoning', 'reassuring', 'rebounding', 'rebuffed', 'rebuilding', 'rebuked', 'recalling', 'received', 'receiving', 'recession-inspired', 'reciting', 'reclaimed', 'recognizing', 'recommended', 'recommending', 'record-keeping', 'recorded', 'recouped', 'recovered', 'recovering', 'recruited', 'recruiting', 'rectified', 'recycled', 'red', 'redeemed', 'redeeming', 'redistributing', 'reduced', 'reducing', 'reeling', 'referred', 'referring', 'refitting', 'reflected', 'reflecting', 'refocusing', 'refreshing', 'refunded', 'refunding', 'refused', 'regarded', 'regarding', 'regimented', 'registered', 'regulated', 'regulating', 'reimbursed', 'reinstating', 'rejected', 'related', 'relating', 'relaunched', 'released', 'relegated', 'relied', 'relieved', 'remained', 'remaining', 'remarked', 'reminded', 'remodeling', 'removed', 'removing', 'rendering', 'renewed', 'renewing', 'renovated', 'reopened', 'reorganized', 'repaired', 'replaced', 'replacing', 'replicated', 'replicating', 'reported', 'reporting', 'represented', 'representing', 'repriced', 'requested', 'requesting', 'required', 'requiring', 'rescheduled', 'researching', 'reserved', 'reshaping', 'resigned', 'resigning', 'resisting', 'resolved', 'respected', 'responded', 'responding', 'restored', 'restricting', 'restructured', 'restructuring', 'resulted', 'resulting', 'retailing', 'retained', 'retaining', 'retaliating', 'retired', 'retiring', 'retraced', 'returned', 'returning', 'reversed', 'reviewed', 'reviewing', 'revised', 'revising', 'revived', 'rewarding', 'riding', 'rigged', 'ring', 'ringing', 'rising', 'robbed', 'rolled', 'rolling', 'romanticized', 'rooted', 'ruled', 'ruling', 'rumored', 'running', 'rushed', 'rusted', 'sacked', 'sacrificing', 'safeguarding', 'sagged', 'sagging', 'satisfying', 'saved', 'saving', 'saying', 'scared', 'scaring', 'scattered', 'scheduled', 'school-sponsored', 'scrambled', 'scrambling', 'scrapped', 'screened', 'screwed', 'scrutinizing', 'searched', 'searching', 'seasoned', 'secured', 'securities-based', 'seeing', 'seeking', 'seemed', 'segmenting', 'seized', 'selected', 'self-aggrandizing', 'self-perpetuating', 'self-serving', 'selling', 'sending', 'sentencing', 'served', 'serviced', 'servicing', 'serving', 'setting', 'settled', 'shaded', 'shaping', 'shared', 'shed', 'shedding', 'shipbuilding', 'shipped', 'shipping', 'shirt-sleeved', 'shopped', 'shopping', 'shoring', 'short-lived', 'showed', 'showing', 'shrinking', 'signaling', 'signed', 'signifying', 'signing', 'single-handed', 'singled', 'sitting', 'sketching', 'skidded', 'skilled', 'skipped', 'skyrocketed', 'slashing', 'slated', 'slaying', 'sleeping', 'sliding', 'slipped', 'slowed', 'slowing', 'smattering', 'smoking', 'smothering', 'snaking', 'snapped', 'sneaked', 'so-called', 'soared', 'soaring', 'softening', 'soliciting', 'solved', 'something', 'sometimes-exhausting', 'sophisticated', 'sorting', 'sounded', 'sounding', 'soured', 'sparing', 'sparked', 'sparking', 'speaking', 'specialized', 'specializing', 'specified', 'speculated', 'speculating', 'speed', 'spending', 'spilling', 'spooked', 'sports-oriented', 'spotted', 'sprawling', 'spring', 'spurned', 'spurred', 'spurring', 'sputtered', 'squeezed', 'stabbed', 'stacked', 'stacking', 'staggering', 'standardized', 'standing', 'started', 'starting', 'startling', 'state-appointed', 'state-owned', 'state-supervised', 'stated', 'stayed', 'staying', 'stemmed', 'stemming', 'stepped', 'stepping', 'stereotyped', 'sterling', 'sticking', 'stimulated', 'stimulating', 'stirred', 'stock-picking', 'stoked', 'stopped', 'stored', 'strapped', 'strengthened', 'stressed', 'stressing', 'stretched', 'stretching', 'striking', 'string', 'stripped', 'striving', 'strong-willed', 'structured', 'struggled', 'struggling', 'studied', 'studying', 'stunned', 'subdued', 'subjecting', 'subordinated', 'subpoenaed', 'substance-abusing', 'succeed', 'succeeded', 'succeeding', 'sued', 'suffered', 'suffering', 'suggested', 'suing', 'summoned', 'superimposed', 'supported', 'surfaced', 'surged', 'surprised', 'surprising', 'surrendered', 'surrounding', 'surveyed', 'surviving', 'suspended', 'sustained', 'swapped', 'swapping', 'sweeping', 'sweetened', 'swelling', 'swing', 'switched', 'synchronized', 'tailored', 'tailoring', 'taking', 'talked', 'talking', 'tanked', 'tapping', 'targeted', 'targeting', 'teaching', 'teetering', 'telling', 'tempted', 'tendered', 'tendering', 'termed', 'terminated', 'test-coaching', 'tested', 'testing', 'thin-lipped', 'thing', 'thinking', 'thirtysomething', 'threatened', 'thumbing', 'tie-breaking', 'tied', 'tightened', 'tightening', 'timing', 'tired', 'top-selling', 'top-yielding', 'topped', 'totaled', 'totaling', 'touched', 'touted', 'traced', 'tracked', 'tracking', 'traded', 'trading', 'trafficking', 'trailed', 'trained', 'training', 'transacting', 'transferring', 'transformed', 'transforming', 'transporting', 'travel-related', 'traveled', 'traveling', 'treated', 'treating', 'tried', 'triggered', 'trimmed', 'trimming', 'triple-A-rated', 'tripled', 'troubled', 'truth-in-lending', 'trying', 'tumbled', 'turned', 'turning', 'twinned', 'twisting', 'two-tiered', 'unabated', 'unaffiliated', 'unanticipated', 'unauthorized', 'unchanged', 'uncharted', 'uncompensated', 'uncomplaining', 'unconsolidated', 'undelivered', 'undercutting', 'undergoing', 'underlying', 'underperforming', 'underprivileged', 'understanding', 'undertaking', 'undisclosed', 'unenticing', 'unexpected', 'unfettered', 'unfilled', 'unfocused', 'unfounded', 'unfunded', 'unimpeded', 'unjustified', 'unlabeled', 'unleashed', 'unloaded', 'unmarked', 'unneeded', 'unpublished', 'unraveling', 'unrealized', 'unresolved', 'unrestricted', 'unsecured', 'unsettled', 'unsettling', 'unsolicited', 'unspecified', 'unstinting', 'untrained', 'unveiled', 'unwanted', 'unwashed', 'unwilling', 'upsetting', 'urged', 'urging', 'used', 'ushered', 'ushering', 'using', 'uttering', 'valued', 'varied', 'varying', 'ventilated', 'vested', 'video-viewing', 'viewed', 'viewing', 'violated', 'violating', 'visited', 'visiting', 'voted', 'voting', 'vowed', 'waited', 'waiting', 'waived', 'waiving', 'walking', 'wallowing', 'wanted', 'wanting', 'war-damaged', 'war-rationed', 'warehousing', 'warming', 'warned', 'warning', 'wasted', 'watched', 'watching', 'weakening', 'wedded', 'weighed', 'weighing', 'welcomed', 'well-connected', 'when-issued', 'whipping', 'whirling', 'willing', 'winding', 'wine-buying', 'wine-making', 'winning', 'wooing', 'word-processing', 'worked', 'working', 'worried', 'worrying', 'worsening', 'wrecking', 'wrenching', 'wrestling', 'writing', 'wrongdoing', 'yen-denominated', 'yet-to-be-formed', 'yielded', 'yielding', 'yttrium-containing', 'zoomed']\n",
      "['62%-owned', 'Absorbed', 'According', 'Adopting', 'Advanced', 'Advancing', 'Alfred', 'Allied', 'Annualized', 'Anything', 'Arbitrage-related', 'Arbitraging', 'Asked', 'Assuming', 'Atlanta-based', 'Baking', 'Banking', 'Beginning', 'Beijing', 'Being', 'Bermuda-based', 'Betting', 'Biedermann', 'Boeing', 'Breeden', 'Broadcasting', 'Bucking', 'Buying', 'Calif.-based', 'Cathedral', 'Cedric', 'Change-ringing', 'Citing', 'Concerned', 'Confederation', 'Confronted', 'Conn.based', 'Consolidated', 'Continued', 'Continuing', 'Credit', 'Declining', 'Defending', 'Depending', 'Designated', 'Determining', 'Developed', 'Died', 'During', 'Encouraged', 'Encouraging', 'English-speaking', 'Estimated', 'Everything', 'Excluding', 'Exxon-owned', 'Faulding', 'Fed', 'Federal', 'Federalist', 'Federation', 'Feeding', 'Filling', 'Filmed', 'Financing', 'Following', 'Founded', 'Fracturing', 'Francisco-based', 'Fred', 'Freddie', 'Frederick', 'Friedrichs', 'Funded', 'Funding', 'Generalized', 'Germany-based', 'Getting', 'Guaranteed', 'Having', 'Heating', 'Heightened', 'Holding', 'Housing', 'Illuminating', 'Impediments', 'Indeed', 'Indexing', 'Intermediate', 'Irving', 'Jersey-based', 'Judging', 'Kennedy', 'Knowing', 'Learning', 'Legislating', 'Leming', 'Limited', 'London-based', 'Manfred', 'Manufacturing', 'Media', 'Medical', 'Medicine', 'Melamed', 'Mercedes', 'Miami-based', 'Mich.-based', 'Mining', 'Minneapolis-based', 'Mo.-based', 'Montedison', 'Mortgage-Backed', 'Moving', 'Muzzling', 'N.J.-based', 'NBC-owned', 'NIH-appointed', 'Named', 'Nederlanden', 'Needham', 'No-Smoking', 'Observing', 'Offering', 'Ohio-based', 'Orleans-based', 'Packaging', 'Performing', 'Philadelphia-based', 'Posted', 'Proceeds', 'Provided', 'Publishing', 'Purchasing', 'Rated', 'Reached', 'Red', 'Red-blooded', 'Reddington', 'Redevelopment', 'Reducing', 'Reed', 'Regarded', 'Rekindled', 'Related', 'Ringing', 'Roederer', 'Rolling', 'Sacramento-based', 'Scoring', 'Seattle-based', 'Seed', 'Skilled', 'Smelting', 'Something', 'Speedway', 'Spending', 'Standardized', 'Standing', 'Starting', 'Sterling', 'Sweden', 'Taking', 'Teddy', 'Texas-based', 'Toledo', 'Toronto-based', 'Traded', 'Trading', 'Troubled', 'U.N.-supervised', 'U.S.-backed', 'United', 'Used', 'Varying', 'Washington-based', 'Wednesday', 'Wedtech', 'Whiting', 'Wilfred', 'Winning', 'Xiaoping', 'York-based', 'Zayed', 'abandoned', 'abating', 'abolishing', 'abortion-related', 'abounding', 'abridging', 'absorbed', 'acceded', 'accelerated', 'accepted', 'accepting', 'according', 'accounted', 'accounting', 'accrued', 'accumulated', 'accused', 'accusing', 'achieved', 'achieving', 'acknowledge', 'acknowledges', 'acknowledging', 'acquired', 'acquiring', 'acquisition-minded', 'acted', 'acting', 'adapted', 'adapting', 'added', 'adding', 'addressing', 'adjusted', 'adjusting', 'admitted', 'admitting', 'adopted', 'advanced', 'advancing', 'advertised', 'advertising', 'advised', 'advocated', 'advocating', 'affecting', 'afflicted', 'aggravated', 'agreed', 'agreed-upon', 'agreeing', 'ailing', 'aimed', 'aiming', 'aired', 'airline-related', 'alarmed', 'alienated', 'alleged', 'allegedly', 'alleging', 'allocated', 'allowed', 'altered', 'altering', 'amended', 'amending', 'amounted', 'amusing', 'angered', 'announced', 'annoyed', 'annualized', 'answered', 'anti-dumping', 'anticipated', 'anticipating', 'anything', 'apologizing', 'appealing', 'appeared', 'appearing', 'applied', 'appointed', 'approached', 'appropriated', 'approved', 'arched', 'argued', 'arguing', 'arising', 'armed', 'arranged', 'arrested', 'arrived', 'asbestos-related', 'asked', 'asking', 'assassinated', 'assembled', 'asserted', 'asserting', 'assessed', 'assigned', 'assisted', 'associated', 'assumed', 'assuming', 'assured', 'attached', 'attacking', 'attempted', 'attempting', 'attended', 'attending', 'attracted', 'attracting', 'attributed', 'auctioned', 'authorized', 'authorizing', 'automated', 'automotive-lighting', 'averaged', 'averted', 'avoiding', 'awarded', 'awarding', 'backed', 'backing', 'balanced', 'bald-faced', 'balkanized', 'balked', 'balloting', 'bank-backed', 'banking', 'banned', 'banning', 'barking', 'barred', 'based', 'battered', 'battery-operated', 'batting', 'bearing', 'becoming', 'bedding', 'beds', 'befuddled', 'beginning', 'behaving', 'beheading', 'being', 'beleaguered', 'believed', 'bell-ringing', 'belonging', 'benefited', 'best-selling', 'betting', 'bickering', 'bidding', 'billed', 'billing', 'blamed', 'bled', 'blessing', 'blighted', 'blocked', 'blurred', 'boarding', 'bolstered', 'bombarding', 'booked', 'booming', 'boosted', 'boosting', 'borrowed', 'borrowing', 'botched', 'bothered', 'bounced', 'bowed', 'breaking', 'breathed', 'breathtaking', 'breed', 'bribed', 'bribing', 'briefing', 'brightened', 'bring', 'bringing', 'broad-based', 'broadcasting', 'broadened', 'brokering', 'brushed', 'budding', 'building', 'bundling', 'buoyed', 'burned', 'buttoned-down', 'buying', 'calculated', 'called', 'calling', 'campaigning', 'cancer-causing', 'capitalized', 'capped', 'captivating', 'cared', 'carried', 'carrying', 'cascading', 'casting', 'caused', 'causing', 'cautioned', 'ceiling', 'centralized', 'certified', 'chaired', 'challenging', 'championing', 'change-ringing', 'changed', 'changing', 'characterized', 'characterizing', 'charged', 'charging', 'chastised', 'cheating', 'checking', 'cheerleading', 'chilled', 'choosing', 'chopped', 'circulated', 'cited', 'citing', 'citizen-sparked', 'city-owned', 'claimed', 'claiming', 'clamped', 'clarified', 'clashed', 'classed', 'classified', 'cleaned', 'cleaner-burning', 'cleared', 'clearing', 'clicked', 'climbed', 'climbing', 'clipped', 'clobbered', 'closed', 'closed-end', 'closing', 'clothing', 'clouding', 'cluttered', 'co-founded', 'coaching', 'coal-fired', 'coated', 'codified', 'collaborated', 'collapsed', 'collected', 'collecting', 'collective-bargaining', 'colored', 'combined', 'comedies', 'coming', 'commanded', 'commenting', 'committed', 'committing', 'compared', 'compelling', 'competed', 'competing', 'compiled', 'complained', 'complaining', 'completed', 'completing', 'complicated', 'composed', 'composting', 'compressed', 'computer-aided', 'computer-assisted', 'computer-generated', 'computerized', 'computing', 'concede', 'concedes', 'conceding', 'concentrated', 'concentrating', 'concerned', 'concluded', 'condemned', 'condemning', 'conducted', 'conducting', 'confined', 'confirmed', 'confused', 'connected', 'consented', 'considered', 'considering', 'consisting', 'construed', 'consulting', 'contacted', 'contained', 'containing', 'contesting', 'continued', 'continuing', 'contracted', 'contributed', 'contributing', 'controlled', 'controlling', 'converted', 'converting', 'convicted', 'convinced', 'cooled', 'cooperating', 'copied', 'copying', 'corn-buying', 'corrected', 'correcting', 'cost-cutting', 'cost-sharing', 'counseling', 'counting', 'coupled', 'court-ordered', 'covered', 'covering', 'cranked', 'crashing', 'created', 'creating', 'credentials', 'credibility', 'credit', 'credit-rating', 'creditor', 'creditors', 'credits', 'creditworthiness', 'crippled', 'criticized', 'crossed', 'crossing', 'crowded', 'cruising', 'crushed', 'crying', 'cultivated', 'curbed', 'curbing', 'curled', 'current-carrying', 'curtailed', 'cushioned', 'customized', 'cutting', 'damaged', 'damaging', 'dancing', 'darned', 'dashed', 'dating', 'dead-eyed', 'dealing', 'decided', 'declared', 'declaring', 'declined', 'declining', 'decorated', 'decried', 'deducting', 'deeds', 'deemed', 'defeated', 'defended', 'defined', 'defying', 'delayed', 'deliberating', 'delisted', 'delivered', 'delivering', 'demanding', 'demonstrating', 'denied', 'denouncing', 'denying', 'depended', 'depending', 'depleted', 'depressed', 'deprived', 'derived', 'descending', 'described', 'deserving', 'designated', 'designed', 'designing', 'desired', 'despised', 'detailed', 'deteriorated', 'deteriorating', 'determined', 'deterring', 'devastating', 'developed', 'developing', 'devised', 'devoted', 'devouring', 'diagnosed', 'died', 'diluted', 'diming', 'diminished', 'directed', 'directing', 'disaffected', 'disagreed', 'disappointed', 'disappointing', 'disapproved', 'discarded', 'disciplined', 'disclosed', 'disclosing', 'discontinued', 'discontinuing', 'discouraging', 'discovered', 'discredit', 'discussed', 'discussing', 'disembodied', 'dismayed', 'dismissed', 'disposed', 'disputed', 'disseminating', 'distinguished', 'distorted', 'distributed', 'disturbing', 'diversified', 'diversifying', 'divided', 'dividing', 'documented', 'doing', 'doling', 'dollar-denominated', 'dominated', 'dominating', 'doubled', 'doubted', 'downgraded', 'downgrading', 'drafted', 'drawing', 'dreamed', 'dressed', 'drifted', 'drinking', 'driving', 'drooled', 'dropped', 'dubbed', 'duckling', 'dumbfounded', 'dumped', 'during', 'dwindling', 'earned', 'earning', 'eased', 'easing', 'eating', 'echoed', 'edged', 'editing', 'edition', 'editions', 'editor', 'editorial', 'editorially', 'editors', 'educated', 'education', 'educational', 'educators', 'elected', 'eliminated', 'eliminating', 'embarrassing', 'embroiled', 'emerged', 'emerging', 'emphasized', 'employed', 'empowered', 'enabled', 'enabling', 'enacted', 'encircling', 'enclosed', 'encouraging', 'encroaching', 'ended', 'ending', 'endorsed', 'engaged', 'engaging', 'engineered', 'engineering', 'enhanced', 'enjoyed', 'enjoying', 'enlarged', 'enraged', 'ensnarled', 'entangled', 'entered', 'entering', 'entertaining', 'enticed', 'entitled', 'entrenched', 'entrusted', 'equaling', 'equipped', 'escalated', 'escaped', 'established', 'establishing', 'estimated', 'evaluated', 'evaluating', 'evaporated', 'evening', 'everything', 'evoking', 'evolved', 'exacerbated', 'examined', 'exceed', 'exceeded', 'exceeding', 'exceedingly', 'exceeds', 'exchanging', 'excited', 'exciting', 'executed', 'executing', 'exercised', 'exerting', 'exhausted', 'exhibited', 'existed', 'existing', 'expanded', 'expanding', 'expected', 'expecting', 'expedited', 'expelled', 'experienced', 'experiencing', 'expired', 'explained', 'explaining', 'exploded', 'export-oriented', 'exposed', 'expressed', 'expressing', 'expunged', 'extended', 'extending', 'exuded', 'eyeing', 'fabled', 'faced', 'facing', 'factoring', 'faded', 'failed', 'failing', 'fainting', 'falling', 'faltered', 'famed', 'family-planning', 'fared', 'fashioned', 'fast-growing', 'fastest-growing', 'fattened', 'favored', 'fawning', 'feared', 'featured', 'featuring', 'fed', 'federal', 'federally', 'feed', 'feeds', 'feeling', 'fetching', 'fielded', 'fighting', 'filed', 'filing', 'filled', 'filling', 'finalized', 'financed', 'financing', 'finding', 'fined', 'finished', 'fired', 'firmed', 'fixed', 'fixed-income', 'fixed-price', 'fixed-rate', 'fizzled', 'fled', 'fledgling', 'fleeting', 'flirted', 'floated', 'flooded', 'focused', 'focusing', 'folded', 'followed', 'following', 'forced', 'forcing', 'forecasting', 'foreign-led', 'formed', 'forthcoming', 'founded', 'foundering', 'freedom', 'freedoms', 'fretted', 'frightened', 'frustrating', 'fueled', 'fueling', 'full-fledged', 'fuming', 'functioning', 'funded', 'funding', 'fundraising', 'futures-related', 'gained', 'gaining', 'galling', 'galvanized', 'gambling', 'gauging', 'generated', 'getting', 'giving', 'going', 'good-hearted', 'good-natured', 'gored', 'government-certified', 'government-funded', 'government-owned', 'graduated', 'granted', 'granting', 'greed', 'greedy', 'gripping', 'growing', 'guaranteed', 'guarding', 'guided', 'gut-wrenching', 'hailed', 'hailing', 'halted', 'hampered', 'handed', 'handled', 'handling', 'happened', 'happening', 'hard-charging', 'hard-drinking', 'hard-hitting', 'harmed', 'harped', 'harvested', 'hauled', 'hauling', 'having', 'headed', 'heading', 'headlined', 'healing', 'hearing', 'heated', 'heating', 'hedging', 'heightened', 'helped', 'helping', 'high-flying', 'high-minded', 'high-polluting', 'high-priced', 'high-rolling', 'high-speed', 'higher-salaried', 'highest-pitched', 'hired', 'hitting', 'holding', 'hoped', 'hosted', 'housing', 'hugging', 'hundred', 'hundreds', 'hunted', 'hurting', 'identified', 'ignored', 'ignoring', 'immediate', 'immediately', 'impaired', 'impede', 'impeding', 'impending', 'implemented', 'implied', 'imported', 'imposed', 'imposing', 'impressed', 'improved', 'improving', 'incentive-backed', 'inched', 'inching', 'included', 'including', 'incorporated', 'increased', 'increasing', 'incredible', 'incurred', 'indeed', 'index-related', 'indicated', 'indicating', 'indulging', 'industrialized', 'industry-supported', 'inflated', 'influenced', 'influencing', 'infringed', 'ingredients', 'inherited', 'initialing', 'initiated', 'initiating', 'injecting', 'injuring', 'inkling', 'inquiring', 'inserted', 'insider-trading', 'insinuating', 'insisted', 'inspired', 'installed', 'installing', 'instituted', 'instructed', 'insured', 'integrated', 'intended', 'intentioned', 'interest-bearing', 'interested', 'interesting', 'intermediate', 'interrogated', 'interviewed', 'intriguing', 'introduced', 'introducing', 'invented', 'inverted', 'invested', 'investigating', 'investing', 'inviting', 'involved', 'involving', 'issued', 'issuing', 'jeopardizing', 'joined', 'joining', 'judged', 'jumped', 'jumping', 'justified', 'justifying', 'keeping', 'kicked', 'kidnapping', 'killed', 'killing', 'knitted', 'knocked', 'knowledge', 'knowledgeable', 'labeled', 'labeling', 'labor-backed', 'lacked', 'lagging', 'land-idling', 'landing', 'lasted', 'lasting', 'lauded', 'laughing', 'launched', 'lawmaking', 'laying', 'leading', 'learned', 'learning', 'leasing', 'leaving', 'led', 'lending', 'lengthened', 'lessening', 'letter-writing', 'letting', 'leveling', 'leveraged', 'leveraging', 'licensed', 'licensing', 'lifted', 'lifting', 'limited', 'limited-partnership', 'limiting', 'limping', 'linked', 'liquidated', 'listed', 'listing', 'living', 'loaded', 'loading', 'located', 'locked', 'long-tenured', 'longstanding', 'looked', 'looking', 'looming', 'losing', 'loved', 'low-priced', 'lower-priced', 'lowered', 'lowering', 'lying', 'machine-gun-toting', 'magnified', 'mailed', 'mailing', 'maintained', 'maintaining', 'making', 'male-dominated', 'managed', 'managing', 'manufactured', 'manufacturing', 'marching', 'market-based', 'market-oriented', 'marketed', 'marketing', 'matched', 'matching', 'materialized', 'mating', 'maturing', 'meaning', 'measured', 'meatpacking', 'medallions', 'media', 'medical', 'medicine', 'mediocre', 'medium-sized', 'meeting', 'melt-textured', 'mentioned', 'merchandising', 'merged', 'merger-related', 'midsized', 'milked', 'mind-boggling', 'mining', 'minority-owned', 'minted', 'mired', 'missed', 'mixed', 'mobilizing', 'moderated', 'mollified', 'money-losing', 'monied', 'morale-damaging', 'more-advanced', 'morning', 'mortgage-backed', 'mortgage-based', 'mortgaged', 'mounted', 'moved', 'moving', 'mudslinging', 'muffled', 'mulling', 'multiplying', 'murdered', 'muscling', 'muted', 'muzzling', 'named', 'naming', 'narrowed', 'need', 'needed', 'needing', 'needle-like', 'needs', 'needy', 'negotiated', 'negotiating', 'neighboring', 'networking', 'newspaper-printing', 'nominated', 'non-encapsulating', 'nonrecurring', 'notched', 'noted', 'nothing', 'noticed', 'noticing', 'notified', 'noting', 'notwithstanding', 'nullified', 'numbered', 'nurtured', 'obedient', 'obligated', 'observed', 'obsessed', 'obtained', 'obtaining', 'occupying', 'occurred', 'odd-sounding', 'offending', 'offered', 'offering', 'offsetting', 'old-fashioned', 'omitted', 'ongoing', 'opened', 'opening', 'operated', 'operating', 'opposed', 'orchestrated', 'ordered', 'ordering', 'organized', 'oriented', 'outdistanced', 'outlawed', 'outlawing', 'outnumbered', 'outpaced', 'outraged', 'outstanding', 'overcrowding', 'overleveraged', 'overpaying', 'overpriced', 'overriding', 'overstated', 'overused', 'overvalued', 'owed', 'owned', 'owning', 'packaging', 'packed', 'painted', 'painting', 'parched', 'parking', 'participated', 'parts-engineering', 'passed', 'passing', 'patented', 'paying', 'peaked', 'pealing', 'peddling', 'pediatrician', 'pegged', 'pending', 'perceived', 'performed', 'performing', 'permitted', 'permitting', 'phasing', 'photocopying', 'pianist-comedian', 'picked', 'picking', 'pinning', 'pitting', 'placed', 'placing', 'plagued', 'planned', 'planning', 'planted', 'planting', 'played', 'playing', 'pleaded', 'pleased', 'pledged', 'plugged', 'plummeted', 'plunged', 'plunging', 'pointed', 'pointing', 'polarized', 'policy-making', 'polled', 'populated', 'portrayed', 'posing', 'positioned', 'possessed', 'post-hearing', 'posted', 'posting', 'postponed', 'poured', 'practiced', 'practicing', 'praised', 'pre-approved', 'pre-cooked', 'pre-existing', 'preapproved', 'precedent', 'precedes', 'predecessor', 'predicated', 'predict', 'predictable', 'predictably', 'predicted', 'predicting', 'predicts', 'predispose', 'preferred', 'prepared', 'presented', 'preserving', 'pressed', 'pressing', 'pressured', 'prevailing', 'preventing', 'price-depressing', 'priced', 'pricing', 'printed', 'privileged', 'procedural', 'procedure', 'procedures', 'proceedings', 'proceeds', 'processing', 'produced', 'producing', 'profit-taking', 'profited', 'program-trading', 'programming', 'prohibited', 'prohibiting', 'prolonged', 'promised', 'promising', 'promoting', 'prompted', 'propelling', 'proposed', 'proposing', 'prosecuted', 'prosecuting', 'protected', 'protecting', 'protracted', 'proved', 'provided', 'providing', 'proving', 'provoked', 'prying', 'publicized', 'published', 'publishing', 'pulled', 'pulling', 'pumping', 'punishing', 'purchased', 'purchasing', 'purhasing', 'pursued', 'pushed', 'pushing', 'putting', 'puzzled', 'qualified', 'quashing', 'questioned', 'queuing', 'quipped', 'quitting', 'quoted', 'quoting', 'raced', 'racing', 'railing', 'raised', 'raising', 'rallying', 'ranged', 'ranging', 'ranked', 'rarefied', 'raring', 'ratcheting', 'rated', 'ratified', 'rating', 'rationed', 'reached', 'reaching', 'reacted', 'reading', 'reaffirmed', 'realized', 'reallocated', 'reaped', 'reaping', 'reasoning', 'reassuring', 'rebounding', 'rebuffed', 'rebuilding', 'rebuked', 'recalling', 'recede', 'received', 'receiving', 'recession-inspired', 'reciting', 'reclaimed', 'recognizing', 'recommended', 'recommending', 'record-keeping', 'recorded', 'recouped', 'recovered', 'recovering', 'recruited', 'recruiting', 'rectified', 'recycled', 'red', 'red-and-white', 'red-carpet', 'red-flag', 'redeem', 'redeemed', 'redeeming', 'redemption', 'redeploy', 'redistribute', 'redistributing', 'reds', 'reduce', 'reduced', 'reducing', 'reduction', 'reductions', 'reeling', 'referred', 'referring', 'refitting', 'reflected', 'reflecting', 'refocusing', 'refreshing', 'refunded', 'refunding', 'refused', 'regarded', 'regarding', 'regimented', 'registered', 'regulated', 'regulating', 'reimbursed', 'reinstating', 'rejected', 'related', 'relating', 'relaunched', 'released', 'relegated', 'relied', 'relieved', 'remained', 'remaining', 'remarked', 'reminded', 'remodeling', 'removed', 'removing', 'rendering', 'renewed', 'renewing', 'renovated', 'reopened', 'reorganized', 'repaired', 'repeatedly', 'replaced', 'replacing', 'replicated', 'replicating', 'reported', 'reportedly', 'reporting', 'represented', 'representing', 'repriced', 'requested', 'requesting', 'required', 'requiring', 'rescheduled', 'researching', 'reserved', 'reshaping', 'resigned', 'resigning', 'resisting', 'resolved', 'respected', 'responded', 'responding', 'restored', 'restricting', 'restructured', 'restructuring', 'resulted', 'resulting', 'retailing', 'retained', 'retaining', 'retaliating', 'retired', 'retiring', 'retraced', 'returned', 'returning', 'reversed', 'reviewed', 'reviewing', 'revised', 'revising', 'revived', 'rewarding', 'riding', 'rigged', 'ring', 'ringing', 'rising', 'robbed', 'rolled', 'rolling', 'romanticized', 'rooted', 'ruled', 'ruling', 'rumored', 'running', 'rushed', 'rusted', 'sacked', 'sacrificing', 'safeguarding', 'sagged', 'sagging', 'satisfying', 'saved', 'saving', 'saying', 'scared', 'scaring', 'scattered', 'schedule', 'scheduled', 'school-sponsored', 'scrambled', 'scrambling', 'scrapped', 'screened', 'screwed', 'scrutinizing', 'searched', 'searching', 'seasoned', 'secede', 'secured', 'securities-based', 'seduce', 'seeing', 'seeking', 'seemed', 'segmenting', 'seized', 'selected', 'self-aggrandizing', 'self-perpetuating', 'self-serving', 'selling', 'sending', 'sentencing', 'served', 'serviced', 'servicing', 'serving', 'setting', 'settled', 'shaded', 'shaping', 'shared', 'shed', 'shedding', 'shipbuilding', 'shipped', 'shipping', 'shirt-sleeved', 'shopped', 'shopping', 'shoring', 'short-lived', 'showed', 'showing', 'shrinking', 'signaling', 'signed', 'signifying', 'signing', 'single-handed', 'single-handedly', 'singled', 'sitting', 'sketching', 'skidded', 'skilled', 'skipped', 'skyrocketed', 'slashing', 'slated', 'slaying', 'sleeping', 'sliding', 'slipped', 'slowed', 'slowing', 'smattering', 'smoking', 'smothering', 'snaking', 'snapped', 'sneaked', 'so-called', 'soared', 'soaring', 'softening', 'soliciting', 'solved', 'something', 'sometimes-exhausting', 'sophisticated', 'sorting', 'sounded', 'sounding', 'soured', 'sparing', 'sparked', 'sparking', 'speaking', 'specialized', 'specializing', 'specified', 'speculated', 'speculating', 'speed', 'speedway', 'spending', 'spilling', 'spooked', 'sports-oriented', 'spotted', 'sprawling', 'spring', 'spurned', 'spurred', 'spurring', 'sputtered', 'squeezed', 'stabbed', 'stacked', 'stacking', 'staff-reduction', 'staggering', 'standardized', 'standing', 'started', 'starting', 'startling', 'state-appointed', 'state-owned', 'state-supervised', 'stated', 'stayed', 'staying', 'stemmed', 'stemming', 'stepped', 'stepping', 'stereotyped', 'sterling', 'sticking', 'stimulated', 'stimulating', 'stirred', 'stock-picking', 'stoked', 'stopped', 'stored', 'strapped', 'strengthened', 'stressed', 'stressing', 'stretched', 'stretching', 'striking', 'string', 'stripped', 'striving', 'strong-willed', 'structured', 'struggled', 'struggling', 'studied', 'studying', 'stunned', 'subdued', 'subjecting', 'subordinated', 'subpoenaed', 'substance-abusing', 'succeed', 'succeeded', 'succeeding', 'succeeds', 'sued', 'suffered', 'suffering', 'suggested', 'suing', 'summoned', 'superimposed', 'supported', 'supposedly', 'surfaced', 'surged', 'surprised', 'surprising', 'surrendered', 'surrounding', 'surveyed', 'surviving', 'suspended', 'sustained', 'swapped', 'swapping', 'sweeping', 'sweetened', 'swelling', 'swing', 'switched', 'synchronized', 'tailored', 'tailoring', 'taking', 'talked', 'talking', 'tanked', 'tapping', 'targeted', 'targeting', 'teaching', 'teetering', 'telling', 'tempted', 'tendered', 'tendering', 'termed', 'terminated', 'test-coaching', 'tested', 'testing', 'thin-lipped', 'thing', 'thinking', 'thirtysomething', 'threatened', 'thumbing', 'tie-breaking', 'tied', 'tightened', 'tightening', 'timing', 'tired', 'top-selling', 'top-yielding', 'topped', 'totaled', 'totaling', 'touched', 'touted', 'traced', 'tracked', 'tracking', 'traded', 'trading', 'trafficking', 'trailed', 'trained', 'training', 'transacting', 'transferring', 'transformed', 'transforming', 'transporting', 'travel-related', 'traveled', 'traveling', 'treated', 'treating', 'tried', 'triggered', 'trimmed', 'trimming', 'triple-A-rated', 'tripled', 'troubled', 'truth-in-lending', 'trying', 'tumbled', 'turned', 'turning', 'twinned', 'twisting', 'two-tiered', 'unabated', 'unaffiliated', 'unanticipated', 'unauthorized', 'unchanged', 'uncharted', 'uncompensated', 'uncomplaining', 'unconsolidated', 'undelivered', 'undercutting', 'undergoing', 'underlying', 'underperforming', 'underprivileged', 'understanding', 'undertaking', 'undisclosed', 'unenticing', 'unexpected', 'unfettered', 'unfilled', 'unfocused', 'unfounded', 'unfunded', 'unimpeded', 'unjustified', 'unlabeled', 'unleashed', 'unloaded', 'unmarked', 'unneeded', 'unpublished', 'unraveling', 'unrealized', 'unresolved', 'unrestricted', 'unsecured', 'unsettled', 'unsettling', 'unsolicited', 'unspecified', 'unstinting', 'untrained', 'unveiled', 'unwanted', 'unwashed', 'unwilling', 'upsetting', 'urged', 'urging', 'used', 'ushered', 'ushering', 'using', 'uttering', 'valued', 'varied', 'varying', 'ventilated', 'vested', 'video-viewing', 'viewed', 'viewing', 'violated', 'violating', 'visited', 'visiting', 'voted', 'voting', 'vowed', 'waited', 'waiting', 'waived', 'waiving', 'walking', 'wallowing', 'wanted', 'wanting', 'war-damaged', 'war-rationed', 'warehousing', 'warming', 'warned', 'warning', 'wasted', 'watched', 'watching', 'weakening', 'wedded', 'weddings', 'weighed', 'weighing', 'welcomed', 'well-connected', 'when-issued', 'whipping', 'whirling', 'willing', 'winding', 'wine-buying', 'wine-making', 'winning', 'wooing', 'word-processing', 'worked', 'working', 'worried', 'worrying', 'worsening', 'wrecking', 'wrenching', 'wrestling', 'writing', 'wrongdoing', 'yen-denominated', 'yet-to-be-formed', 'yielded', 'yielding', 'yttrium-containing', 'zoomed']\n"
     ]
    }
   ],
   "source": [
    "chat_words = sorted(set(w for w in nltk.corpus.nps_chat.words()))\n",
    "print([w for w in chat_words if re.search('^m+i+n+e+$', w)])\n",
    "print([w for w in chat_words if re.search('^[ha]+$', w)])\n",
    "\n",
    "wsj = sorted(set(nltk.corpus.treebank.words()))\n",
    "print([w for w in wsj if re.search('^[0-9]+\\.[0-9]+$', w)])\n",
    "print([w for w in wsj if re.search('^[A-Z]+\\$$', w)])\n",
    "print([w for w in wsj if re.search('^[0-9]{4}$', w)])\n",
    "print([w for w in wsj if re.search('^[0-9]+-[a-z]{3,5}$', w)])\n",
    "print([w for w in wsj if re.search('(ed|ing)$', w)])\n",
    "print([w for w in wsj if re.search('ed|ing$', w)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'finger-twisters' for top row: \n",
      "\n",
      "['aa', 'aba', 'abac', 'abaca', 'abaff', 'abb', 'abed', 'acca', 'accede', 'ace', 'ad', 'adad', 'add', 'adda', 'added', 'ade', 'adead', 'ae', 'aface', 'affa', 'ba', 'baa', 'baba', 'babe', 'bac', 'bacaba', 'bacca', 'baccae', 'bad', 'bade', 'bae', 'baff', 'be', 'bead', 'beaded', 'bebed', 'bed', 'bedad', 'bedded', 'bedead', 'bedeaf', 'bee', 'beef', 'ca', 'cab', 'caba', 'cabda', 'cad', 'cade', 'caeca', 'caffa', 'ce', 'cede', 'cee', 'da', 'dab', 'dabb', 'dabba', 'dace', 'dad', 'dada', 'dade', 'dae', 'daff', 'de', 'dead', 'deaf', 'deb', 'decad', 'decade', 'dee', 'deed', 'deedeed', 'deface', 'ea', 'ebb', 'ecad', 'edea', 'efface', 'fa', 'facade', 'face', 'faced', 'fad', 'fade', 'faded', 'fae', 'faff', 'fe', 'fed', 'fee', 'feed']\n",
      "\n",
      "'finger-twisters' for middle row: \n",
      "\n",
      "['ghoom', 'gig', 'giggling', 'gigolo', 'gilim', 'gill', 'gilling', 'gilo', 'gim', 'gin', 'ging', 'gingili', 'gink', 'ginkgo', 'ginning', 'gio', 'glink', 'glom', 'glonoin', 'gloom', 'glooming', 'gnomon', 'gog', 'gogo', 'goi', 'going', 'gol', 'goli', 'gon', 'gong', 'gonion', 'goo', 'googol', 'gook', 'gool', 'goon', 'high', 'hill', 'him', 'hin', 'hing', 'hinoki', 'hog', 'hoggin', 'hogling', 'hoi', 'hoin', 'holing', 'holl', 'hollin', 'hollo', 'hollong', 'holm', 'homo', 'homologon', 'hong', 'honk', 'hook', 'hoon', 'igloo', 'ihi', 'ilk', 'ill', 'imi', 'imino', 'immi', 'ing', 'ingoing', 'inion', 'ink', 'inkling', 'inlook', 'inn', 'inning', 'ion', 'jhool', 'jig', 'jing', 'jingling', 'jingo', 'jinjili', 'jink', 'jinn', 'jinni', 'jog', 'johnin', 'join', 'joining', 'joll', 'joom', 'kiki', 'kil', 'kilhig', 'kilim', 'kill', 'killing', 'kiln', 'kilo', 'kim', 'kimono', 'kin', 'king', 'kingling', 'kink', 'kino', 'klom', 'knoll', 'kohl', 'koi', 'koil', 'koilon', 'koinon', 'kokil', 'kokio', 'koko', 'kokoon', 'kolo', 'kolokolo', 'kon', 'kongoni', 'konini', 'lignin', 'liin', 'likin', 'liking', 'liknon', 'lill', 'lim', 'liming', 'limn', 'limonin', 'lin', 'ling', 'lingo', 'linin', 'lining', 'link', 'linking', 'linn', 'lino', 'linolin', 'linon', 'lion', 'log', 'loggin', 'logging', 'login', 'logion', 'logoi', 'loin', 'loll', 'long', 'longing', 'loo', 'look', 'looking', 'loom', 'looming', 'loon', 'mho', 'mig', 'miglio', 'mignon', 'mijl', 'mil', 'milk', 'milking', 'mill', 'milling', 'million', 'milo', 'mim', 'min', 'ming', 'minikin', 'minim', 'mining', 'minion', 'mink', 'minning', 'mino', 'mog', 'mogo', 'moho', 'moil', 'moiling', 'moio', 'mojo', 'moki', 'moko', 'momo', 'mon', 'mong', 'monk', 'mono', 'moo', 'mooing', 'mool', 'moon', 'mooning', 'nig', 'niggling', 'nigh', 'nil', 'nim', 'ninon', 'niog', 'nog', 'noggin', 'nogging', 'noil', 'noll', 'nolo', 'non', 'nonillion', 'nonion', 'nook', 'nooking', 'noon', 'nooning', 'ohm', 'oho', 'oii', 'oil', 'oki', 'olio', 'olm', 'ongoing', 'onion', 'onlook', 'onlooking', 'oolong']\n",
      "\n",
      "'finger-twisters' for bottom row: \n",
      "\n",
      "['prut', 'pry', 'pst', 'pup', 'puppy', 'pur', 'purr', 'purry', 'pursy', 'pus', 'puss', 'pussy', 'put', 'putt', 'putty', 'puxy', 'pyr', 'pyx', 'ruru', 'rust', 'rusty', 'ruswut', 'rut', 'rutty', 'rux', 'spry', 'spur', 'spurry', 'spurt', 'sput', 'spy', 'ssu', 'strut', 'struv', 'stupp', 'sturt', 'stuss', 'stut', 'sty', 'sup', 'sur', 'susu', 'susurr', 'susurrus', 'suz', 'syrt', 'syrup', 'syrupy', 'truss', 'trust', 'trusty', 'try', 'tryp', 'tryst', 'tryt', 'tst', 'tup', 'tur', 'turp', 'turps', 'turr', 'turus', 'tussur', 'tut', 'tuts', 'tutty', 'tutu', 'tux', 'typp', 'typy', 'tyt', 'upspurt', 'upsup', 'uptruss', 'urus', 'ust', 'usurp', 'usury', 'utu', 'wry', 'wup', 'wur', 'wurrus', 'wusp', 'wuss', 'wust', 'wut', 'wuzu', 'wuzzy', 'wyss', 'xyst', 'xystus', 'yurt', 'yus', 'yutu']\n",
      "\n",
      "'finger-twisters' for left column: \n",
      "\n",
      "['gig', 'giggish', 'gip', 'girr', 'girsh', 'gish', 'grig', 'grigri', 'grip', 'gris', 'grisgris', 'grr', 'hi', 'high', 'highish', 'hip', 'hippish', 'his', 'hish', 'hiss', 'ihi', 'iris', 'is', 'phi', 'pi', 'pig', 'piggish', 'pip', 'pipi', 'pipiri', 'pir', 'piripiri', 'pirr', 'pish', 'piss', 'prig', 'priggish', 'priss', 'psi', 'rig', 'riggish', 'rip', 'rishi', 'risp', 'sh', 'shi', 'shih', 'ship', 'shirr', 'shish', 'shrip', 'si', 'sig', 'sigh', 'sip', 'sir', 'sirih', 'siris', 'sirship', 'sis', 'sish', 'sisi', 'siss', 'spig', 'sprig', 'sri']\n",
      "\n",
      "'finger-twisters' for middle column: \n",
      "\n",
      "['aal', 'aba', 'abac', 'abaca', 'aback', 'abb', 'ablaut', 'abu', 'abut', 'abuttal', 'acca', 'act', 'acta', 'actu', 'actual', 'ajaja', 'ajava', 'aka', 'akala', 'aku', 'ala', 'alack', 'alala', 'alb', 'alba', 'albata', 'alk', 'all', 'allabuta', 'alt', 'alula', 'aluta', 'atabal', 'atlatl', 'atta', 'attack', 'auca', 'aucuba', 'auk', 'aula', 'aulu', 'ava', 'aval', 'baa', 'baal', 'baba', 'babu', 'babul', 'bac', 'bacaba', 'bacca', 'back', 'backtack', 'bacula', 'baka', 'bakal', 'baku', 'bakula', 'bal', 'balaclava', 'balata', 'balk', 'ball', 'ballata', 'balu', 'balut', 'bat', 'batata', 'batt', 'batta', 'baul', 'bauta', 'blab', 'black', 'blackback', 'blackball', 'blackbutt', 'blackjack', 'blat', 'blatta', 'blub', 'bual', 'bub', 'buba', 'bubal', 'bucca', 'buccal', 'buccula', 'buck', 'bulak', 'bulb', 'bulbul', 'bulk', 'bull', 'bulla', 'bullback', 'bullbat', 'bult', 'but', 'butt', 'cab', 'caba', 'caback', 'cabal', 'cabala', 'cack', 'cal', 'calaba', 'calalu', 'calk', 'call', 'cat', 'catcall', 'cattabu', 'cauk', 'caul', 'cava', 'caval', 'cavalla', 'clack', 'clat', 'claut', 'clava', 'claval', 'club', 'cluck', 'cub', 'cuck', 'cuculla', 'culbut', 'cull', 'culla', 'cult', 'cultual', 'cut', 'cutback', 'jab', 'jabul', 'jacal', 'jack', 'jackal', 'jacu', 'jauk', 'juba', 'juck', 'juju', 'jut', 'jutka', 'kaka', 'kakkak', 'kala', 'kat', 'katuka', 'kava', 'kuba', 'kubba', 'kuku', 'kula', 'kulack', 'kulak', 'kuttab', 'lab', 'labba', 'lablab', 'lac', 'lacca', 'lack', 'lak', 'lall', 'lat', 'lata', 'lava', 'llautu', 'luck', 'lulab', 'lull', 'lulu', 'lut', 'taa', 'tab', 'tabla', 'tabu', 'tabula', 'tabut', 'tack', 'tact', 'tactual', 'taj', 'takt', 'tal', 'tala', 'talak', 'talc', 'talk', 'tall', 'taluk', 'taluka', 'tat', 'tatta', 'tattva', 'tatu', 'tau', 'taula', 'taut', 'tav', 'tck', 'tua', 'tub', 'tuba', 'tubal', 'tubba', 'tubbal', 'tuck', 'tula', 'tut', 'tutball', 'tutu', 'ula', 'ull', 'ulla', 'ulu', 'ulua', 'ululu', 'uta', 'utu', 'uva', 'uval', 'uvula', 'vacual', 'vall', 'valuta', 'valva', 'valval', 'valvula', 'vat', 'vau', 'vault', 'vulva', 'vulval']\n",
      "\n",
      "'finger-twisters' for right column: \n",
      "\n",
      "['dedo', 'dee', 'deed', 'deedeed', 'deedy', 'deem', 'defend', 'defy', 'deme', 'demoded', 'demon', 'demy', 'den', 'dene', 'deny', 'dew', 'dewy', 'dey', 'dod', 'dodd', 'dodded', 'doddy', 'dodo', 'doe', 'doff', 'dom', 'dome', 'domn', 'domy', 'don', 'done', 'donee', 'doney', 'doom', 'doon', 'dow', 'dowd', 'dowdy', 'dowed', 'dowf', 'down', 'downfeed', 'downweed', 'downy', 'doxy', 'doze', 'dozed', 'dozen', 'dozy', 'dye', 'dyeweed', 'dyewood', 'dyne', 'eddo', 'eddy', 'eme', 'emend', 'emyd', 'end', 'ended', 'endew', 'endoenzyme', 'endome', 'endow', 'enemy', 'enfeoff', 'enow', 'enwood', 'enzone', 'enzym', 'enzyme', 'eon', 'eozoon', 'ewe', 'exode', 'exody', 'exoenzyme', 'exon', 'eye', 'eyed', 'eyen', 'eyey', 'eyn', 'eyne', 'fed', 'fee', 'feed', 'feedy', 'feeze', 'feme', 'fen', 'fend', 'fendy', 'fenny', 'feod', 'feoff', 'feoffee', 'few', 'fey', 'fez', 'fezzed', 'fezzy', 'fod', 'foe', 'fono', 'foo', 'food', 'foody', 'fow', 'fox', 'foxwood', 'foxy', 'foy', 'fozy', 'meed', 'mem', 'memo', 'men', 'mend', 'mendee', 'mennom', 'meny', 'mew', 'mezzo', 'mneme', 'mode', 'moff', 'mome', 'momme', 'mommy', 'momo', 'mon', 'mone', 'money', 'moneyed', 'monny', 'mono', 'monody', 'mononym', 'mononymy', 'moo', 'mood', 'moody', 'moon', 'moondown', 'mooned', 'mooneye', 'moony', 'mow', 'mown', 'moy', 'moyen', 'moyenne', 'moyo', 'myoneme', 'myxo', 'neddy', 'nee', 'need', 'needy', 'neem', 'neeze', 'nef', 'neffy', 'neo', 'neon', 'new', 'nod', 'noddy', 'node', 'noded', 'nome', 'non', 'nondo', 'none', 'nonene', 'nonenemy', 'nonfood', 'nonwoody', 'noon', 'now', 'nowed', 'nowy', 'noy', 'nye', 'odd', 'ode', 'odeon', 'odoom', 'off', 'offend', 'offended', 'omen', 'omened', 'ondy', 'one', 'onym', 'onymy', 'onyx', 'oofy', 'ooze', 'oozy', 'owd', 'owe', 'own', 'oxen', 'oxeye', 'oxozone', 'oxy', 'ozone', 'ozoned', 'wed', 'wedded', 'wede', 'wee', 'weed', 'weeded', 'weedow', 'weedy', 'weemen', 'ween', 'weeny', 'weewow', 'weeze', 'wem', 'wen', 'wend', 'wende', 'wene', 'wenny', 'wey', 'wod', 'wode', 'woe', 'won', 'wone', 'wonned', 'woo', 'wood', 'wooded', 'wooden', 'woodeny', 'woody', 'woof', 'woofed', 'woofy', 'woom', 'woon', 'woozy', 'wow', 'woy', 'wyde', 'wye', 'wyn', 'wynd', 'wyne', 'wynn', 'xenon', 'yed', 'yede', 'yee', 'yen', 'yeo', 'yew', 'yex', 'yez', 'yezzy', 'yoe', 'yom', 'yon', 'yond', 'yow', 'yox', 'yoy', 'zed', 'zee', 'zeed', 'zone', 'zoned', 'zoo', 'zoom', 'zoon', 'zoonomy', 'zoozoo', 'zyme', 'zymome']\n",
      "\n",
      "'finger-twisters' for top left corner: \n",
      "\n",
      "['aal', 'aalii', 'aba', 'abac', 'abaca', 'aback', 'abb', 'abigail', 'abilla', 'ablach', 'acca', 'ach', 'achill', 'aga', 'agal', 'agha', 'agla', 'aha', 'ail', 'ajaja', 'aka', 'akala', 'akia', 'ala', 'alacha', 'alack', 'alaihi', 'alala', 'alb', 'alba', 'albahaca', 'alga', 'algal', 'algalia', 'algic', 'alibi', 'alk', 'alkali', 'alkalic', 'all', 'baa', 'baal', 'baba', 'babai', 'bablah', 'bac', 'bacaba', 'bacach', 'bacca', 'bacchiac', 'bacchic', 'bacchii', 'bach', 'bacilli', 'back', 'bag', 'baga', 'baggala', 'bah', 'bail', 'baka', 'bakal', 'bakli', 'bal', 'balai', 'balalaika', 'bali', 'balk', 'ball', 'balli', 'bib', 'bibb', 'bibi', 'bick', 'big', 'biga', 'bigg', 'biggah', 'bigha', 'bija', 'bikh', 'bilabial', 'bilch', 'bilic', 'bilk', 'bill', 'billa', 'billback', 'blab', 'black', 'blackback', 'blackball', 'blackjack', 'blah', 'blick', 'cab', 'caba', 'caback', 'cabal', 'cabala', 'cabalic', 'cack', 'cag', 'cal', 'calaba', 'calcic', 'caliga', 'calk', 'call', 'calli', 'cha', 'chaa', 'chab', 'chachalaca', 'chack', 'chai', 'chaja', 'chaka', 'chal', 'chalk', 'challah', 'chi', 'chia', 'chic', 'chichi', 'chick', 'chiggak', 'chih', 'chil', 'chilalgia', 'chili', 'chill', 'chilla', 'chkalik', 'cicala', 'cig', 'cigala', 'cilia', 'clack', 'clag', 'cliack', 'click', 'gab', 'gabgab', 'gabi', 'gag', 'gaj', 'gal', 'gala', 'galagala', 'galah', 'galgal', 'gali', 'gall', 'galla', 'gallah', 'gallic', 'gib', 'gig', 'gigback', 'gilia', 'gill', 'glacial', 'glack', 'glaga', 'glaik', 'glia', 'glial', 'glib', 'haab', 'hack', 'hag', 'hagi', 'hagia', 'hah', 'haik', 'haikai', 'haikal', 'hail', 'hajib', 'hajilij', 'hak', 'hala', 'halakah', 'halakic', 'halal', 'halch', 'hall', 'hallah', 'hia', 'hic', 'hick', 'high', 'highball', 'highjack', 'hijack', 'hilch', 'hill', 'iba', 'ich', 'icica', 'ihi', 'ilia', 'iliac', 'iliahi', 'ilial', 'ilicic', 'ilk', 'ilka', 'ill', 'jab', 'jabia', 'jacal', 'jack', 'jackal', 'jag', 'jagla', 'jail', 'jib', 'jibbah', 'jibi', 'jig', 'kaha', 'kahili', 'kai', 'kaik', 'kail', 'kaka', 'kaki', 'kakkak', 'kala', 'kali', 'kallah', 'khaiki', 'khaja', 'khaki', 'kiack', 'kiaki', 'kiblah', 'kick', 'kickback', 'kiki', 'kil', 'kilah', 'kilhig', 'kill', 'killick', 'lab', 'labba', 'labia', 'labial', 'lablab', 'lac', 'lacca', 'laccaic', 'lack', 'lag', 'lai', 'laic', 'laical', 'laich', 'laigh', 'lak', 'lall', 'licca', 'lich', 'lichi', 'lick', 'lija', 'lilac', 'lill']\n",
      "\n",
      "'finger-twisters' for top right corner: \n",
      "\n",
      "['abac', 'abaca', 'aback', 'abaff', 'abalone', 'abandon', 'abandonable', 'abandoned', 'abandonee', 'abdal', 'abdomen', 'abeam', 'abed', 'abele', 'able', 'abloom', 'abode', 'abolla', 'aboma', 'aboon', 'academe', 'acana', 'acca', 'accede', 'accedence', 'accend', 'accolade', 'accoladed', 'accolle', 'accommodable', 'ackman', 'acle', 'acme', 'acne', 'acnodal', 'acnode', 'acock', 'acold', 'acoma', 'acone', 'adad', 'adance', 'adda', 'addable', 'added', 'addend', 'addenda', 'addle', 'adead', 'adeem', 'adenocele', 'adenoma', 'adman', 'adobe', 'aefald', 'aenean', 'aeon', 'aface', 'affa', 'affable', 'aflame', 'afoam', 'ajaja', 'akala', 'akeake', 'akee', 'aknee', 'alack', 'alada', 'alala', 'alameda', 'alamo', 'alan', 'aland', 'alba', 'alban', 'albe', 'albedo', 'albee', 'alcalde', 'alcanna', 'alclad', 'alco', 'aldane', 'aldol', 'aleak', 'alec', 'alee', 'alef', 'alem', 'alemana', 'alemmal', 'alen', 'alfa', 'alfaje', 'alfalfa', 'aljoba', 'alkane', 'alkene', 'alkenna', 'alkool', 'allan', 'allbone', 'allele', 'allemand', 'allemande', 'allene', 'allocable', 'alma', 'almanac', 'alme', 'almon', 'almond', 'alod', 'aloe', 'aloed', 'aloma', 'alone', 'aloof', 'amakebe', 'amala', 'amalaka', 'amba', 'ambalam', 'amban', 'amble', 'ambo', 'ambomalleal', 'ambon', 'ameed', 'ameen', 'amen', 'amenable', 'amend', 'amendable', 'amende', 'amene', 'amla', 'amma', 'amman', 'ammo', 'ammonal', 'ammono', 'amoeba', 'amoebae', 'amoebaean', 'amoeban', 'amok', 'amoke', 'amole', 'amomal', 'anabo', 'anaconda', 'anadem', 'anal', 'analemma', 'anam', 'anama', 'anan', 'anana', 'ananda', 'anba', 'ancon', 'anconad', 'anconal', 'ancone', 'anconeal', 'anda', 'anele', 'anemonal', 'anemone', 'anemonol', 'anend', 'anjan', 'ankee', 'ankle', 'anklebone', 'anklejack', 'anlace', 'anna', 'annal', 'annale', 'anneal', 'annona', 'anoa', 'anodal', 'anode', 'anole', 'anon', 'anonol', 'baal', 'baba', 'babble', 'babe', 'baboen', 'baboo', 'baboodom', 'baboon', 'bacaba', 'bacalao', 'bacao', 'bacca', 'baccae', 'back', 'backband', 'backbone', 'backboned', 'backed', 'backen', 'backfall', 'backfold', 'bacon', 'badan', 'baddock', 'bade', 'badland', 'baff', 'baffle', 'bajada', 'bajan', 'baka', 'bakal', 'bake', 'baked', 'baken', 'balafo', 'balance', 'balanceable', 'balanced', 'balancelle', 'balanceman', 'balanocele', 'balao', 'balboa', 'bald', 'balden', 'bale', 'baleen', 'balk', 'ball', 'ballad', 'ballade', 'ballam', 'ballan', 'balldom', 'balled', 'balloon', 'balm', 'balmacaan', 'balneal', 'balonea', 'baloo', 'bamban', 'bamboo', 'banaba', 'banak', 'banal', 'banana', 'banc', 'banca', 'bancal', 'banco', 'band', 'banda', 'bandaka', 'bandala', 'bandanna', 'bandannaed', 'bande', 'banded', 'bandle', 'bandman', 'bando', 'bane', 'banjo', 'bank', 'bankable', 'bankbook', 'banked', 'bankman', 'bannock', 'baobab', 'beacon', 'bead', 'beaded', 'beadle', 'beadledom', 'beadman', 'beak', 'beaked', 'beal', 'beala', 'beam', 'beamed', 'beamman', 'bean', 'beancod', 'beano', 'beback', 'beballed', 'bebed', 'bebled', 'beblood', 'bebloom', 'becall', 'becalm', 'beck', 'beckon', 'beclad', 'becloak', 'becolme', 'becombed', 'become', 'becomma', 'becoom', 'bedabble', 'bedad', 'bedamn', 'bedded', 'bedead', 'bedeaf', 'bedeafen', 'bedeck', 'bedel', 'beden', 'bedene', 'bedlam', 'bedman', 'beedom', 'beef', 'beek', 'beelol', 'beeman', 'been', 'befall', 'befame', 'befan', 'befanned', 'beflannel', 'beflea', 'befleck', 'befoam', 'befool', 'bejade', 'bejan', 'bejel', 'bekko', 'bela', 'belaced', 'beladle', 'belam', 'belanda', 'beld', 'beldam', 'beleaf', 'belee', 'bell', 'belladonna', 'belle', 'belled', 'belledom', 'bellman', 'beloam', 'bema', 'bemad', 'bemadam', 'beman', 'bemeal', 'bemean', 'bemedaled', 'bemedalled', 'bemoan', 'bemoanable', 'bemock', 'bemole', 'bemoon', 'bena', 'benab', 'bename', 'benben', 'bend', 'benda', 'bendable', 'bended', 'bene', 'benj', 'benn', 'benne', 'bennel', 'beno', 'beode', 'blab', 'black', 'blackback', 'blackball', 'blackband', 'blackcock', 'blacken', 'blackface', 'blackjack', 'blackland', 'blackneb', 'blackneck', 'blacknob', 'blad', 'blade', 'bladebone', 'bladed', 'blae', 'blaff', 'blake', 'blamable', 'blame', 'blamed', 'blan', 'blanc', 'blanca', 'blanco', 'bland', 'blanda', 'blank', 'blankbook', 'blanked', 'blankeel', 'bleak', 'bleb', 'bleck', 'blee', 'bleed', 'bleekbok', 'blend', 'blende', 'blended', 'blennocele', 'blennoma', 'bleo', 'blob', 'blobbed', 'bloc', 'block', 'blockade', 'blocked', 'blockman', 'bloke', 'blonde', 'blood', 'blooded', 'bloodleaf', 'bloom', 'bloomfell', 'boba', 'bobac', 'bobbed', 'bobble', 'bobo', 'bocal', 'bocca', 'boccale', 'bocce', 'boce', 'bock', 'bode', 'boden', 'bodle', 'bodock', 'bojo', 'bokadam', 'boke', 'bokom', 'bola', 'bold', 'bolden', 'boldo', 'bole', 'boled', 'bolk', 'boll', 'bolled', 'bollock', 'bolo', 'boloman', 'boma', 'bomb', 'bombable', 'bombed', 'bombo', 'bombola', 'bombonne', 'bonbon', 'bonce', 'bond', 'bonded', 'bondfolk', 'bondman', 'bone', 'boneblack', 'boned', 'bonk', 'boob', 'boobook', 'bood', 'boodle', 'boodledom', 'boof', 'book', 'bookable', 'bookdom', 'booked', 'bookfold', 'bookland', 'bookman', 'bool', 'boom', 'boomable', 'boon', 'boondock', 'boonk', 'caam', 'caama', 'caba', 'cabaan', 'caback', 'cabal', 'cabala', 'caban', 'cabana', 'cabble', 'cabda', 'cable', 'cabled', 'cableman', 'cabman', 'cabob', 'cabocle', 'caboodle', 'cabook', 'cacam', 'cacao', 'cack', 'cackle', 'cacodemon', 'cacoon', 'cadalene', 'cadamba', 'caddle', 'cade', 'cadelle', 'cadence', 'cadenced', 'cadjan', 'cadlock', 'caeca', 'caecal', 'caeoma', 'caffa', 'caffeol', 'caffeone', 'caffle', 'cajole', 'cake', 'calaba', 'calade', 'calamanco', 'calambac', 'calcaneal', 'calced', 'calden', 'calean', 'calendal', 'calf', 'calk', 'call', 'callable', 'callo', 'calm', 'calodemon', 'calomba', 'calomel', 'calool', 'camaca', 'caman', 'camb', 'came', 'camel', 'camelback', 'camelman', 'cameo', 'cammed', 'cammock', 'canaba', 'canada', 'canadol', 'canal', 'canalman', 'canamo', 'cancan', 'cancel', 'cancelable', 'cand', 'candela', 'candle', 'candleball', 'candlebeam', 'candlebomb', 'candock', 'cane', 'canel', 'canella', 'canelo', 'canjac', 'cank', 'canman', 'canna', 'canned', 'cannel', 'cannon', 'cannonade', 'cannoned', 'canoe', 'canoeload', 'canoeman', 'canon', 'canoodle', 'caoba', 'cebell', 'cede', 'celadon', 'cell', 'cella', 'cellae', 'celled', 'cello', 'cembalo', 'cenacle', 'clack', 'clad', 'cladode', 'clam', 'clamb', 'clambake', 'clame', 'clammed', 'clan', 'clank', 'clanned', 'clead', 'cleaded', 'cleam', 'clean', 'cleanable', 'cleck', 'cled', 'clee', 'cleek', 'cleeked', 'clef', 'clem', 'clemence', 'cloaca', 'cloacal', 'cloacean', 'cloak', 'cloaked', 'cloam', 'cloamen', 'clock', 'clocked', 'clockface', 'clod', 'cloff', 'clomb', 'clomben', 'clonal', 'clone', 'cloof', 'coabode', 'coadjacence', 'coak', 'coal', 'cobaea', 'cobbed', 'cobble', 'cobcab', 'coble', 'cobleman', 'cobloaf', 'cobola', 'coca', 'coccal', 'cocco', 'cock', 'cockade', 'cockaded', 'cockal', 'cockbell', 'cocked', 'cockle', 'cockled', 'coco', 'cocoa', 'cocobolo', 'cocoon', 'coda', 'codbank', 'coddle', 'code', 'codman', 'codo', 'codol', 'codon', 'coecal', 'coed', 'coelom', 'coeloma', 'coembedded', 'coenflame', 'coenobe', 'cofeoffee', 'coff', 'coffee', 'coffeecake', 'coffeeleaf', 'coffle', 'coke', 'cokeman', 'cola', 'colane', 'colback', 'colcannon', 'cold', 'cole', 'colecannon', 'colk', 'coll', 'colleen', 'collembolan', 'collembole', 'collocal', 'collock', 'coloboma', 'colocola', 'colon', 'colonel', 'colonnade', 'colonnaded', 'coma', 'comal', 'comb', 'combed', 'comble', 'come', 'comeback', 'comedo', 'comma', 'command', 'commandable', 'commando', 'commandoman', 'commeddle', 'commence', 'commenceable', 'commend', 'commendable', 'commendam', 'commode', 'common', 'commonable', 'conal', 'conamed', 'conceal', 'concealable', 'concealed', 'concede', 'conceded', 'cond', 'condemn', 'condemnable', 'condemned', 'condole', 'condolence', 'condonable', 'condonance', 'condone', 'cone', 'coned', 'coneen', 'confab', 'confocal', 'conjobble', 'conk', 'conkanee', 'conn', 'cooba', 'coodle', 'cooee', 'coof', 'cooja', 'cook', 'cookable', 'cookbook', 'cookdom', 'cookee', 'cool', 'coolen', 'coom', 'coomb', 'coon', 'cooncan', 'dabb', 'dabba', 'dabble', 'dace', 'dada', 'daddle', 'daddock', 'dade', 'dado', 'daedal', 'daemon', 'daff', 'daffle', 'dale', 'daleman', 'dalk', 'dallack', 'dalle', 'dama', 'daman', 'dame', 'damme', 'damn', 'damnable', 'damned', 'dance', 'dand', 'danda', 'dandle', 'dank', 'dannock', 'deacon', 'deaconal', 'dead', 'deaden', 'deadfall', 'deadlock', 'deadman', 'deaf', 'deafen', 'deal', 'dealable', 'dean', 'debacle', 'deben', 'decad', 'decadal', 'decade', 'decadence', 'decal', 'decan', 'decanal', 'decane', 'decence', 'decene', 'decennal', 'deck', 'decke', 'decked', 'deckel', 'deckle', 'deckload', 'decode', 'decoke', 'dedo', 'deed', 'deedeed', 'deem', 'deface', 'defaceable', 'defalk', 'defame', 'defamed', 'defence', 'defend', 'defendable', 'dekko', 'dekle', 'dele', 'delead', 'delenda', 'delf', 'dell', 'demal', 'demand', 'demandable', 'deme', 'demean', 'demob', 'demoded', 'demon', 'demonland', 'denda', 'dene', 'deodand', 'doab', 'doable', 'dobbed', 'dobe', 'dobla', 'doblon', 'dock', 'docken', 'dockland', 'dockman', 'docmac', 'dodd', 'dodded', 'doddle', 'dodecade', 'dodecane', 'dodman', 'dodo', 'doff', 'doke', 'dola', 'dolcan', 'dole', 'doll', 'dolldom', 'dollface', 'dolman', 'dolmen', 'domal', 'domba', 'dome', 'domn', 'donable', 'doncella', 'done', 'donee', 'donjon', 'donna', 'doob', 'doodab', 'doodad', 'doodle', 'dooja', 'dook', 'dool', 'doolee', 'doom', 'doombook', 'doon', 'ebbman', 'eboe', 'ebon', 'ecad', 'ecanda', 'ecbole', 'ecole', 'eddo', 'edea', 'edema', 'eelbob', 'eelcake', 'effable', 'efface', 'effaceable', 'ejoo', 'ekka', 'elance', 'eland', 'elcaja', 'elfenfolk', 'elfland', 'elflock', 'elle', 'elleck', 'elod', 'emball', 'embalm', 'embank', 'embed', 'emblem', 'emblema', 'embolden', 'embole', 'embolo', 'emcee', 'emend', 'emendable', 'emma', 'emoloa', 'enable', 'enaena', 'enam', 'enamel', 'enameloma', 'encake', 'encefalon', 'encell', 'encloak', 'encode', 'encolden', 'encommon', 'endable', 'endameba', 'ended', 'endocoele', 'endocone', 'endolemma', 'endome', 'eneclann', 'enema', 'enface', 'enfeeble', 'enfelon', 'enfeoff', 'enfold', 'enfolden', 'enfonced', 'enjamb', 'enjambed', 'enlace', 'enleaf', 'enlock', 'ennead', 'ennoble', 'enodal', 'enol', 'eoan', 'fabella', 'fable', 'fabled', 'fabledom', 'fableland', 'facadal', 'facade', 'face', 'faceable', 'faced', 'faceman', 'fack', 'fadable', 'faddle', 'fade', 'faded', 'faden', 'faff', 'faffle', 'fake', 'falanaka', 'falbala', 'falcade', 'falcon', 'falconelle', 'faldfee', 'fall', 'fallace', 'fallback', 'fallen', 'famble', 'fame', 'fana', 'fanal', 'fanam', 'fanback', 'fand', 'fandom', 'fanman', 'fannel', 'fanon', 'faon', 'feak', 'feal', 'fecal', 'feck', 'feddan', 'feeable', 'feeble', 'feed', 'feedable', 'feedback', 'feedman', 'feel', 'feelable', 'fell', 'fellable', 'fellen', 'felloe', 'felon', 'female', 'feme', 'fenbank', 'fence', 'fend', 'fendable', 'fenland', 'fenman', 'fennec', 'fennel', 'feod', 'feodal', 'feoff', 'feoffee', 'fjeld', 'flack', 'flacked', 'flaff', 'flak', 'flake', 'flam', 'flamb', 'flame', 'flamed', 'flamen', 'flamenco', 'flammable', 'flan', 'flanconade', 'flandan', 'flane', 'flank', 'flanked', 'flannel', 'flanneled', 'flannelleaf', 'flea', 'fleabane', 'fleadock', 'fleam', 'fleck', 'flecken', 'fleckled', 'flecnodal', 'flecnode', 'fled', 'flee', 'fleece', 'fleeceable', 'fleeced', 'flob', 'floc', 'flock', 'flockman', 'flocoon', 'floe', 'flood', 'floodable', 'floodcock', 'flooded', 'foal', 'foam', 'focal', 'fodda', 'foeman', 'fold', 'foldable', 'folded', 'folden', 'fole', 'folk', 'folkland', 'fondak', 'fondle', 'fono', 'food', 'fool', 'fooldom', 'jabbed', 'jabble', 'jacal', 'jacana', 'jack', 'jackal', 'jackeen', 'jackman', 'jacko', 'jacobaea', 'jacobaean', 'jade', 'jaded', 'jajman', 'jake', 'jako', 'jama', 'jaman', 'jamb', 'jambo', 'jambolan', 'jambone', 'jambool', 'jane', 'jank', 'jann', 'jannock', 'jaob', 'jean', 'jedcock', 'jeddock', 'jeel', 'jeff', 'jelab', 'jell', 'jenna', 'jobade', 'jobble', 'jobman', 'jobo', 'jock', 'jocko', 'jodel', 'jojoba', 'joke', 'joll', 'joola', 'joom', 'kabel', 'kaka', 'kakkak', 'kakke', 'kala', 'kaladana', 'kalamalo', 'kale', 'kalema', 'kalo', 'kalon', 'kamala', 'kamaloka', 'kamao', 'kambal', 'kame', 'kammalan', 'kana', 'kanae', 'kande', 'kandol', 'kanoon', 'kebab', 'keck', 'keckle', 'kedlock', 'keek', 'keel', 'keelblock', 'keeled', 'keelman', 'keen', 'keena', 'keened', 'keffel', 'keld', 'kele', 'kelebe', 'kelek', 'kelk', 'kell', 'kella', 'kemb', 'kenaf', 'kend', 'kennel', 'kennelman', 'kenno', 'keno', 'klam', 'kleeneboc', 'klom', 'knab', 'knabble', 'knack', 'knead', 'kneadable', 'knee', 'kneed', 'kneel', 'knell', 'knob', 'knobbed', 'knobble', 'knock', 'knockoff', 'knoll', 'koae', 'koala', 'koban', 'kobold', 'koda', 'kodak', 'koel', 'koff', 'kokako', 'kokam', 'kokan', 'koko', 'kokoon', 'kola', 'kolea', 'kolo', 'kolokolo', 'kona', 'konak', 'konjak', 'kooka', 'koolokamba', 'labba', 'label', 'labella', 'lablab', 'lacca', 'laccol', 'lace', 'laced', 'laceleaf', 'laceman', 'lack', 'lackland', 'laddock', 'lade', 'lademan', 'laden', 'ladle', 'lake', 'lakeland', 'lall', 'lalo', 'lama', 'lamb', 'lamba', 'lambale', 'lambda', 'lame', 'lamel', 'lamella', 'lammock', 'lance', 'lanced', 'lanceman', 'land', 'landamman', 'landbook', 'landed', 'landfall', 'landflood', 'landlock', 'landlocked', 'landlook', 'landman', 'lane', 'lank', 'lead', 'leadable', 'leadback', 'leaded', 'leaden', 'leadman', 'leadoff', 'leaf', 'leafdom', 'leafed', 'leafen', 'leak', 'leakance', 'leal', 'lealand', 'leam', 'lean', 'leban', 'lebbek', 'lecama', 'leck', 'lede', 'leden', 'ledol', 'leed', 'leek', 'lekane', 'leman', 'lemel', 'lemma', 'lemnad', 'lemon', 'lemonade', 'lenad', 'lend', 'lendable', 'lendee', 'lene', 'leno', 'llama', 'llano', 'load', 'loaded', 'loaden', 'loaf', 'loam', 'loan', 'loanable', 'lobal', 'lobcock', 'lobe', 'lobed', 'lobo', 'lobola', 'loca', 'locable', 'local', 'locale', 'locanda', 'lock', 'lockable', 'locked', 'lockman', 'loco', 'locofoco', 'lode', 'loka', 'lokao', 'loke', 'loll', 'loma', 'lommock', 'lone', 'lood', 'loof', 'look', 'loom', 'loon', 'maam', 'mabolo', 'macaco', 'macadam', 'macan', 'macana', 'macao', 'macco', 'mace', 'maceman', 'mack', 'mackle', 'macle', 'macled', 'maco', 'madam', 'madame', 'madden', 'maddle', 'made', 'madman', 'mado', 'maenad', 'maffle', 'mafoo', 'majo', 'majoon', 'makable', 'make', 'makedom', 'mako', 'mala', 'malacon', 'malambo', 'male', 'malella', 'maleo', 'malfed', 'mall', 'malleable', 'malleal', 'mallee', 'malleolable', 'malm', 'malo', 'mamba', 'mambo', 'mamma', 'mammal', 'mammee', 'mammock', 'mammon', 'mammondom', 'mamo', 'mana', 'manacle', 'manal', 'mancono', 'mand', 'mandala', 'mandola', 'mandom', 'mane', 'maned', 'manjak', 'mank', 'manna', 'mannan', 'mano', 'manoc', 'maomao', 'mbalolo', 'meable', 'mead', 'meak', 'meal', 'mealable', 'mealman', 'mean', 'meaned', 'mecon', 'medal', 'medaled', 'meddle', 'meddlecome', 'meece', 'meed', 'meek', 'meeken', 'mela', 'melada', 'melam', 'melamed', 'melano', 'melanoma', 'meld', 'mele', 'melee', 'melena', 'melene', 'mell', 'mellon', 'melodeon', 'meloe', 'melomane', 'melon', 'memo', 'menace', 'menaceable', 'menacme', 'menald', 'mend', 'mendable', 'mendee', 'mendole', 'menfolk', 'mennom', 'mneme', 'moan', 'mobable', 'mobbable', 'mobed', 'moble', 'mock', 'mockable', 'mockado', 'mocomoco', 'modal', 'mode', 'model', 'modena', 'moellon', 'moff', 'mojo', 'mokaddam', 'moke', 'moko', 'mola', 'molal', 'mold', 'moldable', 'moldmade', 'mole', 'molka', 'molland', 'molle', 'molman', 'momble', 'mome', 'momme', 'momo', 'mona', 'monad', 'monadnock', 'monaene', 'monal', 'mone', 'monel', 'monk', 'monkdom', 'mono', 'monobloc', 'monocle', 'monocled', 'mood', 'moodle', 'mool', 'moon', 'moonack', 'moonbeam', 'mooncalf', 'mooned', 'moonface', 'moonfaced', 'moonfall', 'moonja', 'moonman', 'naam', 'nabak', 'nabk', 'nabla', 'nable', 'nabob', 'nace', 'nacelle', 'nael', 'nake', 'naked', 'nako', 'nakoo', 'namable', 'namda', 'name', 'nameable', 'nammad', 'nana', 'nane', 'nankeen', 'neal', 'neback', 'nebbed', 'nebel', 'neck', 'neckband', 'necked', 'necklace', 'necklaced', 'neckmold', 'need', 'needle', 'needlebook', 'needled', 'needleman', 'neeld', 'neele', 'neem', 'nema', 'neodamode', 'neomodal', 'neon', 'nobble', 'noble', 'nobleman', 'nocake', 'nock', 'nodal', 'noddle', 'node', 'noded', 'noel', 'noll', 'nolle', 'nolo', 'noma', 'nomad', 'nome', 'nomocanon', 'nonadecane', 'nonamendable', 'nonane', 'nonbankable', 'nonblack', 'nonblended', 'nonblockaded', 'nonblooded', 'noncallable', 'noncancellable', 'nonce', 'noncock', 'noncom', 'noncome', 'noncommendable', 'noncommonable', 'noncon', 'nonda', 'nondecadence', 'nondecane', 'nondemand', 'nondo', 'none', 'nonene', 'nonflammable', 'nonfocal', 'nonfood', 'nonleaded', 'nonlocal', 'nonmalleable', 'nonmodal', 'nonnoble', 'nonomad', 'noodle', 'noodledom', 'nook', 'nooked', 'noon', 'oadal', 'oafdom', 'oaken', 'oban', 'oboe', 'obol', 'obole', 'ocean', 'oceaned', 'oclock', 'odal', 'odalman', 'oddman', 'odel', 'odeon', 'odoom', 'oenomel', 'offal', 'offcome', 'offend', 'offendable', 'offended', 'offlook', 'okee', 'olam', 'olden', 'oldland', 'oleana', 'olena', 'oleo', 'olla', 'ollock', 'olomao', 'olona', 'omao', 'omen', 'omened', 'onca', 'once', 'oncome', 'onefold', 'onfall', 'onflemed', 'onlook', 'oolak', 'oolemma']\n",
      "\n",
      "'finger-twisters' for bottom left corner: \n",
      "\n",
      "['ghrush', 'giggish', 'giggit', 'gigglish', 'gill', 'gilt', 'girl', 'girlish', 'girr', 'girsh', 'girt', 'girth', 'gish', 'gist', 'gith', 'gittith', 'glisk', 'glug', 'gluish', 'glut', 'grig', 'grigri', 'grill', 'grip', 'gris', 'grisgris', 'grist', 'grit', 'grith', 'grits', 'grugru', 'grush', 'gruss', 'gugu', 'guhr', 'guilt', 'guitguit', 'gulgul', 'gull', 'gullish', 'gulp', 'gurk', 'gurl', 'gurr', 'gurt', 'guru', 'guruship', 'gush', 'guss', 'gust', 'gutt', 'gutti', 'guttus', 'high', 'highish', 'highlight', 'hight', 'hill', 'hilt', 'hilus', 'hippish', 'hippus', 'hish', 'hiss', 'hist', 'huipil', 'hulk', 'hull', 'hulu', 'hurl', 'hurr', 'hurst', 'hurt', 'hush', 'husk', 'huspil', 'huss', 'hutukhtu', 'illish', 'illth', 'illupi', 'ipil', 'iris', 'iritis', 'irrupt', 'jiggish', 'jilt', 'jiltish', 'jiqui', 'jiti', 'jujitsu', 'juju', 'jujuist', 'jurist', 'just', 'khir', 'khuskhus', 'khutuktu', 'kiki', 'kiku', 'kilhig', 'kill', 'kilp', 'kilt', 'kiri', 'kirk', 'kish', 'kiss', 'kist', 'kith', 'kitish', 'kittlish', 'kittul', 'kivikivi', 'kivu', 'klip', 'kukri', 'kuku', 'kukui', 'kurus', 'kuskus', 'kusti', 'light', 'lightish', 'lightship', 'lighttight', 'lill', 'lilt', 'lish', 'lisk', 'lisp', 'liss', 'list', 'lith', 'lithi', 'littlish', 'liturgist', 'litus', 'lituus', 'lull', 'lulu', 'lupis', 'lupulus', 'lupus', 'lurg', 'lurk', 'lush', 'lusk', 'lust', 'lutist', 'philippus', 'phit', 'phthisis', 'phut', 'piggish', 'piitis', 'piki', 'pili', 'pill', 'pilpul', 'pilpulist', 'pilulist', 'pilus', 'pipi', 'pipiri', 'pipit', 'pirijiri', 'piripiri', 'pirl', 'pirr', 'pish', 'pishu', 'pisk', 'piss', 'pist', 'pistil', 'pith', 'pitpit', 'pituri', 'piuri', 'plight', 'plug', 'plup', 'plus', 'plush', 'prig', 'priggish', 'prill', 'priss', 'prius', 'pruh', 'pruritus', 'prut', 'puggi', 'puggish', 'pugh', 'pugil', 'pugilist', 'puist', 'pukish', 'puku', 'puli', 'pulish', 'pulk', 'pull', 'pulli', 'pullus', 'pulp', 'pulpit', 'pulpitis', 'pulpitish', 'pulu', 'pulvil', 'pulvillus', 'pupil', 'puriri', 'purist', 'purl', 'purplish', 'purr', 'pursuit', 'push', 'puss', 'putt', 'quill', 'quilt', 'quip', 'quippish', 'quipu', 'quirk', 'quirkish', 'quirl', 'quirt', 'quis', 'quit', 'quits', 'riggish', 'right', 'rightist', 'rightship', 'rikk', 'rill', 'ripgut', 'rippit', 'ripup', 'rishi', 'risk', 'riskish', 'risp', 'rist', 'rukh', 'rull', 'ruru', 'rush', 'rushlight', 'rushlit', 'rusk', 'rust', 'ruth', 'ruttish', 'shih', 'shill', 'shilpit', 'ship', 'shirk', 'shirl', 'shirpit', 'shirr', 'shirt', 'shish', 'shiv', 'shrill', 'shrillish', 'shrip', 'shrug', 'shrups', 'shug', 'shul', 'shush', 'shut', 'sigh', 'sight', 'sigil', 'silk', 'sill', 'silt', 'sirih', 'siris', 'sirki', 'sirship', 'sirup', 'sish', 'sisi', 'siss', 'sist', 'sith', 'situs', 'skil', 'skill', 'skilts', 'skip', 'skirl', 'skirp', 'skirr', 'skirt', 'skit', 'skittish', 'skiv', 'skrupul', 'skulk', 'skull', 'skulp', 'slight', 'slightish', 'slip', 'slirt', 'slish', 'slit', 'slug', 'sluggish', 'sluig', 'sluit', 'slur', 'slurp', 'slush', 'slut', 'sluttish', 'spig', 'spill', 'spilt', 'spilth', 'spilus', 'spirit', 'spiritist', 'spiritus', 'spirt', 'spit', 'spitish', 'spiv', 'split', 'splurt', 'sprig', 'sprit', 'sprug', 'spruit', 'spug', 'spur', 'spurl', 'spurt', 'sput', 'squirish', 'squirk', 'squirr', 'squirt', 'squirtish', 'squish', 'squit', 'squush', 'sruti', 'still', 'stillish', 'stilt', 'stiltish', 'stir', 'stirk', 'stirp', 'stirps', 'stirrup', 'stith', 'strig', 'stright', 'strigil', 'strigilis', 'strip', 'strippit', 'stript', 'strit', 'strut', 'struth', 'struv', 'stug', 'stull', 'stupp', 'sturk', 'sturt', 'stuss', 'stut', 'sugh', 'sugi', 'suist', 'suit', 'suji', 'sulk', 'sull', 'sulphur', 'surplus', 'susi', 'suslik', 'susu', 'susurr', 'susurrus', 'thig', 'thigh', 'thight', 'thilk', 'thill', 'thir', 'thirl', 'thirst', 'thirt', 'this', 'thistlish', 'thlipsis', 'thrill', 'thrip', 'thrips', 'thrush', 'thrust', 'thruv', 'thug', 'thuggish', 'thulir', 'thulr', 'thuluth', 'thurl', 'thurt', 'thus', 'tight', 'tightish', 'tights', 'tikitiki', 'tikur', 'till', 'tilt', 'tilth', 'tiltup', 'tipiti', 'tiptilt', 'tipup', 'tirl', 'tirr', 'titi', 'titlist', 'tittup', 'titulus', 'trig', 'trikir', 'trilit', 'trilith', 'trill', 'trilli', 'trip', 'trippist', 'tripsill', 'tripsis', 'trist', 'trisul', 'tritish', 'trug', 'truish', 'trull', 'trush', 'truss', 'trust', 'truth', 'tugrik', 'tugui', 'tuik', 'tulip', 'tulipist', 'tulsi', 'tupik', 'turk', 'turkis', 'turp', 'turps', 'turr', 'tururi', 'turus', 'tush', 'tusk', 'tuskish', 'tussis', 'tussur', 'tuth', 'tuts', 'tutti', 'tutu', 'tutulus', 'ulitis', 'uluhi', 'ululu', 'upgirt', 'upgush', 'uphill', 'uphurl', 'uplight', 'uppish', 'uppull', 'uppush', 'upright', 'uprightish', 'uprights', 'uprip', 'uprist', 'uprush', 'upshut', 'upsit', 'upslip', 'upspurt', 'upstir', 'upsup', 'upthrust', 'uptill', 'uptilt', 'uptrill', 'uptruss', 'ursuk', 'uruisg', 'urus', 'urushi', 'usurp', 'utsuk', 'uvulitis', 'vigil', 'vill', 'villitis', 'villus', 'virilist', 'virl', 'virtu', 'virus', 'visit', 'vulgus', 'vulturish', 'vulvitis']\n",
      "\n",
      "'finger-twisters' for bottom right corner: \n",
      "\n",
      "['jokul', 'joky', 'joll', 'jolly', 'jolt', 'jolty', 'joom', 'jotty', 'jouk', 'jowl', 'jowly', 'juju', 'junk', 'junt', 'junto', 'jutty', 'jynx', 'klom', 'knoll', 'knolly', 'knot', 'knotty', 'knout', 'know', 'known', 'knut', 'knutty', 'koko', 'kokoon', 'koku', 'kokum', 'kolo', 'kolokolo', 'koto', 'kotuku', 'kotukutuku', 'kowtow', 'kozo', 'kuku', 'kulm', 'kunk', 'llyn', 'loll', 'lolly', 'look', 'lookout', 'lookum', 'loom', 'loon', 'loony', 'loot', 'lotto', 'louk', 'loukoum', 'loulu', 'lout', 'louty', 'lowly', 'lown', 'lownly', 'lowy', 'loxotomy', 'lull', 'lulu', 'lummox', 'lummy', 'lunn', 'lunt', 'lynx', 'mojo', 'moko', 'mokum', 'moky', 'molly', 'molt', 'moly', 'mommy', 'momo', 'monk', 'monkly', 'monny', 'mono', 'monont', 'mononym', 'mononymy', 'monotony', 'monoxylon', 'montjoy', 'monton', 'mool', 'moolum', 'moon', 'moony', 'moot', 'motmot', 'mott', 'motto', 'moul', 'mouly', 'mount', 'mout', 'mouton', 'mown', 'mowt', 'moyo', 'mukluk', 'mulk', 'mull', 'mulmul', 'mult', 'multum', 'mummy', 'munj', 'munt', 'mutt', 'mutton', 'muttony', 'mutuum', 'muzz', 'muzzy', 'myomotomy', 'myotomy', 'myotony', 'myowun', 'myxo', 'myzont', 'noll', 'nolo', 'nonly', 'nonyl', 'nook', 'nooky', 'noon', 'notum', 'noun', 'nowt', 'nowy', 'null', 'nullo', 'nunky', 'nutty', 'nylon', 'onlook', 'only', 'onto', 'onym', 'onymy', 'onyx', 'oolly', 'oont', 'oozy', 'otkon', 'ototomy', 'otto', 'outjut', 'outlook', 'outly', 'outmount', 'outnook', 'ovolo', 'ovum', 'owly', 'oxyl', 'toko', 'toll', 'tolly', 'tolt', 'tolu', 'toluol', 'toluyl', 'tolyl', 'tommy', 'tonjon', 'tonk', 'tony', 'took', 'tool', 'toom', 'toomly', 'toon', 'toot', 'toozoo', 'toto', 'totty', 'totum', 'toty', 'tout', 'town', 'townly', 'towny', 'towy', 'toxon', 'toyon', 'toytown', 'tummy', 'tumtum', 'tumult', 'tunk', 'tunmoot', 'tunny', 'tuno', 'tunu', 'tuny', 'tutly', 'tutty', 'tutu', 'ulmo', 'ululu', 'unjolly', 'unknot', 'unknotty', 'unknow', 'unknown', 'unknownly', 'unlook', 'unlowly', 'unmonkly', 'unmount', 'unmown', 'unown', 'unto', 'untown', 'untz', 'unwon', 'unwooly', 'utum', 'uvulotomy', 'volt', 'vuln', 'wonky', 'wonnot', 'wont', 'wool', 'woolly', 'woom', 'woon', 'wootz', 'woozy', 'wowt', 'wulk', 'wull', 'wuzu', 'wuzzy', 'wynn', 'xylol', 'xylon', 'xylotomy', 'xyloyl', 'xylyl', 'yoky', 'yolk', 'yolky', 'yont', 'yook', 'youl', 'yowl', 'yowt', 'yummy', 'yutu', 'yuzluk', 'zloty', 'zoll', 'zoom', 'zoon', 'zoonomy', 'zootomy', 'zoozoo']\n"
     ]
    }
   ],
   "source": [
    "# Quickest way to get a string of the lowercase letters\n",
    "import string\n",
    "\n",
    "abc = list(string.ascii_lowercase)\n",
    "\n",
    "# Make a nested list matching the letters to the numbers in the T9 system.\n",
    "# For the sake of consistency, I'll add two empty lists for 0 (because Python\n",
    "# is zero indexed) and 1 (because it has no letters in the T9 system)\n",
    "T9 = [[], []]\n",
    "for i in range(2, 10):\n",
    "    # most numbers have three letters assigned to them\n",
    "    k = 3\n",
    "    # but 7 and 9 have four \n",
    "    if i in (7, 9):\n",
    "        k = 4\n",
    "    l = \"\"\n",
    "    for j in range(0, k):\n",
    "        l += (abc.pop(0))\n",
    "    T9.append([l])\n",
    "\n",
    "# Names of the different combinations:\n",
    "# Not strictly necessary, but it looks nicer when we print everything\n",
    "names = [\"top row\", \"middle row\", \"bottom row\", \"left column\", \"middle column\",\n",
    "         \"right column\", \"top left corner\", \"top right corner\", \n",
    "         \"bottom left corner\", \"bottom right corner\"]\n",
    "    \n",
    "# numbers in the different combinations\n",
    "combos = [[2, 3], [4, 5, 6], [7, 8, 9], [4, 7], [2, 5, 8], [3, 6, 9], [2, 4, 5], [2, 3, 5, 6],\n",
    " [4, 5, 7, 8], [5, 6, 8, 9]]\n",
    "\n",
    "# create strings of candidate letters for each combination\n",
    "candidate_letters = []\n",
    "for c in combos:\n",
    "    search_string = ''\n",
    "    for n in c:\n",
    "        search_string += T9[n][0]\n",
    "    candidate_letters.append(search_string)\n",
    "\n",
    "# search over each of the strings of candidate letters\n",
    "for i in range(len(combos)):\n",
    "    print(\"\\n'finger-twisters' for\", names[i] +\": \\n\")\n",
    "\n",
    "    # excluding results that are shorter than the number of keys\n",
    "    print([w for w in wordlist if re.search('^[' + candidate_letters[i] + ']+$', w) and len(w) >= len(combos[i])])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Examples of __Kleene closures__:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['miiiiiiiiiiiiinnnnnnnnnnneeeeeeeeee',\n",
       " 'miiiiiinnnnnnnnnneeeeeeee',\n",
       " 'mine',\n",
       " 'mmmmmmmmiiiiiiiiinnnnnnnnneeeeeeee']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words = sorted(set(w for w in nltk.corpus.nps_chat.words()))\n",
    "[w for w in chat_words if re.search('^m+i+n+e+$', w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'aaaaaaaaaaaaaaaaa', 'aaahhhh', 'ah', 'ahah', 'ahahah', 'ahh', 'ahhahahaha', 'ahhh', 'ahhhh', 'ahhhhhh', 'ahhhhhhhhhhhhhh', 'h', 'ha', 'haaa', 'hah', 'haha', 'hahaaa', 'hahah', 'hahaha', 'hahahaa', 'hahahah', 'hahahaha', 'hahahahaaa', 'hahahahahaha', 'hahahahahahaha', 'hahahahahahahahahahahahahahahaha', 'hahahhahah', 'hahhahahaha']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in chat_words if re.search('^[ha]+$', w)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A `^` inside square brackets means to exclude everything with these characters.  `<<^[^aeiouAEIOU]+$>>` would match everything without a vowel:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '!!', '!!!', '!!!!', '!!!!!', '!!!!!!', '!!!!!!!', '!!!!!!!!', '!!!!!!!!!', '!!!!!!!!!!', '!!!!!!!!!!!', '!!!!!!!!!!!!!', '!!!!!!!!!!!!!!!!', '!!!!!!!!!!!!!!!!!!!!!!', '!!!!!!!!!!!!!!!!!!!!!!!', '!!!!!!!!!!!!!!!!!!!!!!!!!!!', '!!!!!!!!!!!!!!!!!!!!!!!!!!!!', '!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!', '!!!!!!.', '!!!!!.', '!!!!....', '!!!.', '!!.', '!!...', '!.', '!...', '!=', '!?', '!??', '!???', '\"', '\"...', '\"?', '\"s', '#', '###', '####', '$', '$$', '$27', '&', '&^', \"'\", \"''\", \"'.\", \"'d\", \"'ll\", \"'m\", \"'n'\", \"'s\", '(', '(((', '((((', '(((((', '((((((', '(((((((', '((((((((', '(((((((((', '((((((((((', '(((((((((((', '((((((((((((', '(((((((((((((', '((((((((((((((', '(((((((((((((((', '(((((((((((((((((', '((((((((((((((((((', '((((((((((((((((((((', '(((((((((((((((((((((', '(((((((((((((((((((((((', '((((((((((((((((((((((((', '(((((((((((((((((((((((((', '((((((((((((((((((((((((((', '(((((..', '(*&(^', '(.', ')', ')))', '))))', ')))))', ')))))))', '))))))))', ')))))))))', '))))))))))', ')))))))))))', '))))))))))))', ')))))))))))))', '))))))))))))))', ')))))))))))))))', ')))))))))))))))))', ')))))))))))))))))))', ')))))))))))))))))))))', '))))))))))))))))))))))', '))))))))))))))))))))))))))))', ')))))))))))))))))))))))))))))))', ')?', '*', '******', '*VBS*', '+', '+*+*+*+*', '++', ',', ',,', ',,,', ',,,,', ',,,,,', ',,,,,,,', ',,,,,,,,,,,', '-', '-(', '--', '-------------', '--------------------', '--------->', '-->', '-...)...-', '-17', '-21', '-6', '-_-', '-s', '.', '. .', '. . .', '. ...', '.(.', '.(..(.vMp3 v1.7.4.).)', '.)', '.).', '..', '.. .', '..(..', '...', '....', '.....', '......', '.......', '........', '.........', '..........', '...........', '............', '.............', '................', '..................', '...................', '....................', '........................', '..............................', '.45', '.:', '.;)', '/', '//', '0', '05.', '06.', '1', '1.98', '1.99', '10', '100', '100%', '1012.', '1016.', '102.6', '10:49', '10th', '11', '12', '12%', '1200', '121.7', '1299', '13', '138', '14', '14-16', '147.7', '15', '16', '16.', '17', '18', '185', '18ST', '19', '1900', '1930', '1980', '1985', '1996', '2', '2.3', '20', '20.', '2006', '20S', '20s', '21', '22', '220', '224', '23', '24', '246', '247', '25', '26', '27', '28', '280', '28147', '29', '29.88.', '295', '29803', '2:55', '2nd', '3', '30', '30.', '30.00.', '300', '31', '32', '33', '3333333', '33982', '34', '35', '36', '360', '37', '38', '39', '39.3', '396', '3:45', '3~<-..4@.', '4', '4.20', '41', '423', '43', '43.', '45', '45.5', '453', '46', '46.', '47', '47.', '49', '4:03', '5', '50', '51', '53', '55', '55%', '55.', '56', '56.', '57', '57401', '579', '59', '59%', '6', '60', '60s', '64.8', '65%', '68%', '69', '6:38', '6:41', '6:51', '6:53', '7', '70%', '700', '73%', '73042', '75', '75%', '76%', '77', '7:45', '8', '80', '8082653953', '818', '85%', '9', '9.53', '90', '92129', '92780', '93', '93%', '95953', '98.5', '98.6', '99', '99701', '99703', '9:10', ':', ':(', ':)', ':):):)', ':-(', ':-)', ':-@', ':.', ':/', ':@', ':D', ':P', ':]', ':p', ':|', ';', '; ..', ';)', ';-(', ';-)', ';0', ';]', ';p', '<', '<,', '<-', '<--', '<---', '<----', '<----------', '<3', \"<3's\", '<33', '<333', '<3333', '<33333', '<333333333', '<3333333333333333', '<33333333333333333', '<<', '<<<', '<<<<', '<<<<,', '<<<<<', '<<<<<<', '<<<<<<,', '<<<<<<<', '<<<<<<<<<<<<<<', '<~~~', '=', \"='s\", '=(', '=)', '=-\\\\', '=/', '=D', '=[', '=]', '=p', '>', '>.>', '>.>->', '>:->', '>>>', '>>>>>>>>>>', '>>>>>>>>>>>', '>>>>>>>>>>>>', '>?', '>_>', '?', '?!', '?!?!', '?!?!?', \"?'\", '?.', '?..', '?....', '??', '??!!', '??!?!??!', '???', '????', '?????', '??????', '???????', '????????', '?????????', '??@', '@', '@$$', \"@-,'~\", \"@..3-,'~.\", 'B', 'C', 'CDT', 'CST', 'CT', 'Cry', 'Ct', 'Ctrl', 'D', 'DJ', 'DVD', 'Dr', 'Dr.', 'F', 'F5', 'FF', 'FL', 'G', 'GN', 'GNG', 'GrlZ', 'Gs', 'H', 'H0rny', 'Hmm', 'JRZ', 'K', 'LPN', 'M', 'MD', 'MP3', 'MSN', 'MY', 'Mmm', 'Mp3', 'Ms', 'My', 'N', 'N\"T', \"N'T\", 'NC', 'NTMN', 'NY', 'P', 'P.', 'PDT', 'PM', \"PM's\", 'PMSL', 'PMs', 'PS', 'PST', 'Plssss', 'PmS', 'QQ', 'R', \"RN's\", 'S', 'S.M.R.', 'S3x0r', 'St', 'TC', 'TX', 'TY', 'TYPR', 'Ty', 'W', 'WHY', 'WTF', 'Wb', 'Why', 'Wtf', 'X', 'XXXXXXXXXX', '[[[[[[[[[[[[[[[[[[', '\\\\', '\\\\ty', ']:)', ']]]]]]]]]]]]]]]]]]]]]', '^', '^^', '^^^', '^_^', '_', '`', 'b', 'b/c', 'b4', 'bbl', 'bbs', 'bc', 'bf', 'bj', 'brb', 'brbbb', 'brrrrrrr', 'brwn', 'btw', 'by', 'byb', 'c', \"c'm\", 'chp', 'ck', 'cpr', 'cry', 'cyb3r', 'd', 'd=', 'dd', 'dj', 'dl', 'dr', 'dry', 'dsklgjsdk', 'f', 'f.', 'fck', 'fl', 'fly', 'frm', 'frst', 'ft', 'ft.', 'fwd', \"g'\", 'gf', 'gm', 'gn', 'grrl', 'grrr', 'grrrrrrrr', 'grrrrrrrrr', 'grrrrrrrrrrrrrrrrr', 'gtg', 'h', 'h.s', 'hb', 'hfglhs', 'hgfhgfjgf', 'hm', 'hmm', 'hmmm', 'hmmmm', 'hmmmmm', 'hmmmmmmm', 'hmmmmmmmm', 'hmmmmmmmmmm', 'hmph', 'hr', 'hrs', 'http', 'hx', 'hyy', 'j', 'j/k', 'j/p', 'jk', 'jr', 'jw', 'k', \"k's\", 'kc', 'kmph', 'knw', 'kts', 'ky', 'l', 'lb', 'lbs', 'ldskdlsf', 'll', 'ltnc', 'ltns', 'ltr', 'm', 'md', 'mhm', 'mm', 'mmhmm', 'mmm', 'mmmm', 'mmmmk', 'mmmmm', 'mmmmmm', 'mmmmmmmmmm', 'mmmmmmmmmmmmm', 'mmmmmmmmmmmmmm', 'mp3', 'ms', 'ms.', 'msg', 'msn', 'my', 'n', 'n\"t', \"n't\", 'n.n', 'n/', 'n;t', 'nbc', 'nc', 'nd', 'nj', 'nm', 'ny', 'nyc', 'nz', 'p', 'pc', 'pffft', 'pfft', 'plz', 'pm', \"pm'n\", \"pm's\", 'pms', 'pmsl', 'pp', 'ppl', 'pr', 'prrty', 'ps2', 'psh', 'pssssh', 'pssst', 'pvt', 'pwns', 'px', 'r', 's', \"s'\", 'sdlfkjsj', 'sf', 'shhhh', 'sky', 'sldfjlsdf', 'slkfjsldkfjs', 'sp', 'sry', 'st', 'sw', 'syck', 't', 't/c', 't/y', 'tc', 'td', 'tdr', 'thnx', 'thx', 'tks', 'try', 'tv', 'tx', 'ty', 'tyvm', 'vm', 'vs.', 'w', 'w/', 'w/b', 'wb', 'wc', 'why', 'whys', 'wtf', 'wth', 'wv', 'wz', 'x', 'xD', 'xxxxxx', 'y', \"y'\", 'y/w', 'yr', 'yrs', 'ysssssssss', 'yvw', 'yw', \"yw's\", 'zzzzzzzz', '~', '~!']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in chat_words if re.search('^[^aeiouAEIOU]+$', w)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Your Turn:__ Study the ~~above~~ __(below)__ examples and try to work out what the `\\`, `{}`, `()`, and `|` notations mean before you read on.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.0085', '0.05', '0.1', '0.16', '0.2', '0.25', '0.28', '0.3', '0.4', '0.5', '0.50', '0.54', '0.56', '0.60', '0.7', '0.82', '0.84', '0.9', '0.95', '0.99', '1.01', '1.1', '1.125', '1.14', '1.1650', '1.17', '1.18', '1.19', '1.2', '1.20', '1.24', '1.25', '1.26', '1.28', '1.35', '1.39', '1.4', '1.457', '1.46', '1.49', '1.5', '1.50', '1.55', '1.56', '1.5755', '1.5805', '1.6', '1.61', '1.637', '1.64']\n"
     ]
    }
   ],
   "source": [
    "wsj = sorted(set(nltk.corpus.treebank.words()))\n",
    "print([w for w in wsj if re.search('^[0-9]+\\.[0-9]+$', w)][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C$', 'US$']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[A-Z]+\\$$', w)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*`\\` is used as an escape character.  Normally, `.` is a wildcard character and `$` is used to designate the end of a string.  Here we'd like to search for strings composed of numbers with a decimal and for alphabetic strings with a dollar sign, so we need to escape the characters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1614', '1637', '1787', '1901', '1903', '1917', '1925', '1929', '1933', '1934', '1948', '1953', '1955', '1956', '1961', '1965', '1966', '1967', '1968', '1969', '1970', '1971', '1972', '1973', '1975', '1976', '1977', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986', '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999', '2000', '2005', '2009', '2017', '2019', '2029', '3057', '8300']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in wsj if re.search('^[0-9]{4}$', w)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10-day', '10-lap', '10-year', '100-share', '12-point', '12-year', '14-hour', '15-day', '150-point', '190-point', '20-point', '20-stock', '21-month', '237-seat', '240-page', '27-year', '30-day', '30-point', '30-share', '30-year', '300-day', '36-day', '36-store', '42-year', '50-state', '500-stock', '52-week', '69-point', '84-month', '87-store', '90-day']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in wsj if re.search('^[0-9]+-[a-z]{3,5}$', w)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['black-and-white',\n",
       " 'bread-and-butter',\n",
       " 'father-in-law',\n",
       " 'machine-gun-toting',\n",
       " 'savings-and-loan']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in wsj if re.search('^[a-z]{5,}-[a-z]{2,3}-[a-z]{,6}$', w)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*`{ }` are used to restrict the size of the returned hits. `{n}` means only those strings of length $n$.  `{n,}` means those strings at least as long as $n$.  `{,n}` means those strings no longer than $n$.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['62%-owned', 'Absorbed', 'According', 'Adopting', 'Advanced', 'Advancing', 'Alfred', 'Allied', 'Annualized', 'Anything', 'Arbitrage-related', 'Arbitraging', 'Asked', 'Assuming', 'Atlanta-based', 'Baking', 'Banking', 'Beginning', 'Beijing', 'Being', 'Bermuda-based', 'Betting', 'Boeing', 'Broadcasting', 'Bucking', 'Buying', 'Calif.-based', 'Change-ringing', 'Citing', 'Concerned', 'Confronted', 'Conn.based', 'Consolidated', 'Continued', 'Continuing', 'Declining', 'Defending', 'Depending', 'Designated', 'Determining', 'Developed', 'Died', 'During', 'Encouraged', 'Encouraging', 'English-speaking', 'Estimated', 'Everything', 'Excluding', 'Exxon-owned']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in wsj if re.search('(ed|ing)$', w)][:50])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The `|` means to match either of these strings.  When used with parentheses, it can be combined with other operators.  E.g., in the example above `'(ed|ing)$'` returns strings that end with either `ed` or `ing`.  But without the parenthesis, the `$` operator is attached only to `ing`, so the code below will find strings that have `ed` anywhere within their string, or `ing` at their end.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['62%-owned', 'Absorbed', 'According', 'Adopting', 'Advanced', 'Advancing', 'Alfred', 'Allied', 'Annualized', 'Anything', 'Arbitrage-related', 'Arbitraging', 'Asked', 'Assuming', 'Atlanta-based', 'Baking', 'Banking', 'Beginning', 'Beijing', 'Being', 'Bermuda-based', 'Betting', 'Biedermann', 'Boeing', 'Breeden', 'Broadcasting', 'Bucking', 'Buying', 'Calif.-based', 'Cathedral', 'Cedric', 'Change-ringing', 'Citing', 'Concerned', 'Confederation', 'Confronted', 'Conn.based', 'Consolidated', 'Continued', 'Continuing', 'Credit', 'Declining', 'Defending', 'Depending', 'Designated', 'Determining', 'Developed', 'Died', 'During', 'Encouraged']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in wsj if re.search('ed|ing$', w)][:50])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Basic Regular Expression Meta-Characters, Including Wildcards, Ranges and Closures__*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Operator        | Behavior                                                 |\n",
    "|:-----------|:--------------------------------------------------------------------------------|\n",
    "| `.`        | Wildcard, matches any character                                                 |\n",
    "| `^abc`     | Matches some pattern $abc$ at the start of a string                               |\n",
    "| `abc$`     | Matches some pattern $abc$ at the end of a string                                 |\n",
    "| `[abc]`    | Matches one of a set of characters                                              |\n",
    "| `[A-Z0-9]` | Matches one of a range of characters                                            |\n",
    "| `ed|ing|s` | Matches one of the specified strings (disjunction)                              |\n",
    "| `*`        | Zero or more of previous item, e.g. `a*`, `[a-z]*` (also known   as $Kleene Closure$) |\n",
    "| `+`        | One or more of previous item, e.g. `a+`, `[a-z]+`                                   |\n",
    "| `?`        | Zero or one of the previous item (i.e. optional),   e.g. `a?`, `[a-z]?`             |\n",
    "| `{n}`      | Exactly $n$ repeats where $n$ is a non-negative integer                             |\n",
    "| `{n,}`     | At least $n$ repeats                                                              |\n",
    "| `{,n}`     | No more than $n$ repeats                                                          |\n",
    "| `{m,n}`    | At least $m$ and no more than $n$ repeats                                           |\n",
    "| `a(b|c)+`  | Parentheses that indicate the scope of the operators                            |\n",
    "|            |                                                                                 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5   Useful Applications of Regular Expressions\n",
    "\n",
    "*Using `re.findall()` to find and count the vowels in a word:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u', 'e', 'a', 'i', 'a', 'i', 'i', 'i', 'e', 'i', 'a', 'i', 'o', 'i', 'o', 'u']\n"
     ]
    }
   ],
   "source": [
    "word = 'supercalifragilisticexpialidocious'\n",
    "print(re.findall(r'[aeiou]', word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(re.findall(r'[aeiou]', word))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If we only want the number of hits, we can also use this:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1 for r in re.findall(r'[aeiou]', word)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sequences of two or more vowels and their relative frequencies:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('io', 549), ('ea', 476), ('ie', 331), ('ou', 329), ('ai', 261), ('ia', 253), ('ee', 217), ('oo', 174), ('ua', 109), ('au', 106), ('ue', 105), ('ui', 95)]\n"
     ]
    }
   ],
   "source": [
    "wsj = sorted(set(nltk.corpus.treebank.words()))\n",
    "fd = nltk.FreqDist(vs for word in wsj\n",
    "                   for vs in re.findall(r'[aeiou]{2,}', word))\n",
    "print(fd.most_common(12))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Your Turn:__ In the W3C Date Time Format, dates are represented like this: 2009-12-31. Replace the `?` in the following Python code with a regular expression, in order to convert the string `'2009-12-31'` to a list of integers `[2009, 12, 31]`:\n",
    "\n",
    "`[int(n) for n in re.findall(?, '2009-12-31')]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2009, 12, 31]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(n) for n in re.findall(r'[0-9]{2,}', '2009-12-31')]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Doing More with Word Pieces\n",
    "\n",
    "*Removing internal vowels from a text:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unvrsl Dclrtn of Hmn Rghts Prmble Whrs rcgntn of the inhrnt dgnty and\n",
      "of the eql and inlnble rghts of all mmbrs of the hmn fmly is the fndtn\n",
      "of frdm , jstce and pce in the wrld , Whrs dsrgrd and cntmpt fr hmn\n",
      "rghts hve rsltd in brbrs acts whch hve outrgd the cnscnce of mnknd ,\n",
      "and the advnt of a wrld in whch hmn bngs shll enjy frdm of spch and\n"
     ]
    }
   ],
   "source": [
    "regexp = r'^[AEIOUaeiou]+|[^AEIOUaeiou]|[AEIOUaeiou]+$'\n",
    "def compres(word):\n",
    "    pieces = re.findall(regexp, word)\n",
    "    return ''.join(pieces)\n",
    "\n",
    "english_udhr = nltk.corpus.udhr.words('English-Latin1')\n",
    "print(nltk.tokenwrap(compres(w) for w in english_udhr[:75]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finding frequencies of consonant-vowel sequences from the words of Rotokas:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   e   i   o   u \n",
      "k 418 148  94 420 173 \n",
      "p  83  31 105  34  51 \n",
      "r 187  63  84  89  79 \n",
      "s   0   0 100   2   1 \n",
      "t  47   8   0 148  37 \n",
      "v  93  27 105  48  49 \n"
     ]
    }
   ],
   "source": [
    "rotokas_words = nltk.corpus.toolbox.words('rotokas.dic')\n",
    "cvs = [cv for w in rotokas_words for cv in re.findall(r'[ptksvr][aeiou]', w)]\n",
    "cfd = nltk.ConditionalFreqDist(cvs)\n",
    "cfd.tabulate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Making an index of all possible consonant-vowel pairs in the language:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kasuari']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_word_pairs = [(cv, w) for w in rotokas_words\n",
    "                         for cv in re.findall(r'[ptksvr][aeiou]', w)]\n",
    "cv_index = nltk.Index(cv_word_pairs)\n",
    "cv_index['su']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kaapo', 'kaapopato', 'kaipori', 'kaiporipie', 'kaiporivira', 'kapo', 'kapoa', 'kapokao', 'kapokapo', 'kapokapo', 'kapokapoa', 'kapokapoa', 'kapokapora', 'kapokapora', 'kapokaporo', 'kapokaporo', 'kapokari', 'kapokarito', 'kapokoa', 'kapoo', 'kapooto', 'kapoovira', 'kapopaa', 'kaporo', 'kaporo', 'kaporopa', 'kaporoto', 'kapoto', 'karokaropo', 'karopo', 'kepo', 'kepoi', 'keposi', 'kepoto']\n"
     ]
    }
   ],
   "source": [
    "print(cv_index['po'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finding Word Stems\n",
    "\n",
    "*A simple approach:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    for suffix in ['ing', 'ly', 'ed', 'ious', 'ies', 'ive', 'es', 's', 'ment']:\n",
    "        if word.endswith(suffix):\n",
    "            return word[:-len(suffix)]\n",
    "    return word"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A step-by-step outline of how we could use RegExp:*\n",
    "\n",
    "*Here's a disjunction of all the suffixes:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ing']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^.*(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This just returns the suffix because the `( )` also selects which substring to return.  If we want the parentheses to specify the scope of the disjunction, but not select the material to be output, we have to add `?:`:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['processing']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^.*(?:ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Since we want this split, we have to parenthesize both parts of the regular expression:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('process', 'ing')]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^(.*)(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processing')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Let's try it with a different form of the word:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('processe', 's')]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^(.*)(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processes')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Star operators are by default greedy and will try to 'consume' as much of the input as possible.  We can turn this off with `*?`:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('process', 'es')]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)$', 'processes')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We can allow for empty strings by adding `?`:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('language', '')]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$', 'language')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Encasing this in a function:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word):\n",
    "    regexp = r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$'\n",
    "    stem, suffix = re.findall(regexp, word)[0]\n",
    "    return stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DENNIS', ':', 'Listen', ',', 'strange', 'women', 'ly', 'in', 'pond', 'distribut', 'sword', 'i', 'no', 'basi', 'for', 'a', 'system', 'of', 'govern', '.', 'Supreme', 'execut', 'power', 'deriv', 'from', 'a', 'mandate', 'from', 'the', 'mass', ',', 'not', 'from', 'some', 'farcical', 'aquatic', 'ceremony', '.']\n"
     ]
    }
   ],
   "source": [
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
    "is no basis for a system of government.  Supreme executive power derives from\n",
    "a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
    "tokens = word_tokenize(raw)\n",
    "print([stem(t) for t in tokens])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Searching Tokenized Text\n",
    "\n",
    "*`<a> <man>` will find all instances of __a man__ in a text.  The angle brackets are used to mark token boundaries, and white space is ignored (this only applies to NLTK `findall()` method for texts.  Here, we'll look for all occurrences of \"a _ _ _ man\" in \"Moby Dick\".  The parentheses within the search term limits the returned string, so only the word between \"a\" and \"man\" is returned:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monied; nervous; dangerous; white; white; white; pious; queer; good;\n",
      "mature; white; Cape; great; wise; wise; butterless; white; fiendish;\n",
      "pale; furious; better; certain; complete; dismasted; younger; brave;\n",
      "brave; brave; brave\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg, nps_chat\n",
    "moby = nltk.Text(gutenberg.words('melville-moby_dick.txt'))\n",
    "moby.findall(r\"<a> (<.*>) <man>\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Now we'll look at the chat corpus and find three-word phrases ending with \"bro\":*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you rule bro; telling you bro; u twizted bro\n"
     ]
    }
   ],
   "source": [
    "chat = nltk.Text(nps_chat.words())\n",
    "chat.findall(r\"<.*><.*><bro>\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This finds sequences of three or more words starting with __l__:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lol lol lol; lmao lol lol; lol lol lol; la la la la la; la la la; la\n",
      "la la; lovely lol lol love; lol lol lol.; la la la; la la la\n"
     ]
    }
   ],
   "source": [
    "chat.findall(r\"<l.*>{3,}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your Turn:__ Consolidate your understanding of regular expression patterns and substitutions using `nltk.re_show(p, s)` which annotates the string `s` to show every place where pattern `p` was matched, and `nltk.app.nemo()` which provides a graphical interface for exploring regular expressions. For more practice, try some of the exercises on regular expressions at the end of this chapter.\n",
    "\n",
    "*For `nltk.re_show(p, s)`, `p` cannot be a regular expression (a fact which could have been made clearer...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When you come to a fork in the road, take it.\n"
     ]
    }
   ],
   "source": [
    "yogi = \"When you come to a fork in the road, take it.\"\n",
    "nltk.re_show(r\"<f.*k>\", yogi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When you come to a {fork} in the road, take it.\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show(\"fork\", yogi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When you come to a {fork in the road, tak}e it.\n"
     ]
    }
   ],
   "source": [
    "nltk.re_show(\"f.*k\", yogi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*`nltk.app.nemo()` can be used in jupyter notebooks, but it opens an external window which will prevent the other cells in the notebook from running until it's closed. Therefore, I'm not going to call it in this notebook.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We can use RegExs to search for linguistic phenomena.  E.g., we can find hypernyms by looking for __x and other ys__:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speed and other activities; water and other liquids; tomb and other\n",
      "landmarks; Statues and other monuments; pearls and other jewels;\n",
      "charts and other items; roads and other features; figures and other\n",
      "objects; military and other areas; demands and other factors;\n",
      "abstracts and other compilations; iron and other metals\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "hobbies_learned = nltk.Text(brown.words(categories = ['hobbies', 'learned']))\n",
    "hobbies_learned.findall(r\"<\\w*> <and> <other> <\\w*s>\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*But this does result in false positives (e.g., \"demands and other factors\"), and can also result in false negitives.*\n",
    "\n",
    "__Your Turn__: Look for instances of the pattern *as x as y* to discover information about entities and their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as soon as possible; as well as the; as soon as possible; as long as\n",
      "they; as well as representatives; as far as instructed; as long as\n",
      "there; as late as the; as well as a; as much as we; as many as 25; as\n",
      "many as 25; as thoroughly as the; as well as the; as well as his; as\n",
      "great as Mankowski; as long as their; as soon as possible; as soon as\n",
      "the; as early as the; as soon as trading; as well as its; as abrupt as\n",
      "in; as severe as in; as well as to; as carefully as she; as well as\n",
      "golden; as harmless as a; as far as a; as well as a; as good as those;\n",
      "as automatically as it; as well as the; as long as one; as many as\n",
      "six; as good as Hamilton; as large as Western; as hard as I; as much\n",
      "as possible; as early as 1950; as well as bound; as many as a; as much\n",
      "as the; as innocent as it; as well as wit; as much as my; as well as\n",
      "wit; as funny as Ed; as fast as we\n"
     ]
    }
   ],
   "source": [
    "brown_sample = nltk.Text(brown.words(categories=['humor', 'news']))\n",
    "brown_sample.findall(r\"<as> <\\w*> <as> <\\w*>\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A number of idioms tend to dominate the results (i.e., \"as soon as possible\", \"as well as ...\"), so let's remove theses.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as long as they; as far as instructed; as long as there; as late as\n",
      "the; as much as we; as many as 25; as many as 25; as great as\n",
      "Mankowski; as long as their; as abrupt as in; as severe as in; as far\n",
      "as a; as good as those; as long as one; as many as six; as good as\n",
      "Hamilton; as large as Western; as hard as I; as much as possible; as\n",
      "many as a; as much as the; as innocent as it; as much as my; as funny\n",
      "as Ed; as fast as we\n"
     ]
    }
   ],
   "source": [
    "brown_sample = nltk.Text(brown.words(categories=['humor', 'news']))\n",
    "brown_sample.findall(r\"<as> <\\w*[^well][^soon]> <as> <\\w*>\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We could also make the argument that most uses of \"as long as ...\" are also idiomatic and could be eliminated.  But this would lead to false negatives.*  \n",
    "\n",
    "*I would also say that these results might be more useful if we could also see more of the phrase from which these results were taken:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as long as they can; as far as instructed so; as long as there is; as\n",
      "late as the top; as much as we can; as many as 25 home; as many as 25\n",
      "bases; as great as Mankowski did; as long as their names; as abrupt as\n",
      "in 1958; as severe as in late; as far as a black; as good as those\n",
      "elsewhere; as long as one pretends; as many as six strokes; as good as\n",
      "Hamilton Holmes; as large as Western Europe; as hard as I could; as\n",
      "many as a thousand; as much as the ambiguous; as innocent as it looks;\n",
      "as much as my husband; as funny as Ed Wynn; as fast as we replenished\n"
     ]
    }
   ],
   "source": [
    "brown_sample = nltk.Text(brown.words(categories=['humor', 'news']))\n",
    "brown_sample.findall(r\"<as> <\\w*[^well][^soon]> <as> <\\w*>{2}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6   Normalizing Text\n",
    "\n",
    "##### Stemmers\n",
    "\n",
    "The Porter and Lancaster stemmers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['denni', ':', 'listen', ',', 'strang', 'women', 'lie', 'in', 'pond', 'distribut', 'sword', 'is', 'no', 'basi', 'for', 'a', 'system', 'of', 'govern', '.', 'suprem', 'execut', 'power', 'deriv', 'from', 'a', 'mandat', 'from', 'the', 'mass', ',', 'not', 'from', 'some', 'farcic', 'aquat', 'ceremoni', '.']\n"
     ]
    }
   ],
   "source": [
    "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
    "is no basis for a system of government.  Supreme executive power derives from\n",
    "a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
    "tokens = word_tokenize(raw)\n",
    "porter = nltk.PorterStemmer()\n",
    "lancaster = nltk.LancasterStemmer()\n",
    "print([porter.stem(t) for t in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['den', ':', 'list', ',', 'strange', 'wom', 'lying', 'in', 'pond', 'distribut', 'sword', 'is', 'no', 'bas', 'for', 'a', 'system', 'of', 'govern', '.', 'suprem', 'execut', 'pow', 'der', 'from', 'a', 'mand', 'from', 'the', 'mass', ',', 'not', 'from', 'som', 'farc', 'aqu', 'ceremony', '.']\n"
     ]
    }
   ],
   "source": [
    "print([lancaster.stem(t) for t in tokens])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Texts can be indexed using a stemmer, and from there concordances can be made:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexedText(object):\n",
    "    \n",
    "    def __init__(self, stemmer, text):\n",
    "        self._text = text\n",
    "        self._stemmer = stemmer\n",
    "        self._index = nltk.Index((self._stem(word), i)\n",
    "                                 for (i, word) in enumerate(text))\n",
    "        \n",
    "    def concordance(self, word, width = 40):\n",
    "        key = self._stem(word)\n",
    "        wc = int(width/4)\n",
    "        for i in self._index[key]:\n",
    "            lcontext = ' '.join(self._text[i - wc : i])\n",
    "            rcontext = ' '.join(self._text[i : i + wc])\n",
    "            ldisplay = '{:>{width}}'.format(lcontext[-width:], width = width)\n",
    "            rdisplay = '{:{width}}'.format(rcontext[:width], width = width)\n",
    "            print(ldisplay, rdisplay)\n",
    "            \n",
    "    def _stem(self, word):\n",
    "        return self._stemmer.stem(word).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r king ! DENNIS : Listen , strange women lying in ponds distributing swords is no\n",
      " beat a very brave retreat . ROBIN : All lies ! MINSTREL : [ singing ] Bravest of\n",
      "       Nay . Nay . Come . Come . You may lie here . Oh , but you are wounded !   \n",
      "doctors immediately ! No , no , please ! Lie down . [ clap clap ] PIGLET : Well  \n",
      "ere is much danger , for beyond the cave lies the Gorge of Eternal Peril , which \n",
      "   you . Oh ... TIM : To the north there lies a cave -- the cave of Caerbannog --\n",
      "h it and lived ! Bones of full fifty men lie strewn about its lair . So , brave k\n",
      "not stop our fight ' til each one of you lies dead , and the Holy Grail returns t\n"
     ]
    }
   ],
   "source": [
    "grail = nltk.corpus.webtext.words('grail.txt')\n",
    "text = IndexedText(porter, grail)\n",
    "text.concordance('lie')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lemmatization\n",
    "\n",
    "*The WordNet lemmatizer:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DENNIS', ':', 'Listen', ',', 'strange', 'woman', 'lying', 'in', 'pond', 'distributing', 'sword', 'is', 'no', 'basis', 'for', 'a', 'system', 'of', 'government', '.', 'Supreme', 'executive', 'power', 'derives', 'from', 'a', 'mandate', 'from', 'the', 'mass', ',', 'not', 'from', 'some', 'farcical', 'aquatic', 'ceremony', '.']\n"
     ]
    }
   ],
   "source": [
    "wnl = nltk.WordNetLemmatizer()\n",
    "print([wnl.lemmatize(t) for t in tokens])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7   Regular Expressions for Tokenizing Text\n",
    "\n",
    "##### Simple Approaches to Tokenization\n",
    "\n",
    "*Just splitting on whitespace with the string method `.split`:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'When\", \"I'M\", 'a', \"Duchess,'\", 'she', 'said', 'to', 'herself,', '(not', 'in', 'a', 'very', 'hopeful', 'tone', 'though),', \"'I\", \"won't\", 'have', 'any', 'pepper', 'in', 'my', 'kitchen', 'AT', 'ALL.', 'Soup', 'does', 'very', 'well', 'without--Maybe', \"it's\", 'always', 'pepper', 'that', 'makes', 'people', \"hot-tempered,'...\"]\n"
     ]
    }
   ],
   "source": [
    "raw = \"\"\"'When I'M a Duchess,' she said to herself, (not in a very hopeful tone\n",
    "though), 'I won't have any pepper in my kitchen AT ALL. Soup does very\n",
    "well without--Maybe it's always pepper that makes people hot-tempered,'...\"\"\"\n",
    "\n",
    "print(raw.split())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The regular expression is similar, but we need to add code so that it handles tabs and whitespaces:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'When\", \"I'M\", 'a', \"Duchess,'\", 'she', 'said', 'to', 'herself,', '(not', 'in', 'a', 'very', 'hopeful', 'tone\\nthough),', \"'I\", \"won't\", 'have', 'any', 'pepper', 'in', 'my', 'kitchen', 'AT', 'ALL.', 'Soup', 'does', 'very\\nwell', 'without--Maybe', \"it's\", 'always', 'pepper', 'that', 'makes', 'people', \"hot-tempered,'...\"]\n"
     ]
    }
   ],
   "source": [
    "print(re.split(r' ', raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'When\", \"I'M\", 'a', \"Duchess,'\", 'she', 'said', 'to', 'herself,', '(not', 'in', 'a', 'very', 'hopeful', 'tone', 'though),', \"'I\", \"won't\", 'have', 'any', 'pepper', 'in', 'my', 'kitchen', 'AT', 'ALL.', 'Soup', 'does', 'very', 'well', 'without--Maybe', \"it's\", 'always', 'pepper', 'that', 'makes', 'people', \"hot-tempered,'...\"]\n"
     ]
    }
   ],
   "source": [
    "print(re.split(r'[ \\t\\n]+', raw))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We can do this more easily with the built-in `re` abbreviation `\\s`:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'When\", \"I'M\", 'a', \"Duchess,'\", 'she', 'said', 'to', 'herself,', '(not', 'in', 'a', 'very', 'hopeful', 'tone', 'though),', \"'I\", \"won't\", 'have', 'any', 'pepper', 'in', 'my', 'kitchen', 'AT', 'ALL.', 'Soup', 'does', 'very', 'well', 'without--Maybe', \"it's\", 'always', 'pepper', 'that', 'makes', 'people', \"hot-tempered,'...\"]\n"
     ]
    }
   ],
   "source": [
    "print(re.split(r'\\s+', raw))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Remember that when regular expressions are prefixed with `r`, the Python interpreter will treat the string literally.*\n",
    "\n",
    "*`\\w` is the character class (equivalent to `[a-zA-Z0-9_]`), and the complement to this is `\\W` (which seems very counter intuitive to me...).  We could use `\\W` to split a text on anything but a word character:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'When', 'I', 'M', 'a', 'Duchess', 'she', 'said', 'to', 'herself', 'not', 'in', 'a', 'very', 'hopeful', 'tone', 'though', 'I', 'won', 't', 'have', 'any', 'pepper', 'in', 'my', 'kitchen', 'AT', 'ALL', 'Soup', 'does', 'very', 'well', 'without', 'Maybe', 'it', 's', 'always', 'pepper', 'that', 'makes', 'people', 'hot', 'tempered', '']\n"
     ]
    }
   ],
   "source": [
    "print(re.split(r'\\W+', raw))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*But this leaves us with empty strings at the beginning and end.  We could avoid this by using `re.findall(r'\\w+', raw)`:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When', 'I', 'M', 'a', 'Duchess', 'she', 'said', 'to', 'herself', 'not', 'in', 'a', 'very', 'hopeful', 'tone', 'though', 'I', 'won', 't', 'have', 'any', 'pepper', 'in', 'my', 'kitchen', 'AT', 'ALL', 'Soup', 'does', 'very', 'well', 'without', 'Maybe', 'it', 's', 'always', 'pepper', 'that', 'makes', 'people', 'hot', 'tempered']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(r'\\w+', raw))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A more complicated RegEx will first try to match any sequence of word characters; if it can't find a match, it will use `\\S` to find non-whitespace charcters.  In this way, punctuation is grouped with following letters, but sequences of punctuation will be separated:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'When\", 'I', \"'M\", 'a', 'Duchess', ',', \"'\", 'she', 'said', 'to', 'herself', ',', '(not', 'in', 'a', 'very', 'hopeful', 'tone', 'though', ')', ',', \"'I\", 'won', \"'t\", 'have', 'any', 'pepper', 'in', 'my', 'kitchen', 'AT', 'ALL', '.', 'Soup', 'does', 'very', 'well', 'without', '-', '-Maybe', 'it', \"'s\", 'always', 'pepper', 'that', 'makes', 'people', 'hot', '-tempered', ',', \"'\", '.', '.', '.']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(r'\\w+|\\S\\w*', raw))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If we want to include internal hyphens and apostrophes, we could use this: `re.findall(r\"\\w+(?:[-']\\w+)*|'|[-.(]+|\\S\\w*\", raw)`.  `<<\\w+(?:[-']\\w+)*>>` means `\\w+` followed by zero or more instances of `[-']\\w+`, which matches strings like __hot-tempered__ and __it's__.  We have to include `?:` to return the entire string.  We also need to separate quote chatacters `|'|`, and `<<[-.(]+>>` will allow double hyphens, ellipses, etc... to be tokenized separately:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'\", 'When', \"I'M\", 'a', 'Duchess', ',', \"'\", 'she', 'said', 'to', 'herself', ',', '(', 'not', 'in', 'a', 'very', 'hopeful', 'tone', 'though', ')', ',', \"'\", 'I', \"won't\", 'have', 'any', 'pepper', 'in', 'my', 'kitchen', 'AT', 'ALL', '.', 'Soup', 'does', 'very', 'well', 'without', '--', 'Maybe', \"it's\", 'always', 'pepper', 'that', 'makes', 'people', 'hot-tempered', ',', \"'\", '...']\n"
     ]
    }
   ],
   "source": [
    "print(re.findall(r\"\\w+(?:[-']\\w+)*|'|[-.(]+|\\S\\w*\", raw))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Regular Expression Symbols\n",
    "\n",
    "\n",
    "|Symbol| Function                                 |\n",
    "|:-----|:-------------------------------------------------------------|\n",
    "| `\\b` | Word boundary (zero width)                                   |\n",
    "| `\\d` | Any decimal digit (equivalent to `[0-9]`)                     |\n",
    "| `\\D` | Any non-digit character (equivalent to `[^0-9]`)               |\n",
    "| `\\s` | Any whitespace character (equivalent to `[ \\t\\n\\r\\f\\v]`)       |\n",
    "| `\\S` | Any non-whitespace character (equivalent to `[^ \\t\\n\\r\\f\\v]`)  |\n",
    "| `\\w` | Any alphanumeric character (equivalent to `[a-zA-Z0-9_]`)      |\n",
    "| `\\W` | Any non-alphanumeric character (equivalent to `[^a-zA-Z0-9_]`) |\n",
    "| `\\t` | The tab character                                            |\n",
    "| `\\n` | The newline character                                        |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NLTK's Regular Expression Tokenizer\n",
    "\n",
    "*`nltk.regexp_tokenizer()` is similar to `re.findall()`, but is more efficient, and avoids the need for special treatment of parentheses. The `(?x)` flag tells Python to strip out the embedded whitespace and comments:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['That', 'U.S.A.', 'poster-print', 'costs', '$12.40', '...']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'That U.S.A. poster-print costs $12.40...'\n",
    "pattern = r'''(?x)     # set flag to allow verbose regexps\n",
    "    (?:[A-Z]\\.)+       # abbreviations, e.g. U.S.A.\n",
    "  | \\w+(?:-\\w+)*       # words with optional internal hyphens\n",
    "  | \\$?\\d+(?:\\.\\d+)?%? # currency and percentages, e.g. $12.40, 82%\n",
    "  | \\.\\.\\.             # ellipsis\n",
    "  | [][.,;\"'?():-_`]   # these are separate tokens; includes ], [\n",
    "  '''\n",
    "nltk.regexp_tokenize(text, pattern)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If we use the verbose flag, we can't use `' '` to match a space character - we have to use `\\s`.  Also, `regexp_tokenizer()` has an optional `gaps` parameter that specifies the gaps between tokens:*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We can evaluate a tokenizer by seeing how many of the resulting tokens are not in a wordlist:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '--',\n",
       " '.',\n",
       " '...',\n",
       " 'hot-tempered',\n",
       " \"i'm\",\n",
       " \"it's\",\n",
       " 'makes',\n",
       " \"won't\"}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [w.lower() for w in re.findall(r\"\\w+(?:[-']\\w+)*|'|[-.(]+|\\S\\w*\", raw)]\n",
    "set(tokens).difference(wordlist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Further Issues with Tokenization\n",
    "\n",
    "### 3.8 Sementation\n",
    "\n",
    "##### Sentence Segmentation\n",
    "\n",
    "*Average number of word per sentence in the Brown Corpus:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.250994070456922"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nltk.corpus.brown.words()) / len(nltk.corpus.brown.sents())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Example of the Punkt sentence segmeneter:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Nonsense!\"',\n",
      " 'said Gregory, who was very rational when anyone else\\nattempted paradox.',\n",
      " '\"Why do all the clerks and navvies in the\\n'\n",
      " 'railway trains look so sad and tired, so very sad and tired?',\n",
      " 'I will\\ntell you.',\n",
      " 'It is because they know that the train is going right.',\n",
      " 'It\\n'\n",
      " 'is because they know that whatever place they have taken a ticket\\n'\n",
      " 'for that place they will reach.',\n",
      " 'It is because after they have\\n'\n",
      " 'passed Sloane Square they know that the next station must be\\n'\n",
      " 'Victoria, and nothing but Victoria.',\n",
      " 'Oh, their wild rapture!',\n",
      " 'oh,\\n'\n",
      " 'their eyes like stars and their souls again in Eden, if the next\\n'\n",
      " 'station were unaccountably Baker Street!\"',\n",
      " '\"It is you who are unpoetical,\" replied the poet Syme.']\n"
     ]
    }
   ],
   "source": [
    "text = nltk.corpus.gutenberg.raw('chesterton-thursday.txt')\n",
    "sents = nltk.sent_tokenize(text)\n",
    "pprint.pprint(sents[79:89])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Word Segmentation\n",
    "\n",
    "*Example of a joined text and a simple segmenter:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(text, segs):\n",
    "    words = []\n",
    "    last = 0\n",
    "    for i in range(len(segs)):\n",
    "        if segs[i] == '1':\n",
    "            words.append(text[last : i + 1])\n",
    "            last = i + 1\n",
    "    words.append(text[last:])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"doyouseethekittyseethedoggydoyoulikethekittylikethedoggy\"\n",
    "seg1 = \"0000000000000001000000000010000000000000000100000000000\"\n",
    "seg2 = \"0100100100100001001001000010100100010010000100010010000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment(text, seg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['do', 'you', 'see', 'the', 'kitty', 'see', 'the', 'doggy', 'do', 'you', 'like', 'the', 'kitty', 'like', 'the', 'doggy']\n"
     ]
    }
   ],
   "source": [
    "print(segment(text, seg2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I've always found the explanation of the following to be a bit lacking.  The solution involves search, which is technically a machine learning topic.  Dealing with machine learning techniques just a couple chapters after covering Python basics such as printing strings and indexing is an incredible acceleration in the level of difficulty.  Suffice to say, the following section presents some functions that are __muuuuuuuuuuch__ too difficult for this part of the book.*\n",
    "\n",
    "*The __TLDR__ version of the topic is this: it's possible to create an objective function and that will score a segmentation of a text.  The segmentation divides the string into a lexicon and a derivation that uses the words in this lexicon.  The smaller the lengths of the lexical items and the derivations, the better the score.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\brent.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[147], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m display(Image(filename \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mC:\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mUsers\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mmjcor\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mDesktop\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mProgrammingStuff\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mnltk\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mbrent.png\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\display.py:970\u001b[0m, in \u001b[0;36mImage.__init__\u001b[1;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata, alt)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munconfined \u001b[39m=\u001b[39m unconfined\n\u001b[0;32m    969\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malt \u001b[39m=\u001b[39m alt\n\u001b[1;32m--> 970\u001b[0m \u001b[39msuper\u001b[39;49m(Image, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(data\u001b[39m=\u001b[39;49mdata, url\u001b[39m=\u001b[39;49murl, filename\u001b[39m=\u001b[39;49mfilename,\n\u001b[0;32m    971\u001b[0m         metadata\u001b[39m=\u001b[39;49mmetadata)\n\u001b[0;32m    973\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mwidth\u001b[39m\u001b[39m'\u001b[39m, {}):\n\u001b[0;32m    974\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth \u001b[39m=\u001b[39m metadata[\u001b[39m'\u001b[39m\u001b[39mwidth\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\display.py:327\u001b[0m, in \u001b[0;36mDisplayObject.__init__\u001b[1;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 327\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreload()\n\u001b[0;32m    328\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_data()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\display.py:1005\u001b[0m, in \u001b[0;36mImage.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1003\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed:\n\u001b[1;32m-> 1005\u001b[0m     \u001b[39msuper\u001b[39;49m(Image,\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mreload()\n\u001b[0;32m   1006\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretina:\n\u001b[0;32m   1007\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retina_shape()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\IPython\\core\\display.py:353\u001b[0m, in \u001b[0;36mDisplayObject.reload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    352\u001b[0m     encoding \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_flags \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 353\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilename, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_flags, encoding\u001b[39m=\u001b[39;49mencoding) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    354\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[0;32m    355\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m     \u001b[39m# Deferred import\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\brent.png'"
     ]
    }
   ],
   "source": [
    "display(Image(filename = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\brent.png\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The objective function looks quite straightforward:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(text, segs):\n",
    "    words = segment(text, segs)\n",
    "    text_size = len(words)\n",
    "    lexicon_size = sum(len(word) + 1 for word in set(words))\n",
    "    return text_size + lexicon_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We'll use the same text and segmentations as earlier, and add one more:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['doyou', 'see', 'thekitt', 'y', 'see', 'thedogg', 'y', 'doyou', 'like', 'thekitt', 'y', 'like', 'thedogg', 'y']\n"
     ]
    }
   ],
   "source": [
    "text = \"doyouseethekittyseethedoggydoyoulikethekittylikethedoggy\"\n",
    "seg1 = \"0000000000000001000000000010000000000000000100000000000\"\n",
    "seg2 = \"0100100100100001001001000010100100010010000100010010000\"\n",
    "seg3 = \"0000100100000011001000000110000100010000001100010000001\"\n",
    "print(segment(text, seg3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(text, seg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(text, seg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(text, seg3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The fact that the second segmentation - which represents the correct segmentation in natural English - has a lower score than the third - which segments \"thekitty\" and \"thedoggy\" respectively into (\"thekitt\", \"y\") and (\"thedogg\", \"y\") - is to me concerning.  Either this heuristic or the example are not ideal.  It's possible with a longer text, the heuristic could isolate \"the\". I feel the example would have been that much easier to follow if the authors had picked a sample that did this.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Next, we have to search for the optimal string segmentation.  The first function is simple enough: it just flips a binary digit at a given position;*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(segs, pos):\n",
    "    return segs[:pos] + str(1 - int(segs[pos])) + segs[pos + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11011'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg = \"11111\"\n",
    "flip(seg, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The second function flips n digits at random positions:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def flip_n(segs, n):\n",
    "    for i in range(n):\n",
    "        segs = flip(segs, randint(0, len(segs) - 1))\n",
    "    return segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10111111111'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg = \"11111111111\"\n",
    "flip_n(seg, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*It will almost certainly give different results every time it's called:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01010111111'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg = \"11111111111\"\n",
    "flip_n(seg, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01011111011'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg = \"11111111111\"\n",
    "flip_n(seg, 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The third part is the clusterf\\*^k.  The number of possible segmentation strings in $2^n$, where $n$ is the length of the text.  Since our text is 56 characters long, the number of possible segmentations would be 72,057,594,037,927,936.  To evaluate all of those would take years on most machines.*\n",
    "\n",
    "*So the function below uses a technique called \"annealing\" (there's a decent wiki [here](https://en.wikipedia.org/wiki/Simulated_annealing \"simulated annealing\")).  Another __TLDR__ explanation:  instead of trying all 72,057,594,037,927,936 possibilities, we'll try a small subset - here, 5,000.  Then we'll take the best result of that subset, and use that for the basis of the next 5,000 trials.  At each step, the number of digits in our segmentation that is randomly flipped will become smaller and smaller, and as a result we'll slowly converge on a \"good\" estimate. (I say \"good\", because there's no guarantee we'll find the optimal solution).  The reference to \"annealing\" is because of our use of a \"cooling rate\" - a parameter that determines the speed at which we converge to our solution.  If the cooling rate is too high, we'll converge too quickly and the solution may not be very good; but if the rates too low, the convergence will be very slow.*\n",
    "\n",
    "*And yes, if you're wondering, I'm in no way qualified to be instructing anyone about machine learning.  But take a look for yourself at the code, and you'll see that this is what basically happens:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anneal(text, segs, iterations, cooling_rate):\n",
    "    temperature = float(len(segs))\n",
    "    while temperature > 0.5:\n",
    "        best_segs, best = segs, evaluate(text, segs)\n",
    "        for i in range(iterations):\n",
    "            guess = flip_n(segs, round(temperature))\n",
    "            score = evaluate(text, guess)\n",
    "            if score < best:\n",
    "                best, best_segs = score, guess\n",
    "        score, segs = best, best_segs\n",
    "        temperature = temperature / cooling_rate\n",
    "        print(evaluate(text, segs), segment(text, segs))\n",
    "    print()\n",
    "    return segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "59 ['doyous', 'ee', 'thekitty', 'se', 'ethedoggy', 'd', 'oyoul', 'ike', 'thekitty', 'lik', 'ethedoggy']\n",
      "59 ['doyous', 'ee', 'thekitty', 'se', 'ethedoggy', 'd', 'oyoul', 'ike', 'thekitty', 'lik', 'ethedoggy']\n",
      "59 ['doyous', 'ee', 'thekitty', 'se', 'ethedoggy', 'd', 'oyoul', 'ike', 'thekitty', 'lik', 'ethedoggy']\n",
      "59 ['doyous', 'ee', 'thekitty', 'se', 'ethedoggy', 'd', 'oyoul', 'ike', 'thekitty', 'lik', 'ethedoggy']\n",
      "57 ['d', 'oyousee', 'thekitty', 'se', 'ethedoggy', 'doyoul', 'ike', 'thekitty', 'lik', 'ethedoggy']\n",
      "57 ['d', 'oyousee', 'thekitty', 'se', 'ethedoggy', 'doyoul', 'ike', 'thekitty', 'lik', 'ethedoggy']\n",
      "55 ['doyouse', 'e', 'thekitty', 'se', 'ethedoggy', 'doyoulike', 'thekitty', 'lik', 'ethedoggy']\n",
      "50 ['doyou', 'se', 'e', 'thekitty', 'se', 'ethedoggy', 'doyou', 'like', 'thekitty', 'lik', 'ethedoggy']\n",
      "49 ['doyou', 's', 'e', 'e', 'thekitty', 'se', 'ethedoggy', 'doyou', 'lik', 'e', 'thekitty', 'lik', 'ethedoggy']\n",
      "46 ['doyou', 'se', 'e', 'thekitty', 'se', 'ethedoggy', 'doyou', 'lik', 'e', 'thekitty', 'lik', 'ethedoggy']\n",
      "43 ['doyou', 'se', 'ethekitty', 'se', 'ethedoggy', 'doyou', 'lik', 'ethekitty', 'lik', 'ethedoggy']\n",
      "43 ['doyou', 'se', 'ethekitty', 'se', 'ethedoggy', 'doyou', 'lik', 'ethekitty', 'lik', 'ethedoggy']\n",
      "43 ['doyou', 'se', 'ethekitty', 'se', 'ethedoggy', 'doyou', 'lik', 'ethekitty', 'lik', 'ethedoggy']\n",
      "43 ['doyou', 'se', 'ethekitty', 'se', 'ethedoggy', 'doyou', 'lik', 'ethekitty', 'lik', 'ethedoggy']\n",
      "43 ['doyou', 'se', 'ethekitty', 'se', 'ethedoggy', 'doyou', 'lik', 'ethekitty', 'lik', 'ethedoggy']\n",
      "43 ['doyou', 'se', 'ethekitty', 'se', 'ethedoggy', 'doyou', 'lik', 'ethekitty', 'lik', 'ethedoggy']\n",
      "43 ['doyou', 'se', 'ethekitty', 'se', 'ethedoggy', 'doyou', 'lik', 'ethekitty', 'lik', 'ethedoggy']\n",
      "43 ['doyou', 'se', 'ethekitty', 'se', 'ethedoggy', 'doyou', 'lik', 'ethekitty', 'lik', 'ethedoggy']\n",
      "43 ['doyou', 'se', 'ethekitty', 'se', 'ethedoggy', 'doyou', 'lik', 'ethekitty', 'lik', 'ethedoggy']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0000101000000001010000000010000100100000000100100000000'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"doyouseethekittyseethedoggydoyoulikethekittylikethedoggy\"\n",
    "seg1 = \"0000000000000001000000000010000000000000000100000000000\"\n",
    "anneal(text, seg1, 5000, 1.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Because we're using random elements, the end result will likely be somewhat different every time.  Therefore, there's no guarantee this algorithm will find the optimal solution.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "63 ['doyous', 'eethekitty', 'seeth', 'edoggy', 'doyoulikethekittylike', 'th', 'edoggy']\n",
      "63 ['doyous', 'eethekitty', 'seeth', 'edoggy', 'doyoulikethekittylike', 'th', 'edoggy']\n",
      "60 ['doyous', 'eeth', 'ekittys', 'eeth', 'edoggy', 'doyoulikethekittylike', 'th', 'edoggy']\n",
      "59 ['doyou', 'seeth', 'ekitt', 'y', 'seeth', 'edoggy', 'doyou', 'likethekittyl', 'ike', 'th', 'edoggy']\n",
      "59 ['doyou', 'seeth', 'ekitt', 'y', 'seeth', 'edoggy', 'doyou', 'likethekittyl', 'ike', 'th', 'edoggy']\n",
      "57 ['doyou', 'seeth', 'ekit', 'ty', 'seeth', 'edoggy', 'doyou', 'likethekittyl', 'iketh', 'edoggy']\n",
      "53 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'likethekittyliketh', 'edoggy']\n",
      "53 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'likethekittyliketh', 'edoggy']\n",
      "51 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'do', 'you', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "51 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'do', 'you', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "51 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'do', 'you', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "51 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'do', 'you', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "43 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "43 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "43 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "43 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "43 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "43 ['doyou', 'seeth', 'ekitty', 'seeth', 'edoggy', 'doyou', 'liketh', 'ekitty', 'liketh', 'edoggy']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0000100001000001000010000010000100000100000100000100000'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anneal(text, seg1, 5000, 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11011'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg = \"11111\"\n",
    "flip(seg, 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We might get better results if we lower the `cooling_rate`, but we'll also need more time to run the algorithm.  __Warning:__ The `cooling_rate` should never go to 1.0 or below.  If we do that, the algorithm will run forever.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "64 ['doyouseethekitty', 'seethedoggy', 'doyoulikethekitty', 'likethedoggy']\n",
      "62 ['doyo', 'us', 'eethekitt', 'y', 'see', 'thedoggy', 'doyo', 'ulikethekitty', 'like', 'thedoggy']\n",
      "62 ['doyo', 'us', 'eethekitt', 'y', 'see', 'thedoggy', 'doyo', 'ulikethekitty', 'like', 'thedoggy']\n",
      "62 ['doyo', 'us', 'eethekitt', 'y', 'see', 'thedoggy', 'doyo', 'ulikethekitty', 'like', 'thedoggy']\n",
      "62 ['doyo', 'us', 'eethekitt', 'y', 'see', 'thedoggy', 'doyo', 'ulikethekitty', 'like', 'thedoggy']\n",
      "62 ['doyo', 'us', 'eethekitt', 'y', 'see', 'thedoggy', 'doyo', 'ulikethekitty', 'like', 'thedoggy']\n",
      "62 ['doyo', 'us', 'eethekitt', 'y', 'see', 'thedoggy', 'doyo', 'ulikethekitty', 'like', 'thedoggy']\n",
      "62 ['doyo', 'us', 'eethekitt', 'y', 'see', 'thedoggy', 'doyo', 'ulikethekitty', 'like', 'thedoggy']\n",
      "62 ['doyo', 'us', 'eethekitt', 'y', 'see', 'thedoggy', 'doyo', 'ulikethekitty', 'like', 'thedoggy']\n",
      "62 ['doyo', 'us', 'eethekitt', 'y', 'see', 'thedoggy', 'doyo', 'ulikethekitty', 'like', 'thedoggy']\n",
      "62 ['doyo', 'us', 'eethekitt', 'y', 'see', 'thedoggy', 'doyo', 'ulikethekitty', 'like', 'thedoggy']\n",
      "60 ['doyo', 'us', 'eethekitt', 'ysee', 'thedoggy', 'doyo', 'ulikethekitty', 'like', 'thedoggy']\n",
      "58 ['doyou', 's', 'ee', 'thekitt', 'ysee', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "58 ['doyou', 's', 'ee', 'thekitt', 'ysee', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "58 ['doyou', 's', 'ee', 'thekitt', 'ysee', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "56 ['doyou', 's', 'eethekitt', 'ysee', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "56 ['doyou', 's', 'eethekitt', 'ysee', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "56 ['doyou', 's', 'eethekitt', 'ysee', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "56 ['doyou', 's', 'eethekitt', 'ysee', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "54 ['doyou', 'seethe', 'kittysee', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "54 ['doyou', 'seethe', 'kittysee', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "54 ['doyou', 'seethe', 'kittysee', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "54 ['doyou', 'seethe', 'kittysee', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "53 ['doy', 'ou', 'seet', 'hekitty', 'see', 'thedoggy', 'doy', 'ou', 'like', 't', 'hekitty', 'like', 'thedoggy']\n",
      "53 ['doy', 'ou', 'seet', 'hekitty', 'see', 'thedoggy', 'doy', 'ou', 'like', 't', 'hekitty', 'like', 'thedoggy']\n",
      "51 ['doyou', 'see', 't', 'hekitty', 'see', 'thedoggy', 'doyou', 'liket', 'hekitty', 'like', 'thedoggy']\n",
      "51 ['doyou', 'see', 't', 'hekitty', 'see', 'thedoggy', 'doyou', 'liket', 'hekitty', 'like', 'thedoggy']\n",
      "46 ['doyou', 'see', 't', 'hekitty', 'see', 'thedoggy', 'doyou', 'like', 't', 'hekitty', 'like', 'thedoggy']\n",
      "46 ['doyou', 'see', 't', 'hekitty', 'see', 'thedoggy', 'doyou', 'like', 't', 'hekitty', 'like', 'thedoggy']\n",
      "46 ['doyou', 'see', 't', 'hekitty', 'see', 'thedoggy', 'doyou', 'like', 't', 'hekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "43 ['doyou', 'see', 'thekitty', 'see', 'thedoggy', 'doyou', 'like', 'thekitty', 'like', 'thedoggy']\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0000100100000001001000000010000100010000000100010000000'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anneal(text, seg1, 5000, 1.05)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9   Formatting: From Lists to Strings\n",
    "\n",
    "##### From Lists to Strings\n",
    "\n",
    "*__No notes.__*\n",
    "\n",
    "##### Strings and Formats\n",
    "\n",
    "*__No notes.__*\n",
    "\n",
    "##### Lining Things Up\n",
    "\n",
    "*We can add padding to formatted strings with `:`.  The number in the bracket refers to the width of the new string.  Numbers are right-justified by default, and strings are left-justified:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We called him Tortoise because he taught us .\n",
      "We;called;him;Tortoise;because;he;taught;us;.\n",
      "WecalledhimTortoisebecausehetaughtus.\n",
      "cat\n",
      "hello\n",
      "world\n",
      "dog -> 4 ; cat -> 3 ; snake -> 1 ; dog->4; cat->3; snake->1; cat->3;\n",
      "cat->\n",
      "3\n",
      "I want a coffee right now\n",
      "Lee wants a sandwich for lunch\n",
      "Lee wants a sandwich right now\n",
      "Lee wants a spam fritter right now\n",
      "Lee wants a pancake right now\n"
     ]
    }
   ],
   "source": [
    "silly = ['We', 'called', 'him', 'Tortoise', 'because', 'he', 'taught', 'us', '.']\n",
    "print(' '.join(silly))\n",
    "print(';'.join(silly))\n",
    "print(''.join(silly))\n",
    "\n",
    "word = 'cat'\n",
    "sentence = \"\"\"hello\n",
    "world\"\"\"\n",
    "print(word)\n",
    "print(sentence)\n",
    "\n",
    "fdist = nltk.FreqDist(['dog', 'cat', 'dog', 'cat', 'dog', 'snake', 'dog', 'cat'])\n",
    "for word in fdist:\n",
    "    print(word, '->', fdist[word], ';', end=' ')\n",
    "\n",
    "for word in fdist:\n",
    "    print('{}->{};'.format(word, fdist[word]), end=' ')\n",
    "\n",
    "print('%s->%d;' % ('cat', 3))\n",
    "# print('%s->%d;' % 'cat') # error\n",
    "print('%s->' % 'cat')\n",
    "print('%d' % 3)\n",
    "print(\"I want a %s right now\" % \"coffee\")\n",
    "print(\"%s wants a %s %s\" % (\"Lee\", \"sandwich\", \"for lunch\"))\n",
    "\n",
    "template = 'Lee wants a %s right now'\n",
    "menu = ['sandwich', 'spam fritter', 'pancake']\n",
    "for snack in menu:\n",
    "    print(template % snack)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    41'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:6}'.format(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bob   '"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:6}'.format(\"Bob\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We can use `:<` to right-justify numbers, and `:>` to left-justify strings:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'41    '"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:<6}'.format(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   Bob'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:>6}'.format(\"Bob\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We can use these methods to format a table of Conditional Frequency Distributions:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate(cfdist, words, categories):\n",
    "    print('{:16}'.format('Category'), end = ' ')\n",
    "    for word in words:\n",
    "        print('{:>6}'.format(word), end = ' ')\n",
    "    print()\n",
    "    for category in categories:\n",
    "        print('{:16}'.format(category), end = ' ')\n",
    "        for word in words:\n",
    "            print('{:6}'.format(cfdist[category][word]), end = ' ')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category            can  could    may  might   must   will \n",
      "news                 93     86     66     38     50    389 \n",
      "religion             82     59     78     12     54     71 \n",
      "hobbies             268     58    131     22     83    264 \n",
      "science_fiction      16     49      4     12      8     16 \n",
      "romance              74    193     11     51     45     43 \n",
      "humor                16     30      8      8      9     13 \n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "         (genre, word)\n",
    "         for genre in brown.categories()\n",
    "         for word in brown.words(categories = genre))\n",
    "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
    "modals = ['can', 'could', 'may', 'might', 'must', 'will']\n",
    "tabulate(cfd, modals, genres)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*However, this function was crafted to work specifically with the words in `modals`.  If we use a new set of terms, the output isn't so nice:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category         Sunday Monday Tuesday Wednesday Thursday Friday Saturday \n",
      "news                 51     54     43     22     20     41     33 \n",
      "religion              8      0      0      0      0      2      0 \n",
      "hobbies               2      1      0      0      1      3      0 \n",
      "science_fiction       1      0      0      0      0      0      0 \n",
      "romance               5      2      3      3      1      3      4 \n",
      "humor                 0      1      0      0      0      0      3 \n"
     ]
    }
   ],
   "source": [
    "days = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "tabulate(cfd, days, genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for 9375 words: 34.1867%\n"
     ]
    }
   ],
   "source": [
    "count, total = 3205, 9375\n",
    "print(\"accuracy for %d words: %2.4f%%\" % (total, 100 * count / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   Monty Python'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'%*s' % (15, \"Monty Python\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The function below makes allowances for the size of the words and the categories by using the width of the longest word in each.  Notice how we have to use a second set of `{}` when we wish to use a variable inside the `format` method.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabulate(cfdist, words, categories):\n",
    "    c_length = max([len(c) for c in categories]) + 2\n",
    "    print('{:{}}'.format('Category', c_length), end = ' ')\n",
    "    w_length = max([len(w) for w in words]) + 1\n",
    "    for word in words:\n",
    "        print('{:>{}}'.format(word, w_length), end = ' ')\n",
    "    print()\n",
    "    for category in categories:\n",
    "        print('{:{}}'.format(category, c_length), end = ' ')\n",
    "        for word in words:\n",
    "            print('{:{}}'.format(cfdist[category][word], w_length), end = ' ')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category              Sunday     Monday    Tuesday  Wednesday   Thursday     Friday   Saturday \n",
      "news                      51         54         43         22         20         41         33 \n",
      "religion                   8          0          0          0          0          2          0 \n",
      "hobbies                    2          1          0          0          1          3          0 \n",
      "science_fiction            1          0          0          0          0          0          0 \n",
      "romance                    5          2          3          3          1          3          4 \n",
      "humor                      0          1          0          0          0          0          3 \n"
     ]
    }
   ],
   "source": [
    "days = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "tabulate(cfd, days, genres)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Writing Results to a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modals = ['can', 'could', 'may', 'might', 'must', 'will', 'ggggggggggg']\n",
    "max([len(w) for w in modals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2789\n",
      "2789\n"
     ]
    }
   ],
   "source": [
    "output_file = open('output/output.txt', 'w')\n",
    "words = set(nltk.corpus.genesis.words('english-kjv.txt'))\n",
    "for word in sorted(words):\n",
    "    print(word, file = output_file)\n",
    "    \n",
    "print(\"\\n\" + str(len(words)) + \" words total\", file = output_file)\n",
    "\n",
    "# Can't use the file until we close it.  This step was omitted in the book.\n",
    "\n",
    "print(len(words))\n",
    "print(str(len(words)))\n",
    "output_file.write(str(len(words)) + \"\\n\")\n",
    "output_file.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Text Wrapping\n",
    "\n",
    "*Could not produce the same output as the book:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After (5), all (3), is (2), said (4), and (3), done (4), , (1), more (4), is (2), said (4), than (4), done (4), . (1), "
     ]
    }
   ],
   "source": [
    "saying = ['After', 'all', 'is', 'said', 'and', 'done', ',',\n",
    "           'more', 'is', 'said', 'than', 'done', '.']\n",
    "\n",
    "for word in saying:\n",
    "    print(word, '(' + str(len(word)) + '),', end = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 5 all 3 is 2 said 4 and 3 done 4 , 1 more 4 is 2 said 4 than 4\n",
      "done 4 . 1\n",
      "2789\n",
      "2789\n"
     ]
    }
   ],
   "source": [
    "from textwrap import fill\n",
    "pieces = [\"{} {}\".format(word, len(word)) for word in saying]\n",
    "output = ' '.join(pieces)\n",
    "wrapped = fill(output)\n",
    "print(wrapped)\n",
    "\n",
    "print(len(words))\n",
    "print(str(len(words)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10 Summary \n",
    "\n",
    "*__No notes.__*\n",
    "\n",
    "### 3.11 Further Reading\n",
    "\n",
    "*__No notes.__*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
