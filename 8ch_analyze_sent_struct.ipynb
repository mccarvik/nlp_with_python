{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Chapter 8\n",
    "\n",
    "## Analyzing Sentence Structure\n",
    "\n",
    "*The html version of this chapter in the book is available [here](https://www.nltk.org/book/ch08.html \"ch08\").*\n",
    "\n",
    "### 1   Some Grammatical Dilemmas\n",
    "\n",
    "#### 1.1   Linguistic Data and Unlimited Possibilities\n",
    "\n",
    "*__No notes.__*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Ubiquitous Ambiguity\n",
    "\n",
    "A well-known ambiguous sentence from Groucho Marx:\n",
    "\n",
    "\"While hunting in Africa, I shot an elephant in my pajamas. How he got into my pajamas, I don't know.\"\n",
    "\n",
    "*Defining a simple grammar for this sentence:*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "groucho_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "PP -> P NP\n",
    "NP -> Det N | Det N PP | 'I'\n",
    "VP -> V NP | VP PP\n",
    "Det -> 'an' | 'my'\n",
    "N -> 'elephant' | 'pajamas'\n",
    "V -> 'shot'\n",
    "P -> 'in'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grammar allows us to analyze the sentences in two ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V shot) (NP (Det an) (N elephant)))\n",
      "    (PP (P in) (NP (Det my) (N pajamas)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V shot)\n",
      "    (NP (Det an) (N elephant) (PP (P in) (NP (Det my) (N pajamas))))))\n"
     ]
    }
   ],
   "source": [
    "sent = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
    "parser = nltk.ChartParser(groucho_grammar)\n",
    "for tree in parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The trees for these parses:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "# display(Image(filename = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\ch08-tree-1.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Image(filename = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\ch08-tree-2.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your Turn:__ Consider the following sentences and see if you can think of two quite different interpretations: *Fighting animals could be dangerous. Visiting relatives can be tiresome.* Is ambiguity of the individual words to blame? If not, what is the cause of the ambiguity?\n",
    "\n",
    "The two different interpretations for the first sentence are:\n",
    "\n",
    "* 1. Animals that fight might be vicious.\n",
    "\n",
    "* 2. It might be risky to fight animals.\n",
    "\n",
    "The interpretations for the second sentence are similar:\n",
    "\n",
    "* 1. Relatives that visit may be annoying.\n",
    "\n",
    "* 2. It may be annoying to vist relatives.\n",
    "\n",
    "It's not the ambiguity of the words; rather, the ambiguity of the structure.  Verbs ending in *-ing* could be (among other things) present participle adjectives or gerunds, which would act as nouns.\n",
    "\n",
    "### 2 What's the Use of Syntax?\n",
    "\n",
    "#### 2.1   Beyond n-grams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Image(filename = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\ic_diagram.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Figure 2.1:__ Substitution of Word Sequences: working from the top row, we can replace particular sequences of words (e.g. the brook) with individual words (e.g. it); repeating this process we arrive at a grammatical two-word sentence.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Image(filename = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\ic_diagram_labeled.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Figure 2.2:__ Substitution of Word Sequences Plus Grammatical Categories: This diagram reproduces 2.1 along with grammatical categories corresponding to noun phrases (NP), verb phrases (VP), prepositional phrases (PP), and nominals (Nom).*\n",
    "\n",
    "If we now strip out the words apart from the topmost row, add an S node, and flip the figure over, we end up with a standard phrase structure tree, shown below. Each node in this tree (including the words) is called a __constituent__. The __immediate constituents__ of `S` are `NP` and `VP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Image(filename = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\ch08-tree-3.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Context Free Grammar\n",
    "\n",
    "#### 3.1   A Simple Grammar\n",
    "\n",
    "The left-hand side of the first production is the __start-symbol__ of the grammar, and all well-formed trees must have this symbol as their root label.\n",
    "\n",
    "*Here's a simple Context-Free Grammar:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar1 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "VP -> V NP | V NP PP\n",
    "PP -> P NP\n",
    "V -> \"saw\" | \"ate\" | \"walked\"\n",
    "NP -> \"John\" | \"Mary\" | \"Bob\" | Det N | Det N PP\n",
    "Det -> \"a\" | \"an\" | \"the\" | \"my\"\n",
    "N -> \"man\" | \"dog\" | \"cat\" | \"telescope\" | \"park\"\n",
    "P -> \"in\" | \"on\" | \"by\" | \"with\"\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP Bob)))\n"
     ]
    }
   ],
   "source": [
    "sent = \"Mary saw Bob\".split()\n",
    "rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| __Symbol__ | __Meaning__              | __Example__          |\n",
    "|--------|----------------------|------------------|\n",
    "| S      | sentence             | *the man walked*   |\n",
    "| NP     | noun phrase          | *a dog*  |\n",
    "| VP     | verb phrase          | *saw a park* |\n",
    "| PP     | prepositional phrase | *with a telescope*|\n",
    "| Det    | determiner           | *the* |\n",
    "| N      | noun                 | *dog* |\n",
    "| V      | verb                 | *walked* |\n",
    "| P      | preposition          | *in* |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your Turn:__ Try developing a simple grammar of your own, using the recursive descent parser application, `nltk.app.rdparser()`. It comes already loaded with a sample grammar, but you can edit this as you please (using the `Edit` menu). Change the grammar, and the sentence to be parsed, and run the parser using the autostep button.\n",
    "\n",
    "*The application opens in a new window, so I won't be calling it from inside a notebook window.  Just FYI, the parser goes through all possible parses, and takes a while to run before it finds the correct one.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "nltk.app.rdparser()\n",
    "\n",
    "[('under',)]\n",
    "[('with',)]\n",
    "[('in',)]\n",
    "[('under',), ('with',)]\n",
    "[('ate',)]\n",
    "[('saw',)]\n",
    "[('dog',)]\n",
    "[('telescope',)]\n",
    "[('park',)]\n",
    "[('dog',), ('telescope',)]\n",
    "[('man',)]\n",
    "[('park',), ('dog',), ('telescope',)]\n",
    "[('the',)]\n",
    "[('a',)]\n",
    "[(V, NP)]\n",
    "[(V,)]\n",
    "[(V, NP, PP)]\n",
    "[(V, NP), (V,)]\n",
    "[(Det, N, PP)]\n",
    "[(Det, N)]\n",
    "S [(NP, VP)]\n",
    "NP [(Det, N, PP), (Det, N)]\n",
    "VP [(V, NP, PP), (V, NP), (V,)]\n",
    "PP [(P, NP)]\n",
    "NP [('I',)]\n",
    "Det [('the',), ('a',)]\n",
    "N [('man',), ('park',), ('dog',), ('telescope',)]\n",
    "V [('ate',), ('saw',)]\n",
    "P [('in',), ('under',), ('with',)]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2   Writing Your Own Grammars\n",
    "\n",
    "You can write and edit grammars in a text file. The file needs the suffix `.cfg`. The file can be loaded into NLTK as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# path = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\"\n",
    "\n",
    "# os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grammar1 = nltk.data.load('file:mygrammar.cfg')\n",
    "# sent = \"Mary saw Bob\".split()\n",
    "# rd_parser = nltk.RecursiveDescentParser(grammar1)\n",
    "# for tree in rd_parser.parse(sent):\n",
    "#     print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `print(tree)` produces no output, it's probably because `sent` is not admitted by the grammar.  You can call the parser with tracing set to be with `rd_parser = nltk.RecursiveDescentParser(grammar1, trace = 2)`.\n",
    "\n",
    "#### 3.3 Recursion in Syntactic Structure\n",
    "\n",
    "Grammars are __recursive__ if a category on the left hand side of production also appears on the right (e.g., `Nom -> Adj Nom | N`).  Indirect recursion is a combination of two productiosn (e.g. `S -> NP VP` and `VP -> V S`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar2 = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> Det Nom | PropN\n",
    "Nom -> Adj Nom | N\n",
    "VP -> V Adj | V NP | V S | V NP PP\n",
    "PP -> P NP\n",
    "PropN -> 'Buster' | 'Chatterer' | 'Joe'\n",
    "Det -> 'the' | 'a'\n",
    "N -> 'bear' | 'squirrel' | 'tree' | 'fish' | 'log'\n",
    "Adj -> 'angry' | 'frightened' | 'little' | 'tall'\n",
    "V -> 'chased'| 'saw' | 'said' | 'thought' | 'was' | 'put'\n",
    "P -> 'on'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Image(filename = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\ch08-tree-6.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Image(filename = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\ch08-tree-7.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4   Parsing With Context Free Grammar\n",
    "\n",
    "#### 4.1   Recursive Descent Parsing\n",
    "\n",
    "The parser will replace goals with subgoals, which will in turn be replaced by sub- sub-goals, and so on until a parse is found or all possibilities are exhausted.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Image(filename = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\rdparser1-6.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Figure 4.1__: Six Stages of a Recursive Descent Parser: the parser begins with a tree consisting of the node S; at each stage it consults the grammar to find a production that can be used to enlarge the tree; when a lexical production is encountered, its word is compared against the input; after a complete parse has been found, the parser backtracks to look for more parses.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP (Det the) (N dog))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N man) (PP (P in) (NP (Det the) (N park))))))\n",
      "(S\n",
      "  (NP (Det the) (N dog))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N man))\n",
      "    (PP (P in) (NP (Det the) (N park)))))\n"
     ]
    }
   ],
   "source": [
    "sent = \"the dog saw a man in the park\".split()\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Adding the parameter `trace` to `RecursiveDescentParser()` will make the parser report the steps that it takes as it parses a text.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 'the dog saw a man in the park'\n",
      "Found a parse:\n",
      "(S\n",
      "  (NP (Det the) (N dog))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N man) (PP (P in) (NP (Det the) (N park))))))\n",
      "(S\n",
      "  (NP (Det the) (N dog))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N man) (PP (P in) (NP (Det the) (N park))))))\n",
      "Found a parse:\n",
      "(S\n",
      "  (NP (Det the) (N dog))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N man))\n",
      "    (PP (P in) (NP (Det the) (N park)))))\n",
      "(S\n",
      "  (NP (Det the) (N dog))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N man))\n",
      "    (PP (P in) (NP (Det the) (N park)))))\n"
     ]
    }
   ],
   "source": [
    "rd_parser = nltk.RecursiveDescentParser(grammar1, trace = 1)\n",
    "sent = \"the dog saw a man in the park\".split()\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 'the dog saw a man in the park'\n",
      "    [ * S ]\n",
      "  E [ * NP VP ]\n",
      "  E [ * 'John' VP ]\n",
      "  E [ * 'Mary' VP ]\n",
      "  E [ * 'Bob' VP ]\n",
      "  E [ * Det N VP ]\n",
      "  E [ * 'a' N VP ]\n",
      "  E [ * 'an' N VP ]\n",
      "  E [ * 'the' N VP ]\n",
      "  M [ 'the' * N VP ]\n",
      "  E [ 'the' * 'man' VP ]\n",
      "  E [ 'the' * 'dog' VP ]\n",
      "  M [ 'the' 'dog' * VP ]\n",
      "  E [ 'the' 'dog' * V NP ]\n",
      "  E [ 'the' 'dog' * 'saw' NP ]\n",
      "  M [ 'the' 'dog' 'saw' * NP ]\n",
      "  E [ 'the' 'dog' 'saw' * 'John' ]\n",
      "  E [ 'the' 'dog' 'saw' * 'Mary' ]\n",
      "  E [ 'the' 'dog' 'saw' * 'Bob' ]\n",
      "  E [ 'the' 'dog' 'saw' * Det N ]\n",
      "  E [ 'the' 'dog' 'saw' * 'a' N ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' * N ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' * 'man' ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' 'man' ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' * 'dog' ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' * 'cat' ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' * 'telescope' ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' * 'park' ]\n",
      "  E [ 'the' 'dog' 'saw' * 'an' N ]\n",
      "  E [ 'the' 'dog' 'saw' * 'the' N ]\n",
      "  E [ 'the' 'dog' 'saw' * 'my' N ]\n",
      "  E [ 'the' 'dog' 'saw' * Det N PP ]\n",
      "  E [ 'the' 'dog' 'saw' * 'a' N PP ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' * N PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' * 'man' PP ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' 'man' * PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' * P NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' * 'in' NP ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' 'man' 'in' * NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'John' ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'Mary' ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'Bob' ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * Det N ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'a' N ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'an' N ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'the' N ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * N ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'man' ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'dog' ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'cat' ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'telescope' ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'park' ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' ]\n",
      "  + [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' ]\n",
      "(S\n",
      "  (NP (Det the) (N dog))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N man) (PP (P in) (NP (Det the) (N park))))))\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'my' N ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * Det N PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'a' N PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'an' N PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'the' N PP ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * N PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'man' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'dog' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'cat' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'telescope' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'park' PP ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * P NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'in' NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'on' NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'by' NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'with' NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'my' N PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' * 'on' NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' * 'by' NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' * 'with' NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' * 'dog' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' * 'cat' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' * 'telescope' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' * 'park' PP ]\n",
      "  E [ 'the' 'dog' 'saw' * 'an' N PP ]\n",
      "  E [ 'the' 'dog' 'saw' * 'the' N PP ]\n",
      "  E [ 'the' 'dog' 'saw' * 'my' N PP ]\n",
      "  E [ 'the' 'dog' * 'ate' NP ]\n",
      "  E [ 'the' 'dog' * 'walked' NP ]\n",
      "  E [ 'the' 'dog' * V NP PP ]\n",
      "  E [ 'the' 'dog' * 'saw' NP PP ]\n",
      "  M [ 'the' 'dog' 'saw' * NP PP ]\n",
      "  E [ 'the' 'dog' 'saw' * 'John' PP ]\n",
      "  E [ 'the' 'dog' 'saw' * 'Mary' PP ]\n",
      "  E [ 'the' 'dog' 'saw' * 'Bob' PP ]\n",
      "  E [ 'the' 'dog' 'saw' * Det N PP ]\n",
      "  E [ 'the' 'dog' 'saw' * 'a' N PP ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' * N PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' * 'man' PP ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' 'man' * PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' * P NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' * 'in' NP ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' 'man' 'in' * NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'John' ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'Mary' ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'Bob' ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * Det N ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'a' N ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'an' N ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'the' N ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * N ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'man' ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'dog' ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'cat' ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'telescope' ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'park' ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' ]\n",
      "  + [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' ]\n",
      "(S\n",
      "  (NP (Det the) (N dog))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N man))\n",
      "    (PP (P in) (NP (Det the) (N park)))))\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'my' N ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * Det N PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'a' N PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'an' N PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'the' N PP ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * N PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'man' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'dog' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'cat' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'telescope' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'park' PP ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * P NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'in' NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'on' NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'by' NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'with' NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'my' N PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' * 'on' NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' * 'by' NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' * 'with' NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' * 'dog' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' * 'cat' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' * 'telescope' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' * 'park' PP ]\n",
      "  E [ 'the' 'dog' 'saw' * 'an' N PP ]\n",
      "  E [ 'the' 'dog' 'saw' * 'the' N PP ]\n",
      "  E [ 'the' 'dog' 'saw' * 'my' N PP ]\n",
      "  E [ 'the' 'dog' 'saw' * Det N PP PP ]\n",
      "  E [ 'the' 'dog' 'saw' * 'a' N PP PP ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' * N PP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' * 'man' PP PP ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' 'man' * PP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' * P NP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' * 'in' NP PP ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' 'man' 'in' * NP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'John' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'Mary' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'Bob' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * Det N PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'a' N PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'an' N PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'the' N PP ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * N PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'man' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'dog' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'cat' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'telescope' PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'park' PP ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * P NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'in' NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'on' NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'by' NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'with' NP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'my' N PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * Det N PP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'a' N PP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'an' N PP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'the' N PP PP ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * N PP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'man' PP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'dog' PP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'cat' PP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'telescope' PP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'park' PP PP ]\n",
      "  M [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * PP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * P NP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'in' NP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'on' NP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'by' NP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'with' NP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'my' N PP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' * 'on' NP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' * 'by' NP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' 'man' * 'with' NP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' * 'dog' PP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' * 'cat' PP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' * 'telescope' PP PP ]\n",
      "  E [ 'the' 'dog' 'saw' 'a' * 'park' PP PP ]\n",
      "  E [ 'the' 'dog' 'saw' * 'an' N PP PP ]\n",
      "  E [ 'the' 'dog' 'saw' * 'the' N PP PP ]\n",
      "  E [ 'the' 'dog' 'saw' * 'my' N PP PP ]\n",
      "  E [ 'the' 'dog' * 'ate' NP PP ]\n",
      "  E [ 'the' 'dog' * 'walked' NP PP ]\n",
      "  E [ 'the' * 'cat' VP ]\n",
      "  E [ 'the' * 'telescope' VP ]\n",
      "  E [ 'the' * 'park' VP ]\n",
      "  E [ * 'my' N VP ]\n",
      "  E [ * Det N PP VP ]\n",
      "  E [ * 'a' N PP VP ]\n",
      "  E [ * 'an' N PP VP ]\n",
      "  E [ * 'the' N PP VP ]\n",
      "  M [ 'the' * N PP VP ]\n",
      "  E [ 'the' * 'man' PP VP ]\n",
      "  E [ 'the' * 'dog' PP VP ]\n",
      "  M [ 'the' 'dog' * PP VP ]\n",
      "  E [ 'the' 'dog' * P NP VP ]\n",
      "  E [ 'the' 'dog' * 'in' NP VP ]\n",
      "  E [ 'the' 'dog' * 'on' NP VP ]\n",
      "  E [ 'the' 'dog' * 'by' NP VP ]\n",
      "  E [ 'the' 'dog' * 'with' NP VP ]\n",
      "  E [ 'the' * 'cat' PP VP ]\n",
      "  E [ 'the' * 'telescope' PP VP ]\n",
      "  E [ 'the' * 'park' PP VP ]\n",
      "  E [ * 'my' N PP VP ]\n"
     ]
    }
   ],
   "source": [
    "rd_parser = nltk.RecursiveDescentParser(grammar1, trace = 2)\n",
    "sent = \"the dog saw a man in the park\".split()\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 'the dog saw a man in the park'\n",
      "Start:\n",
      "    [ * S ]\n",
      "Expand: S -> NP VP\n",
      "    [ * NP VP ]\n",
      "Expand: NP -> 'John'\n",
      "    [ * 'John' VP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: NP -> 'Mary'\n",
      "    [ * 'Mary' VP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: NP -> 'Bob'\n",
      "    [ * 'Bob' VP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: NP -> Det N\n",
      "    [ * Det N VP ]\n",
      "Expand: Det -> 'a'\n",
      "    [ * 'a' N VP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: Det -> 'an'\n",
      "    [ * 'an' N VP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: Det -> 'the'\n",
      "    [ * 'the' N VP ]\n",
      "Match: 'the'\n",
      "    [ 'the' * N VP ]\n",
      "Expand: N -> 'man'\n",
      "    [ 'the' * 'man' VP ]\n",
      "Backtrack: 'dog' match failed\n",
      "Expand: N -> 'dog'\n",
      "    [ 'the' * 'dog' VP ]\n",
      "Match: 'dog'\n",
      "    [ 'the' 'dog' * VP ]\n",
      "Expand: VP -> V NP\n",
      "    [ 'the' 'dog' * V NP ]\n",
      "Expand: V -> 'saw'\n",
      "    [ 'the' 'dog' * 'saw' NP ]\n",
      "Match: 'saw'\n",
      "    [ 'the' 'dog' 'saw' * NP ]\n",
      "Expand: NP -> 'John'\n",
      "    [ 'the' 'dog' 'saw' * 'John' ]\n",
      "Backtrack: 'a' match failed\n",
      "Expand: NP -> 'Mary'\n",
      "    [ 'the' 'dog' 'saw' * 'Mary' ]\n",
      "Backtrack: 'a' match failed\n",
      "Expand: NP -> 'Bob'\n",
      "    [ 'the' 'dog' 'saw' * 'Bob' ]\n",
      "Backtrack: 'a' match failed\n",
      "Expand: NP -> Det N\n",
      "    [ 'the' 'dog' 'saw' * Det N ]\n",
      "Expand: Det -> 'a'\n",
      "    [ 'the' 'dog' 'saw' * 'a' N ]\n",
      "Match: 'a'\n",
      "    [ 'the' 'dog' 'saw' 'a' * N ]\n",
      "Expand: N -> 'man'\n",
      "    [ 'the' 'dog' 'saw' 'a' * 'man' ]\n",
      "Match: 'man'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' ]\n",
      "Backtrack\n",
      "Expand: N -> 'dog'\n",
      "    [ 'the' 'dog' 'saw' 'a' * 'dog' ]\n",
      "Backtrack: 'man' match failed\n",
      "Expand: N -> 'cat'\n",
      "    [ 'the' 'dog' 'saw' 'a' * 'cat' ]\n",
      "Backtrack: 'man' match failed\n",
      "Expand: N -> 'telescope'\n",
      "    [ 'the' 'dog' 'saw' 'a' * 'telescope' ]\n",
      "Backtrack: 'man' match failed\n",
      "Expand: N -> 'park'\n",
      "    [ 'the' 'dog' 'saw' 'a' * 'park' ]\n",
      "Backtrack: 'man' match failed\n",
      "Expand: Det -> 'an'\n",
      "    [ 'the' 'dog' 'saw' * 'an' N ]\n",
      "Backtrack: 'a' match failed\n",
      "Expand: Det -> 'the'\n",
      "    [ 'the' 'dog' 'saw' * 'the' N ]\n",
      "Backtrack: 'a' match failed\n",
      "Expand: Det -> 'my'\n",
      "    [ 'the' 'dog' 'saw' * 'my' N ]\n",
      "Backtrack: 'a' match failed\n",
      "Expand: NP -> Det N PP\n",
      "    [ 'the' 'dog' 'saw' * Det N PP ]\n",
      "Expand: Det -> 'a'\n",
      "    [ 'the' 'dog' 'saw' * 'a' N PP ]\n",
      "Match: 'a'\n",
      "    [ 'the' 'dog' 'saw' 'a' * N PP ]\n",
      "Expand: N -> 'man'\n",
      "    [ 'the' 'dog' 'saw' 'a' * 'man' PP ]\n",
      "Match: 'man'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' * PP ]\n",
      "Expand: PP -> P NP\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' * P NP ]\n",
      "Expand: P -> 'in'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' * 'in' NP ]\n",
      "Match: 'in'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * NP ]\n",
      "Expand: NP -> 'John'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'John' ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: NP -> 'Mary'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'Mary' ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: NP -> 'Bob'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'Bob' ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: NP -> Det N\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * Det N ]\n",
      "Expand: Det -> 'a'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'a' N ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: Det -> 'an'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'an' N ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: Det -> 'the'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'the' N ]\n",
      "Match: 'the'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * N ]\n",
      "Expand: N -> 'man'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'man' ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'dog'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'dog' ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'cat'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'cat' ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'telescope'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'telescope' ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'park'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'park' ]\n",
      "Match: 'park'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' ]\n",
      "GOOD PARSE:\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' ]\n",
      "(S\n",
      "  (NP (Det the) (N dog))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N man) (PP (P in) (NP (Det the) (N park))))))\n",
      "Expand: Det -> 'my'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'my' N ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: NP -> Det N PP\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * Det N PP ]\n",
      "Expand: Det -> 'a'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'a' N PP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: Det -> 'an'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'an' N PP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: Det -> 'the'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'the' N PP ]\n",
      "Match: 'the'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * N PP ]\n",
      "Expand: N -> 'man'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'man' PP ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'dog'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'dog' PP ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'cat'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'cat' PP ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'telescope'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'telescope' PP ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'park'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'park' PP ]\n",
      "Match: 'park'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * PP ]\n",
      "Expand: PP -> P NP\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * P NP ]\n",
      "Expand: P -> 'in'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'in' NP ]\n",
      "Backtrack\n",
      "Expand: P -> 'on'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'on' NP ]\n",
      "Backtrack\n",
      "Expand: P -> 'by'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'by' NP ]\n",
      "Backtrack\n",
      "Expand: P -> 'with'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'with' NP ]\n",
      "Backtrack\n",
      "Expand: Det -> 'my'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'my' N PP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: P -> 'on'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' * 'on' NP ]\n",
      "Backtrack: 'in' match failed\n",
      "Expand: P -> 'by'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' * 'by' NP ]\n",
      "Backtrack: 'in' match failed\n",
      "Expand: P -> 'with'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' * 'with' NP ]\n",
      "Backtrack: 'in' match failed\n",
      "Expand: N -> 'dog'\n",
      "    [ 'the' 'dog' 'saw' 'a' * 'dog' PP ]\n",
      "Backtrack: 'man' match failed\n",
      "Expand: N -> 'cat'\n",
      "    [ 'the' 'dog' 'saw' 'a' * 'cat' PP ]\n",
      "Backtrack: 'man' match failed\n",
      "Expand: N -> 'telescope'\n",
      "    [ 'the' 'dog' 'saw' 'a' * 'telescope' PP ]\n",
      "Backtrack: 'man' match failed\n",
      "Expand: N -> 'park'\n",
      "    [ 'the' 'dog' 'saw' 'a' * 'park' PP ]\n",
      "Backtrack: 'man' match failed\n",
      "Expand: Det -> 'an'\n",
      "    [ 'the' 'dog' 'saw' * 'an' N PP ]\n",
      "Backtrack: 'a' match failed\n",
      "Expand: Det -> 'the'\n",
      "    [ 'the' 'dog' 'saw' * 'the' N PP ]\n",
      "Backtrack: 'a' match failed\n",
      "Expand: Det -> 'my'\n",
      "    [ 'the' 'dog' 'saw' * 'my' N PP ]\n",
      "Backtrack: 'a' match failed\n",
      "Expand: V -> 'ate'\n",
      "    [ 'the' 'dog' * 'ate' NP ]\n",
      "Backtrack: 'saw' match failed\n",
      "Expand: V -> 'walked'\n",
      "    [ 'the' 'dog' * 'walked' NP ]\n",
      "Backtrack: 'saw' match failed\n",
      "Expand: VP -> V NP PP\n",
      "    [ 'the' 'dog' * V NP PP ]\n",
      "Expand: V -> 'saw'\n",
      "    [ 'the' 'dog' * 'saw' NP PP ]\n",
      "Match: 'saw'\n",
      "    [ 'the' 'dog' 'saw' * NP PP ]\n",
      "Expand: NP -> 'John'\n",
      "    [ 'the' 'dog' 'saw' * 'John' PP ]\n",
      "Backtrack: 'a' match failed\n",
      "Expand: NP -> 'Mary'\n",
      "    [ 'the' 'dog' 'saw' * 'Mary' PP ]\n",
      "Backtrack: 'a' match failed\n",
      "Expand: NP -> 'Bob'\n",
      "    [ 'the' 'dog' 'saw' * 'Bob' PP ]\n",
      "Backtrack: 'a' match failed\n",
      "Expand: NP -> Det N\n",
      "    [ 'the' 'dog' 'saw' * Det N PP ]\n",
      "Expand: Det -> 'a'\n",
      "    [ 'the' 'dog' 'saw' * 'a' N PP ]\n",
      "Match: 'a'\n",
      "    [ 'the' 'dog' 'saw' 'a' * N PP ]\n",
      "Expand: N -> 'man'\n",
      "    [ 'the' 'dog' 'saw' 'a' * 'man' PP ]\n",
      "Match: 'man'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' * PP ]\n",
      "Expand: PP -> P NP\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' * P NP ]\n",
      "Expand: P -> 'in'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' * 'in' NP ]\n",
      "Match: 'in'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * NP ]\n",
      "Expand: NP -> 'John'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'John' ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: NP -> 'Mary'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'Mary' ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: NP -> 'Bob'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'Bob' ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: NP -> Det N\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * Det N ]\n",
      "Expand: Det -> 'a'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'a' N ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: Det -> 'an'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'an' N ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: Det -> 'the'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'the' N ]\n",
      "Match: 'the'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * N ]\n",
      "Expand: N -> 'man'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'man' ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'dog'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'dog' ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'cat'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'cat' ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'telescope'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'telescope' ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'park'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'park' ]\n",
      "Match: 'park'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' ]\n",
      "GOOD PARSE:\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' ]\n",
      "(S\n",
      "  (NP (Det the) (N dog))\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det a) (N man))\n",
      "    (PP (P in) (NP (Det the) (N park)))))\n",
      "Expand: Det -> 'my'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'my' N ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: NP -> Det N PP\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * Det N PP ]\n",
      "Expand: Det -> 'a'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'a' N PP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: Det -> 'an'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'an' N PP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: Det -> 'the'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'the' N PP ]\n",
      "Match: 'the'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * N PP ]\n",
      "Expand: N -> 'man'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'man' PP ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'dog'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'dog' PP ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'cat'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'cat' PP ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'telescope'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'telescope' PP ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'park'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'park' PP ]\n",
      "Match: 'park'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * PP ]\n",
      "Expand: PP -> P NP\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * P NP ]\n",
      "Expand: P -> 'in'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'in' NP ]\n",
      "Backtrack\n",
      "Expand: P -> 'on'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'on' NP ]\n",
      "Backtrack\n",
      "Expand: P -> 'by'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'by' NP ]\n",
      "Backtrack\n",
      "Expand: P -> 'with'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'with' NP ]\n",
      "Backtrack\n",
      "Expand: Det -> 'my'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'my' N PP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: P -> 'on'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' * 'on' NP ]\n",
      "Backtrack: 'in' match failed\n",
      "Expand: P -> 'by'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' * 'by' NP ]\n",
      "Backtrack: 'in' match failed\n",
      "Expand: P -> 'with'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' * 'with' NP ]\n",
      "Backtrack: 'in' match failed\n",
      "Expand: N -> 'dog'\n",
      "    [ 'the' 'dog' 'saw' 'a' * 'dog' PP ]\n",
      "Backtrack: 'man' match failed\n",
      "Expand: N -> 'cat'\n",
      "    [ 'the' 'dog' 'saw' 'a' * 'cat' PP ]\n",
      "Backtrack: 'man' match failed\n",
      "Expand: N -> 'telescope'\n",
      "    [ 'the' 'dog' 'saw' 'a' * 'telescope' PP ]\n",
      "Backtrack: 'man' match failed\n",
      "Expand: N -> 'park'\n",
      "    [ 'the' 'dog' 'saw' 'a' * 'park' PP ]\n",
      "Backtrack: 'man' match failed\n",
      "Expand: Det -> 'an'\n",
      "    [ 'the' 'dog' 'saw' * 'an' N PP ]\n",
      "Backtrack: 'a' match failed\n",
      "Expand: Det -> 'the'\n",
      "    [ 'the' 'dog' 'saw' * 'the' N PP ]\n",
      "Backtrack: 'a' match failed\n",
      "Expand: Det -> 'my'\n",
      "    [ 'the' 'dog' 'saw' * 'my' N PP ]\n",
      "Backtrack: 'a' match failed\n",
      "Expand: NP -> Det N PP\n",
      "    [ 'the' 'dog' 'saw' * Det N PP PP ]\n",
      "Expand: Det -> 'a'\n",
      "    [ 'the' 'dog' 'saw' * 'a' N PP PP ]\n",
      "Match: 'a'\n",
      "    [ 'the' 'dog' 'saw' 'a' * N PP PP ]\n",
      "Expand: N -> 'man'\n",
      "    [ 'the' 'dog' 'saw' 'a' * 'man' PP PP ]\n",
      "Match: 'man'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' * PP PP ]\n",
      "Expand: PP -> P NP\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' * P NP PP ]\n",
      "Expand: P -> 'in'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' * 'in' NP PP ]\n",
      "Match: 'in'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * NP PP ]\n",
      "Expand: NP -> 'John'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'John' PP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: NP -> 'Mary'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'Mary' PP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: NP -> 'Bob'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'Bob' PP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: NP -> Det N\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * Det N PP ]\n",
      "Expand: Det -> 'a'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'a' N PP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: Det -> 'an'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'an' N PP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: Det -> 'the'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'the' N PP ]\n",
      "Match: 'the'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * N PP ]\n",
      "Expand: N -> 'man'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'man' PP ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'dog'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'dog' PP ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'cat'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'cat' PP ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'telescope'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'telescope' PP ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'park'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'park' PP ]\n",
      "Match: 'park'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * PP ]\n",
      "Expand: PP -> P NP\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * P NP ]\n",
      "Expand: P -> 'in'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'in' NP ]\n",
      "Backtrack\n",
      "Expand: P -> 'on'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'on' NP ]\n",
      "Backtrack\n",
      "Expand: P -> 'by'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'by' NP ]\n",
      "Backtrack\n",
      "Expand: P -> 'with'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'with' NP ]\n",
      "Backtrack\n",
      "Expand: Det -> 'my'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'my' N PP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: NP -> Det N PP\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * Det N PP PP ]\n",
      "Expand: Det -> 'a'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'a' N PP PP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: Det -> 'an'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'an' N PP PP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: Det -> 'the'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'the' N PP PP ]\n",
      "Match: 'the'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * N PP PP ]\n",
      "Expand: N -> 'man'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'man' PP PP ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'dog'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'dog' PP PP ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'cat'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'cat' PP PP ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'telescope'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'telescope' PP PP ]\n",
      "Backtrack: 'park' match failed\n",
      "Expand: N -> 'park'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' * 'park' PP PP ]\n",
      "Match: 'park'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * PP PP ]\n",
      "Expand: PP -> P NP\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * P NP PP ]\n",
      "Expand: P -> 'in'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'in' NP PP ]\n",
      "Backtrack\n",
      "Expand: P -> 'on'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'on' NP PP ]\n",
      "Backtrack\n",
      "Expand: P -> 'by'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'by' NP PP ]\n",
      "Backtrack\n",
      "Expand: P -> 'with'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' 'the' 'park' * 'with' NP PP ]\n",
      "Backtrack\n",
      "Expand: Det -> 'my'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' 'in' * 'my' N PP PP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: P -> 'on'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' * 'on' NP PP ]\n",
      "Backtrack: 'in' match failed\n",
      "Expand: P -> 'by'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' * 'by' NP PP ]\n",
      "Backtrack: 'in' match failed\n",
      "Expand: P -> 'with'\n",
      "    [ 'the' 'dog' 'saw' 'a' 'man' * 'with' NP PP ]\n",
      "Backtrack: 'in' match failed\n",
      "Expand: N -> 'dog'\n",
      "    [ 'the' 'dog' 'saw' 'a' * 'dog' PP PP ]\n",
      "Backtrack: 'man' match failed\n",
      "Expand: N -> 'cat'\n",
      "    [ 'the' 'dog' 'saw' 'a' * 'cat' PP PP ]\n",
      "Backtrack: 'man' match failed\n",
      "Expand: N -> 'telescope'\n",
      "    [ 'the' 'dog' 'saw' 'a' * 'telescope' PP PP ]\n",
      "Backtrack: 'man' match failed\n",
      "Expand: N -> 'park'\n",
      "    [ 'the' 'dog' 'saw' 'a' * 'park' PP PP ]\n",
      "Backtrack: 'man' match failed\n",
      "Expand: Det -> 'an'\n",
      "    [ 'the' 'dog' 'saw' * 'an' N PP PP ]\n",
      "Backtrack: 'a' match failed\n",
      "Expand: Det -> 'the'\n",
      "    [ 'the' 'dog' 'saw' * 'the' N PP PP ]\n",
      "Backtrack: 'a' match failed\n",
      "Expand: Det -> 'my'\n",
      "    [ 'the' 'dog' 'saw' * 'my' N PP PP ]\n",
      "Backtrack: 'a' match failed\n",
      "Expand: V -> 'ate'\n",
      "    [ 'the' 'dog' * 'ate' NP PP ]\n",
      "Backtrack: 'saw' match failed\n",
      "Expand: V -> 'walked'\n",
      "    [ 'the' 'dog' * 'walked' NP PP ]\n",
      "Backtrack: 'saw' match failed\n",
      "Expand: N -> 'cat'\n",
      "    [ 'the' * 'cat' VP ]\n",
      "Backtrack: 'dog' match failed\n",
      "Expand: N -> 'telescope'\n",
      "    [ 'the' * 'telescope' VP ]\n",
      "Backtrack: 'dog' match failed\n",
      "Expand: N -> 'park'\n",
      "    [ 'the' * 'park' VP ]\n",
      "Backtrack: 'dog' match failed\n",
      "Expand: Det -> 'my'\n",
      "    [ * 'my' N VP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: NP -> Det N PP\n",
      "    [ * Det N PP VP ]\n",
      "Expand: Det -> 'a'\n",
      "    [ * 'a' N PP VP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: Det -> 'an'\n",
      "    [ * 'an' N PP VP ]\n",
      "Backtrack: 'the' match failed\n",
      "Expand: Det -> 'the'\n",
      "    [ * 'the' N PP VP ]\n",
      "Match: 'the'\n",
      "    [ 'the' * N PP VP ]\n",
      "Expand: N -> 'man'\n",
      "    [ 'the' * 'man' PP VP ]\n",
      "Backtrack: 'dog' match failed\n",
      "Expand: N -> 'dog'\n",
      "    [ 'the' * 'dog' PP VP ]\n",
      "Match: 'dog'\n",
      "    [ 'the' 'dog' * PP VP ]\n",
      "Expand: PP -> P NP\n",
      "    [ 'the' 'dog' * P NP VP ]\n",
      "Expand: P -> 'in'\n",
      "    [ 'the' 'dog' * 'in' NP VP ]\n",
      "Backtrack: 'saw' match failed\n",
      "Expand: P -> 'on'\n",
      "    [ 'the' 'dog' * 'on' NP VP ]\n",
      "Backtrack: 'saw' match failed\n",
      "Expand: P -> 'by'\n",
      "    [ 'the' 'dog' * 'by' NP VP ]\n",
      "Backtrack: 'saw' match failed\n",
      "Expand: P -> 'with'\n",
      "    [ 'the' 'dog' * 'with' NP VP ]\n",
      "Backtrack: 'saw' match failed\n",
      "Expand: N -> 'cat'\n",
      "    [ 'the' * 'cat' PP VP ]\n",
      "Backtrack: 'dog' match failed\n",
      "Expand: N -> 'telescope'\n",
      "    [ 'the' * 'telescope' PP VP ]\n",
      "Backtrack: 'dog' match failed\n",
      "Expand: N -> 'park'\n",
      "    [ 'the' * 'park' PP VP ]\n",
      "Backtrack: 'dog' match failed\n",
      "Expand: Det -> 'my'\n",
      "    [ * 'my' N PP VP ]\n",
      "Backtrack: 'the' match failed\n"
     ]
    }
   ],
   "source": [
    "rd_parser = nltk.RecursiveDescentParser(grammar1, trace = 3)\n",
    "sent = \"the dog saw a man in the park\".split()\n",
    "for tree in rd_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The example above is a kind of __top-down parsing__, which is very slow: it will spend a lot of time considering words and structures that do not correspond to the input sentence, and it will also discard parsed constituents that will need to be rebuilt again later.  Left-recursive productions (e.g., `NP -> NP PP`) will send the the parser into an infinite loop.*\n",
    "\n",
    "#### 4.2 Shift-Reduce Parsing\n",
    "\n",
    "A __shift-reduce__ parser tries to find sequences of words and phrases that correspond to the *right hand* side of grammar and replace them with the left-hand side until the whole sentence is reduced to an `S`. \n",
    "\n",
    "This parser repeatedly pushes the next input word onto a stack (i.e., the __shift__ operation).  If the top $n$ items on the stack match the $n$ items on the right hand side of some production, they are all popped off the stack, and the item on the left-hand side of the production is pushed on the stack (i.e., the __reduce__ operation).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Image(filename = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\srparser1-6.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Figure 4.2:__ Six Stages of a Shift-Reduce Parser: the parser begins by shifting the first input word onto its stack; once the top items on the stack match the right hand side of a grammar production, they can be replaced with the left hand side of that production; the parser succeeds once all input is consumed and one `S` item remains on the stack.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ShiftReduceParser()` in NLTK does not implement any backtracking, so it is not guaranteed to find a parse for a text, even if one exists.  It will also only find at most one parse.  A `trace` parameter controls how verbosely the parser reports the steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n"
     ]
    }
   ],
   "source": [
    "sr_parser = nltk.ShiftReduceParser(grammar1)\n",
    "sent = 'Mary saw a dog'.split()\n",
    "for tree in sr_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your Turn:__ Run the above parser in tracing mode to see the sequence of shift and reduce operations, using `sr_parse = nltk.ShiftReduceParser(grammar1, trace=2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing 'Mary saw a dog'\n",
      "    [ * Mary saw a dog]\n",
      "  S [ 'Mary' * saw a dog]\n",
      "  R [ NP * saw a dog]\n",
      "  S [ NP 'saw' * a dog]\n",
      "  R [ NP V * a dog]\n",
      "  S [ NP V 'a' * dog]\n",
      "  R [ NP V Det * dog]\n",
      "  S [ NP V Det 'dog' * ]\n",
      "  R [ NP V Det N * ]\n",
      "  R [ NP V NP * ]\n",
      "  R [ NP VP * ]\n",
      "  R [ S * ]\n",
      "(S (NP Mary) (VP (V saw) (NP (Det a) (N dog))))\n"
     ]
    }
   ],
   "source": [
    "sr_parser = nltk.ShiftReduceParser(grammar1, trace = 2)\n",
    "sent = 'Mary saw a dog'.split()\n",
    "for tree in sr_parser.parse(sent):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shift-reduce parsers can reach a dead end and fail to find a parse, even if the input sentence was well-formed according to the grammar.  This is because of earlier choices which cannot be undone. \n",
    "\n",
    "An SR parser can be extended to implement policies to resolve such conflicts.\n",
    "\n",
    "SR parsers have advantages over RD parsers in that they only build structure that corresponds to the words in the input, and they only build each sub-structure once.\n",
    "\n",
    "#### 4.3 The Left-Corner Parser\n",
    "\n",
    "A __left-corner parser__ is a top-down parser with bottom-up filtering which cannot get trapped in left recursive productions.  A left-corner parser preprocesses the CFG to build a table where each row contains two cells: the first holds a non-terminal, and the second a collection of possible left corners of that non-terminal.  \n",
    "\n",
    "Each time a production is considered by the parser, it checks that the next input word is compatible with at least one of the pre-terminal categories in the left-corner table.\n",
    "\n",
    "#### 4.4 Well-Formed Substring Tables\n",
    "\n",
    "__Chart parsing__ uses dynamic programming to implement more efficient parsers.  Phrases are saved as __well-formed substring tables__ (WFST).  In a WFST, the position of words are recorded by filling in cells in a triangular matrix: the vertical axis will denote the start position of a substring, while the horizontal axis will denote the end position.  So, *shot* will appear in the cell with coordinates (1, 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Image(filename = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\chart_positions1.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every word in `text` we can look up in our grammar what category it belongs to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[V -> 'shot']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ['I', 'shot', 'an', 'elephant', 'in', 'my', 'pajamas']\n",
    "groucho_grammar.productions(rhs = text[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create an $(n-1) \\times (n-1)$ matrix for the WFST, and initialize it with the lexical categores of each token in the `init_wfst()` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_wfst(tokens, grammar):\n",
    "    numtokens = len(tokens)\n",
    "    wfst = [[None for i in range(numtokens + 1)] for j in range(numtokens + 1)]\n",
    "    for i in range(numtokens):\n",
    "        productions = grammar.productions(rhs = tokens[i])\n",
    "        wfst[i][i + 1] = productions[0].lhs()\n",
    "    return wfst\n",
    "\n",
    "def complex_wfst(wfst, tokens, grammar, trace = False):\n",
    "    index = dict( (p.rhs(), p.lhs()) for p in grammar.productions())\n",
    "    numtokens = len(tokens)\n",
    "    for span in range(2, numtokens + 1):\n",
    "        for start in range(numtokens + 1 - span):\n",
    "            end = start + span\n",
    "            for mid in range(start + 1, end):\n",
    "                nt1, nt2 = wfst[start][mid], wfst[mid][end]\n",
    "                if nt1 and nt2 and (nt1, nt2) in index:\n",
    "                    wfst[start][end] = index[(nt1, nt2)]\n",
    "                    if trace:\n",
    "                        print(\"[%s] %3s [%s] %3s [%s] ==> [%s] %3s [%s]\" % \\\n",
    "                             (start, nt1, mid, nt2, end, start, index[(nt1, nt2)], end))\n",
    "    return wfst\n",
    "\n",
    "def display(wfst, tokens):\n",
    "    print('\\nWFST' + ' '.join( (\"%-4d\" % i) for i in range(1, len(wfst))))\n",
    "    for i in range(len(wfst) - 1):\n",
    "        print(\"%d   \" % i, end = \" \")\n",
    "        for j in range(1, len(wfst)):\n",
    "            print(\"%-4s\" % (wfst[i][j] or '.'), end = \" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WFST1    2    3    4    5    6    7   \n",
      "0    NP   .    .    .    .    .    .    \n",
      "1    .    V    .    .    .    .    .    \n",
      "2    .    .    Det  .    .    .    .    \n",
      "3    .    .    .    N    .    .    .    \n",
      "4    .    .    .    .    P    .    .    \n",
      "5    .    .    .    .    .    Det  .    \n",
      "6    .    .    .    .    .    .    N    \n"
     ]
    }
   ],
   "source": [
    "tokens = \"I shot an elephant in my pajamas\".split()\n",
    "wfst0 = init_wfst(tokens, groucho_grammar)\n",
    "display(wfst0, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WFST1    2    3    4    5    6    7   \n",
      "0    NP   .    .    S    .    .    S    \n",
      "1    .    V    .    VP   .    .    VP   \n",
      "2    .    .    Det  NP   .    .    .    \n",
      "3    .    .    .    N    .    .    .    \n",
      "4    .    .    .    .    P    .    PP   \n",
      "5    .    .    .    .    .    Det  NP   \n",
      "6    .    .    .    .    .    .    N    \n"
     ]
    }
   ],
   "source": [
    "wfst1 = complex_wfst(wfst0, tokens, groucho_grammar)\n",
    "display(wfst1, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we set `trace` to `True` we can see the WFST being constructed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] Det [3]   N [4] ==> [2]  NP [4]\n",
      "[5] Det [6]   N [7] ==> [5]  NP [7]\n",
      "[1]   V [2]  NP [4] ==> [1]  VP [4]\n",
      "[4]   P [5]  NP [7] ==> [4]  PP [7]\n",
      "[0]  NP [1]  VP [4] ==> [0]   S [4]\n",
      "[1]  VP [4]  PP [7] ==> [1]  VP [7]\n",
      "[0]  NP [1]  VP [7] ==> [0]   S [7]\n"
     ]
    }
   ],
   "source": [
    "wfst1 = complex_wfst(wfst0, tokens, groucho_grammar, trace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image(filename = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\chart_positions2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Figure 4.5:__ The Chart Data Structure: non-terminals are represented as extra edges in the chart.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WFST's require every non-lexical grammar production to be binary.  \n",
    "\n",
    "__Your Turn:__ Try out the interactive chart parser application `nltk.app.chartparser()`.\n",
    "\n",
    "The application opens in a new window, so I won't be running it from this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5   Dependencies and Dependency Grammar\n",
    "\n",
    "__Phrase structure grammar__ concerns how words and sequences combine to form constituents.  __Dependency grammar__ focuses on how words relate to other words.  Dependency is a binary asymmetric relation that holds between a __head__ and its __dependents__.  The head of a sentence is usually the tensed verb, and every other word is either dependent on the sentence head or connects to it through a path of dependencies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image(filename = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\depgraph0.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Figure 5.1__: Dependency Structure: arrows point from heads to their dependents; labels indicate the grammatical function of the dependent as subject, object or modifier. This dependency graph is __projective__.  I.e., when the words are written in linear order, the edges can be drawn above the wrods without crossing.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of encoding a dependency grammar in NLTK.  This captures bare dependency information without specifying the type of dependency:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "groucho_dep_grammar = nltk.DependencyGrammar.fromstring(\"\"\"\n",
    "    'shot' -> 'I' | 'elephant' | 'in'\n",
    "    'elephant' -> 'an' | 'in'\n",
    "    'in' -> 'pajamas'\n",
    "    'pajamas' -> 'my'\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependency grammar with 7 productions\n",
      "  'shot' -> 'I'\n",
      "  'shot' -> 'elephant'\n",
      "  'shot' -> 'in'\n",
      "  'elephant' -> 'an'\n",
      "  'elephant' -> 'in'\n",
      "  'in' -> 'pajamas'\n",
      "  'pajamas' -> 'my'\n"
     ]
    }
   ],
   "source": [
    "print(groucho_dep_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an alternative approach to capturing the attachment ambiguity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(shot I (elephant an (in (pajamas my))))\n",
      "(shot I (elephant an) (in (pajamas my)))\n"
     ]
    }
   ],
   "source": [
    "pdp = nltk.ProjectiveDependencyParser(groucho_dep_grammar)\n",
    "sent = 'I shot an elephant in my pajamas'.split()\n",
    "trees = pdp.parse(sent)\n",
    "for tree in trees:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image(filename = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\ch08-tree-10.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image(filename = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\ch08-tree-11.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1   Valency and the Lexicon\n",
    "\n",
    "Some parts of speech (e.g., verbs) have valenices which restrict which __complements__ they can take.  E.g., transitive verbs need an object, whereas intransitive ones can't take one.  We could further constrain a grammar by specifying the valencies of its parts of speech, e.g.\n",
    "\n",
    "```\n",
    "VP -> TV NP\n",
    "TV -> 'chased' | 'saw'\n",
    "```\n",
    "\n",
    "#### 5.2 Scaling Up\n",
    "\n",
    "It is very difficult to scale up grammars like those considered in this chapter so that they can be applied to whole languages, but some people have tried.\n",
    "\n",
    "### 6 Grammar Development\n",
    "\n",
    "#### 6.1 Treebanks and Grammars\n",
    "\n",
    "`corpus` defines the `treebank` corpus reader, which contains a 10% sample of the Penn Treebank corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP-SBJ\n",
      "    (NP (NNP Pierre) (NNP Vinken))\n",
      "    (, ,)\n",
      "    (ADJP (NP (CD 61) (NNS years)) (JJ old))\n",
      "    (, ,))\n",
      "  (VP\n",
      "    (MD will)\n",
      "    (VP\n",
      "      (VB join)\n",
      "      (NP (DT the) (NN board))\n",
      "      (PP-CLR (IN as) (NP (DT a) (JJ nonexecutive) (NN director)))\n",
      "      (NP-TMP (NNP Nov.) (CD 29))))\n",
      "  (. .))\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "t = treebank.parsed_sents('wsj_0001.mrg')[0]\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use corpora to help develop grammars.  The function below uses a filter to find verbs that take sentential complements (i.e., an entire sentence could appear after the verb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(tree):\n",
    "    child_nodes = [child.label() for child in tree\n",
    "                   if isinstance(child, nltk.Tree)]\n",
    "    return (tree.label() == 'VP') and ('S' in child_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree('VP', [Tree('VBN', ['named']), Tree('S', [Tree('NP-SBJ', [Tree('-NONE-', ['*-1'])]), Tree('NP-PRD', [Tree('NP', [Tree('DT', ['a']), Tree('JJ', ['nonexecutive']), Tree('NN', ['director'])]), Tree('PP', [Tree('IN', ['of']), Tree('NP', [Tree('DT', ['this']), Tree('JJ', ['British']), Tree('JJ', ['industrial']), Tree('NN', ['conglomerate'])])])])])]),\n",
       " Tree('VP', [Tree('VBD', ['said']), Tree(',', [',']), Tree('``', ['``']), Tree('S', [Tree('NP-SBJ', [Tree('DT', ['This'])]), Tree('VP', [Tree('VBZ', ['is']), Tree('NP-PRD', [Tree('DT', ['an']), Tree('JJ', ['old']), Tree('NN', ['story'])])])])]),\n",
       " Tree('VP', [Tree('VBD', ['said']), Tree('S', [Tree('-NONE-', ['*T*-1'])])]),\n",
       " Tree('VP', [Tree('VBN', ['expected']), Tree('S', [Tree('-NONE-', ['*?*'])])]),\n",
       " Tree('VP', [Tree('VBD', ['said']), Tree('S', [Tree('-NONE-', ['*T*-1'])])])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "[subtree for tree in treebank.parsed_sents()\n",
    "         for subtree in tree.subtrees(filter)][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example from the Prepositional Phrase Attachment Corpus that finds pairs of prepositional phrases where the preposition and noun are fixed, but the choice of verb determines whether the prepositional phrase is attached to the `VP` or `NP`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%-below-level N: ['left'] V: ['be']\n",
      "%-from-year N: ['was'] V: ['declined', 'dropped', 'fell', 'grew', 'increased', 'plunged', 'rose', 'was']\n",
      "%-in-August N: ['was'] V: ['climbed', 'fell', 'leaping', 'rising', 'rose']\n",
      "%-in-September N: ['increased'] V: ['climbed', 'declined', 'dropped', 'edged', 'fell', 'grew', 'plunged', 'rose', 'slipped']\n",
      "%-in-week N: ['declined'] V: ['was']\n",
      "%-to-% N: ['add', 'added', 'backed', 'be', 'cut', 'go', 'grow', 'increased', 'increasing', 'is', 'offer', 'plummet', 'reduce', 'rejected', 'rise', 'risen', 'shaved', 'wants', 'yield', 'zapping'] V: ['fell', 'rise', 'slipped']\n",
      "%-to-million N: ['declining'] V: ['advanced', 'climbed', 'cutting', 'declined', 'declining', 'dived', 'dropped', 'edged', 'fell', 'gained', 'grew', 'increased', 'jump', 'jumped', 'plunged', 'rising', 'rose', 'slid', 'slipped', 'soared', 'tumbled']\n",
      "1-to-21 N: ['dropped'] V: ['dropped']\n",
      "1-to-33 N: ['gained'] V: ['dropped', 'fell', 'jumped']\n",
      "1-to-4 N: ['added'] V: ['gained']\n",
      "1-to-47 N: ['jumped'] V: ['added', 'rose']\n",
      "1-to-point N: ['ended'] V: ['fell', 'rose']\n",
      "3-to-17 N: ['lost'] V: ['lost']\n",
      "500,000-in-fines N: ['paid'] V: ['paid']\n",
      "6.9-on-scale N: ['registered'] V: ['registered']\n",
      "access-to-AZT N: ['had'] V: ['had']\n",
      "access-to-arena N: ['permits'] V: ['lack']\n",
      "activity-in-part N: ['showed'] V: ['attributed']\n",
      "agreement-in-principle N: ['reached'] V: ['reached']\n",
      "agreement-with-Inc. N: ['announced', 'signed'] V: ['signed']\n",
      "agreement-with-creditors N: ['reached'] V: ['nearing']\n",
      "agreement-with-regulators N: ['presages', 'reach'] V: ['reach']\n",
      "aid-to-Contras N: ['renewing'] V: ['renewing']\n",
      "alliance-with-GM N: ['discussing', 'wrapping'] V: ['forge', 'have', 'negotiating']\n",
      "approval-for-drug N: ['granted'] V: ['obtain']\n",
      "attention-to-comments N: ['paid'] V: ['paid']\n",
      "attention-to-concerns N: ['pay'] V: ['show']\n",
      "attention-to-reports N: ['paid'] V: ['pay']\n",
      "bid-for-company N: ['fend', 'launch'] V: ['made', 'make']\n",
      "bid-for-million N: ['finance'] V: ['had']\n",
      "bids-for-company N: ['submitted'] V: ['solicit']\n",
      "billion-in-cash N: ['pay', 'raise'] V: ['raise']\n",
      "billion-of-bills N: ['sell', 'sold'] V: ['sold']\n",
      "billion-over-years N: ['total'] V: ['spent']\n",
      "billion-to-billion N: ['cause', 'place'] V: ['increased', 'rose']\n",
      "business-to-firms N: ['cutting'] V: ['give', 'transfer']\n",
      "business-with-them N: ['cease'] V: ['do']\n",
      "cap-on-amount N: ['eliminate'] V: ['places']\n",
      "cents-to-cents N: ['be', 'recovering'] V: ['fell', 'rose']\n",
      "change-in-earnings N: ['had'] V: ['had']\n",
      "changes-for-% N: ['measures'] V: ['measures', 'monitors']\n",
      "charge-in-quarter N: ['took'] V: ['had', 'included', 'incur', 'take', 'took']\n",
      "collar-on-trading N: ['re-establishing'] V: ['reinstating']\n",
      "commitments-from-banks N: ['secured', 'won'] V: ['obtained']\n",
      "competition-from-competitors N: ['faced'] V: ['fend']\n",
      "competition-in-production N: ['reduce'] V: ['reduce']\n",
      "contract-for-parts N: ['awarded', 'given', 'won'] V: ['received']\n",
      "contract-for-support N: ['awarded', 'issued'] V: ['received']\n",
      "contract-from-Co. N: ['received'] V: ['won']\n",
      "contract-with-Warner N: ['violates'] V: ['terminate']\n",
      "control-of-Inc. N: ['took'] V: ['seek']\n",
      "decline-for-quarter N: ['posted'] V: ['reported']\n",
      "decline-in-August N: ['followed', 'following', 'recorded'] V: ['following']\n",
      "decline-in-earnings N: ['alleviate', 'report', 'reported'] V: ['expects']\n",
      "declines-in-prices N: ['reflect'] V: ['had']\n",
      "disputes-with-company N: ['resolve'] V: ['resolve']\n",
      "domestic-production-through-July N: ['includes'] V: ['includes']\n",
      "drop-in-earnings N: ['posted'] V: ['posted']\n",
      "drop-in-profit N: ['experienced', 'had', 'posted', 'reported', 'reporting'] V: ['posted']\n",
      "earnings-for-companies N: ['reported'] V: ['reported']\n",
      "earnings-for-quarter N: ['posting'] V: ['posted', 'report', 'reported']\n",
      "earnings-in-quarter N: ['projecting'] V: ['had']\n",
      "earnings-of-million N: ['had', 'include', 'posted', 'reported'] V: ['reported']\n",
      "effect-on-market N: ['had'] V: ['had']\n",
      "emphasis-on-quality N: ['be'] V: ['place']\n",
      "financing-for-buy-out N: ['deliver', 'get'] V: ['obtaining']\n",
      "floor-for-price N: ['establishes'] V: ['providing']\n",
      "foot-in-door N: ['wanted'] V: ['getting']\n",
      "funding-for-abortion N: ['supporting'] V: ['oppose']\n",
      "funds-for-station N: ['including', 'providing'] V: ['includes']\n",
      "gain-from-sale N: ['included', 'includes'] V: ['a-Includes', 'including', 'record', 'report']\n",
      "gain-in-profit N: ['posted', 'reported'] V: ['posted']\n",
      "head-to-head N: ['going'] V: ['go']\n",
      "impact-on-market N: ['have'] V: ['has', 'have']\n",
      "impact-on-markets N: ['had'] V: ['have']\n",
      "impact-on-results N: ['have'] V: ['have']\n",
      "income-for-quarter N: ['announcing'] V: ['report']\n",
      "increase-in-earnings N: ['reported'] V: ['posted']\n",
      "information-from-companies N: ['requested'] V: ['steal']\n",
      "inquiry-into-activities N: ['conducted'] V: ['drop']\n",
      "interest-in-company N: ['bought', 'have', 'holds', 'owning', 'retain'] V: ['represent']\n",
      "interest-in-metals N: ['create'] V: ['was']\n",
      "interest-on-loans N: ['computing'] V: ['pay']\n",
      "loans-to-China N: ['suspended'] V: ['resuming']\n",
      "loss-for-quarter N: ['announced', 'have', 'post', 'posted', 'reported', 'reporting'] V: ['post', 'report', 'reported']\n",
      "loss-in-quarter N: ['expect', 'had'] V: ['caused', 'had', 'posted', 'took']\n",
      "losses-in-years N: ['reported'] V: ['had']\n",
      "markets-in-stocks N: ['making'] V: ['make']\n",
      "million-before-tax N: ['reported'] V: ['contributed']\n",
      "million-for-initiative N: ['attached'] V: ['add']\n",
      "million-for-stake N: ['pay'] V: ['paid', 'pay', 'putting']\n",
      "million-from-funds N: ['commit'] V: ['raises']\n",
      "million-from-operations N: ['included'] V: ['reported']\n",
      "million-from-sale N: ['including'] V: ['take']\n",
      "million-in-payments N: ['make', 'owes', 'pay', 'receive'] V: ['fallen']\n",
      "million-of-debt N: ['add', 'borrow', 'consolidate', 'convert', 'downgraded', 'includes', 'pay', 'raise'] V: ['assume']\n",
      "million-on-revenue N: ['earned'] V: ['earned', 'was', 'were']\n",
      "million-on-sales N: ['earned'] V: ['earned', 'reach', 'totaled', 'was', 'were']\n",
      "million-to-million N: ['be', 'bills', 'cost', 'pump', 'sell', 'totaled'] V: ['declined', 'fell', 'spend', 'tumbled']\n",
      "month-in-time N: ['delivered'] V: ['delivered']\n",
      "net-on-revenue N: ['posted'] V: ['reported']\n",
      "nothing-about-it N: ['knew'] V: ['doing']\n",
      "offer-for-all N: ['begun', 'make'] V: ['begin']\n",
      "offer-for-shares N: ['began', 'extended'] V: ['launched', 'made']\n",
      "offer-for-stock N: ['extended'] V: ['make']\n",
      "offer-from-group N: ['rejected'] V: ['received']\n",
      "office-in-Worth N: ['Call'] V: ['has']\n",
      "pace-with-inflation N: ['keep', 'keeping'] V: ['keep']\n",
      "payment-on-million N: ['make'] V: ['make']\n",
      "payments-on-debt N: ['cover', 'make'] V: ['make']\n",
      "president-in-charge N: ['is', 'named'] V: ['been']\n",
      "pressure-on-government N: ['keep'] V: ['keep', 'put']\n",
      "pressure-on-prices N: ['suffered'] V: ['keep', 'put']\n",
      "price-for-incentives N: ['paid'] V: ['paid']\n",
      "prices-on-market N: ['push'] V: ['bring']\n",
      "profit-for-year N: ['report'] V: ['report']\n",
      "profit-from-discontinued N: ['had'] V: ['was']\n",
      "profit-in-quarter N: ['indicates'] V: ['produce', 'recorded']\n",
      "projections-for-year N: ['slashed'] V: ['exceed']\n",
      "provisions-for-loans N: ['taken'] V: ['made']\n",
      "rates-to-% N: ['boosting'] V: ['increase', 'pushed', 'raised']\n",
      "reporter-in-bureau N: ['is'] V: ['is']\n",
      "restrictions-on-use N: ['waiving'] V: ['impose']\n",
      "revenue-for-year N: ['projected'] V: ['had']\n",
      "revenue-in-quarter N: ['expects'] V: ['had']\n",
      "sales-in-excess N: ['combined'] V: ['had']\n",
      "sales-in-quarter N: ['had'] V: ['increasing']\n",
      "sales-of-million N: ['expected', 'had', 'has', 'have', 'posted'] V: ['had']\n",
      "salvo-in-battle N: ['marking'] V: ['marking']\n",
      "services-for-customers N: ['offering'] V: ['provide']\n",
      "shareholder-in-bank N: ['become'] V: ['become']\n",
      "stake-in-Airlines N: ['acquiring', 'buy', 'raise'] V: ['buy']\n",
      "stake-in-Mixte N: ['bring'] V: ['boost']\n",
      "stake-in-Rally N: ['hold'] V: ['had']\n",
      "stake-in-company N: ['bought', 'building', 'built', 'buying', 'give', 'hold', 'obtaining', 'own', 'owns', 'raised', 'take'] V: ['accumulating', 'had', 'has', 'holds', 'own']\n",
      "stake-in-concern N: ['acquires', 'lowered'] V: ['retaining']\n",
      "stake-in-unit N: ['sell'] V: ['acquire']\n",
      "stake-in-venture N: ['has', 'hold', 'holds'] V: ['held']\n",
      "suit-against-Keating N: ['press'] V: ['brought']\n",
      "swings-in-market N: ['cause', 'create'] V: ['cause']\n",
      "system-for-city N: ['design'] V: ['design']\n",
      "system-in-Pakistan N: ['operate'] V: ['operate']\n",
      "time-for-Congress N: ['is'] V: ['buy', 'buys']\n",
      "venture-with-Co. N: ['started'] V: ['started']\n",
      "ventures-with-companies N: ['established'] V: ['form']\n",
      "verdict-in-case N: ['is', 'won'] V: ['won']\n",
      "volatility-in-stocks N: ['ignoring'] V: ['see']\n",
      "vote-on-issue N: ['allow'] V: ['prevent']\n",
      "way-for-declines N: ['open'] V: ['pave']\n",
      "writer-in-York N: ['is'] V: ['is']\n",
      "yen-to-yen N: ['shed'] V: ['advanced', 'fell', 'gained', 'lost', 'rose']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "entries = nltk.corpus.ppattach.attachments('training')\n",
    "table = defaultdict(lambda: defaultdict(set))\n",
    "for entry in entries:\n",
    "    key = entry.noun1 + '-' + entry.prep + '-' + entry.noun2\n",
    "    table[key][entry.attachment].add(entry.verb)\n",
    "\n",
    "for key in sorted(table):\n",
    "    if len(table[key]) > 1:\n",
    "        print(key, 'N:', sorted(table[key]['N']), 'V:', sorted(table[key]['V']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example from the *Sinica Treebank Corpus*:\n",
    "\n",
    "*Opens in new window, so not calling it from this notebook:*\n",
    "\n",
    "```\n",
    "nltk.corpus.sinica_treebank.parsed_sents()[3450].draw()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image(filename = \"C:\\\\Users\\\\mjcor\\\\Desktop\\\\ProgrammingStuff\\\\nltk\\\\sinica-tree.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Pernicious Ambiguity\n",
    "\n",
    "As the coverage of grammar increases and the length of the input sentences grows, the number of parse trees grows rapidly.  E.g., we can expand the sentence *fish fish fish* until it grows to an absure size:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP V NP\n",
    "NP -> NP Sbar\n",
    "Sbar -> NP V\n",
    "NP -> 'fish'\n",
    "V -> 'fish'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing *fish fish fish fish fish*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP fish) (V fish) (NP (NP fish) (Sbar (NP fish) (V fish))))\n",
      "(S (NP (NP fish) (Sbar (NP fish) (V fish))) (V fish) (NP fish))\n"
     ]
    }
   ],
   "source": [
    "tokens = [\"fish\"] * 5\n",
    "cp = nltk.ChartParser(grammar)\n",
    "for tree in cp.parse(tokens):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In case it's not clear, think \"Fish (that) fish fish (also) fish fish,\" or \"Fish fish fish, (that) fish fish.\"*\n",
    "\n",
    "As the length of this sentence goes up (3, 5, 7, ...), the number of parse trees increases so: 1, 2, 5, 14, 42, 132, 429, 1,430, etc...  These are Catalan numbers.  For a sentence of length 50 there would be over 1,000,000,000,000 parses.  No practical NLP system could construct millions of trees for a sentence and choose the appropriate one in the context.\n",
    "\n",
    "#### 6.3 Weighted Grammar\n",
    "\n",
    "Using the Penn Treebank sample to examine all instances of prepositional dative and double object constructions involving *give*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give(t):\n",
    "    return t.label() == 'VP' and len(t) > 2 and t[1].label() == 'NP'\\\n",
    "           and (t[2].label() == 'PP-DTV' or t[2].label() == 'NP')\\\n",
    "           and ('give' in t[0].leaves() or 'gave' in t[0].leaves())\n",
    "\n",
    "def sent(t):\n",
    "    return ' '.join(token for token in t.leaves() if token[0] not in '*-0')\n",
    "\n",
    "def print_node(t, width):\n",
    "    output = \"%s %s: %s / %s: %s\" %\\\n",
    "        (sent(t[0]), t[1].label(), sent(t[1]), t[2].label(), sent(t[2]))\n",
    "    if len(output) > width:\n",
    "        output = output[:width] + '...'\n",
    "    print(output)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gave NP: the chefs / NP: a standing ovation\n",
      "give NP: advertisers / NP: discounts for maintaining or increasing ad sp...\n",
      "give NP: it / PP-DTV: to the politicians\n",
      "gave NP: them / NP: similar help\n",
      "give NP: them / NP: \n",
      "give NP: only French history questions / PP-DTV: to students in a Europe...\n",
      "give NP: federal judges / NP: a raise\n",
      "give NP: consumers / NP: the straight scoop on the U.S. waste crisis\n",
      "gave NP: Mitsui / NP: access to a high-tech medical product\n",
      "give NP: Mitsubishi / NP: a window on the U.S. glass industry\n",
      "give NP: much thought / PP-DTV: to the rates she was receiving , nor to ...\n",
      "give NP: your Foster Savings Institution / NP: the gift of hope and free...\n",
      "give NP: market operators / NP: the authority to suspend trading in futu...\n",
      "gave NP: quick approval / PP-DTV: to $ 3.18 billion in supplemental appr...\n",
      "give NP: the Transportation Department / NP: up to 50 days to review any...\n",
      "give NP: the president / NP: such power\n",
      "give NP: me / NP: the heebie-jeebies\n",
      "give NP: holders / NP: the right , but not the obligation , to buy a cal...\n",
      "gave NP: Mr. Thomas / NP: only a `` qualified '' rating , rather than ``...\n",
      "give NP: the president / NP: line-item veto power\n"
     ]
    }
   ],
   "source": [
    "for tree in nltk.corpus.treebank.parsed_sents():\n",
    "    for t in tree.subtrees(give):\n",
    "        print_node(t, 72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A __probabilistic context free grammar__ (PCFG) is a CFG that associates a probability with each of its productions.  It generates the same set of parses for a text that the CFG does, and assigns a probability to each.  The probability of a parse is simply the product of the probabilities of its constituent productions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = nltk.PCFG.fromstring(\"\"\"\n",
    "    S    -> NP VP              [1.0]\n",
    "    VP   -> TV NP              [0.4]\n",
    "    VP   -> IV                 [0.3]\n",
    "    VP   -> DatV NP NP         [0.3]\n",
    "    TV   -> 'saw'              [1.0]\n",
    "    IV   -> 'ate'              [1.0]\n",
    "    DatV -> 'gave'             [1.0]\n",
    "    NP   -> 'telescopes'       [0.8]\n",
    "    NP   -> 'Jack'             [0.2]\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammar with 9 productions (start state = S)\n",
      "    S -> NP VP [1.0]\n",
      "    VP -> TV NP [0.4]\n",
      "    VP -> IV [0.3]\n",
      "    VP -> DatV NP NP [0.3]\n",
      "    TV -> 'saw' [1.0]\n",
      "    IV -> 'ate' [1.0]\n",
      "    DatV -> 'gave' [1.0]\n",
      "    NP -> 'telescopes' [0.8]\n",
      "    NP -> 'Jack' [0.2]\n"
     ]
    }
   ],
   "source": [
    "print(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Jack) (VP (TV saw) (NP telescopes))) (p=0.064)\n"
     ]
    }
   ],
   "source": [
    "viterbi_parser = nltk.ViterbiParser(grammar)\n",
    "for tree in viterbi_parser.parse(['Jack', 'saw', 'telescopes']):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 Summary\n",
    "\n",
    "*__No notes.__*\n",
    "\n",
    "### 8 Further Reading\n",
    "\n",
    "*__No notes.__*\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
